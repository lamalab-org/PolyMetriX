{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PolyMetriX","text":"<p>PolyMetriX is a comprehensive Python library that powers the entire machine learning workflow for polymer informatics. From data preparation to feature engineering, it provides a unified framework for developing structure-property relationships in polymer science. </p>"},{"location":"#why-polymetrix","title":"Why PolyMetriX?","text":"<p>The polymer informatics community often works with fragmented tools and custom implementations, making it challenging to develop reproducible and standardized workflows. PolyMetriX addresses this by providing an integrated ecosystem:</p> <ul> <li>Data:</li> <li>Standardized dataset objects for polymer data management</li> <li>Curated datasets including glass transition temperature (Tg) database</li> <li>Custom data splitting strategies optimized for polymer structures</li> <li>Advanced Featurization</li> <li>Hierarchical feature extraction at full polymer, backbone, and side-chain levels</li> <li>RDKit integration for robust molecular descriptor computation</li> <li>Specialized polymer-specific descriptors</li> <li>Built-in data splitting strategies for robust model validation</li> <li>Consistent API inspired by established cheminformatics tools</li> </ul> <p>Whether you're developing ML models for polymers, PolyMetriX streamlines your entire workflow. The package is open-source and designed to support reproducible research in polymer science and engineering, aiming to become the foundation for digital polymer chemistry.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#polymetrix.TSNE_embeddings","title":"<code>TSNE_embeddings</code>","text":""},{"location":"api/#polymetrix.TSNE_embeddings.parse_embedding","title":"<code>parse_embedding(embedding_str)</code>","text":"<p>Parse embedding string to numpy array</p> Source code in <code>src/polymetrix/TSNE_embeddings.py</code> <pre><code>def parse_embedding(embedding_str):\n    \"\"\"Parse embedding string to numpy array\"\"\"\n    if isinstance(embedding_str, str):\n        # Remove 'tensor(' and ')' if present, then parse as list\n        embedding_str = embedding_str.replace('tensor(', '').replace(')', '')\n        return np.array(ast.literal_eval(embedding_str))\n    return np.array(embedding_str)\n</code></pre>"},{"location":"api/#polymetrix.TSNE_embeddings.process_embeddings","title":"<code>process_embeddings(data, label)</code>","text":"<p>Process embeddings and concatenate them</p> Source code in <code>src/polymetrix/TSNE_embeddings.py</code> <pre><code>def process_embeddings(data, label):\n    \"\"\"Process embeddings and concatenate them\"\"\"\n    embeddings = []\n    valid_indices = []\n\n    for i, row in data.iterrows():\n        try:\n            psmiles_embed = parse_embedding(row['psmiles_embed'])\n            bigsmiles_embed = parse_embedding(row['bigsmiles_embed'])\n            # bigsmiles_embed = parse_embedding(row['polymer_name_embed'])\n\n            # Concatenate the embeddings\n            concat_embed = np.concatenate([psmiles_embed, bigsmiles_embed])\n            embeddings.append(concat_embed)\n            valid_indices.append(i)\n        except Exception as e:\n            print(f\"Skipping row {i} due to parsing error: {e}\")\n\n    embeddings = np.array(embeddings)\n    print(f\"{label} - Valid embeddings: {len(embeddings)}, Embedding dimension: {embeddings.shape[1] if len(embeddings) &gt; 0 else 0}\")\n\n    return embeddings, valid_indices\n</code></pre>"},{"location":"api/#polymetrix.datasets","title":"<code>datasets</code>","text":""},{"location":"api/#polymetrix.datasets.AbstractDataset","title":"<code>AbstractDataset</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for polymer datasets.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>class AbstractDataset(ABC):\n    \"\"\"Base class for polymer datasets.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize a dataset.\"\"\"\n        self._meta_data = None\n        self._features = None\n        self._labels = None\n        self._psmiles = None\n        self._feature_names = []\n        self._label_names = []\n        self._meta_names = []\n\n    @abstractmethod\n    def _load_data(self, subset: Optional[Collection[int]] = None):\n        \"\"\"Load and prepare the dataset-specific data.\n\n        Args:\n            subset (Optional[Collection[int]]): Indices to include in the dataset.\n        \"\"\"\n        pass\n\n    def get_subset(self, indices: Collection[int]) -&gt; \"AbstractDataset\":\n        \"\"\"Get a subset of the dataset.\"\"\"\n        if not all(0 &lt;= i &lt; len(self) for i in indices):\n            raise IndexError(\"Indices out of bounds.\")\n        subset = self.__class__()\n        subset._features = self._features[indices]\n        subset._labels = self._labels[indices]\n        subset._meta_data = self._meta_data[indices]\n        subset._psmiles = self._psmiles[indices] if self._psmiles is not None else None\n        subset._feature_names = self._feature_names.copy()\n        subset._label_names = self._label_names.copy()\n        subset._meta_names = self._meta_names.copy()\n        return subset\n\n    @property\n    def available_features(self) -&gt; list[str]:\n        \"\"\"List of available features.\n        Returns:\n            list[str]: List of feature names\n        \"\"\"\n        return self._feature_names\n\n    @property\n    def available_labels(self) -&gt; list[str]:\n        \"\"\"List of available labels.\n        Returns:\n            list[str]: List of label names\n        \"\"\"\n        return self._label_names\n\n    @property\n    def meta_info(self) -&gt; list[str]:\n        \"\"\"List of available metadata fields.\n        Returns:\n            list[str]: List of metadata field names\n        \"\"\"\n        return self._meta_names\n\n    @property\n    def psmiles(self) -&gt; np.ndarray:\n        \"\"\"Return the polymer SMILES strings.\n        Returns:\n            np.ndarray: Array of polymer SMILES strings\n        \"\"\"\n        return self._psmiles\n\n    def __len__(self):\n        \"\"\"Return the number of entries in the dataset.\"\"\"\n        return len(self._features) if self._features is not None else 0\n\n    def __iter__(self):\n        \"\"\"Iterate over the features in the dataset.\"\"\"\n        return iter(self._features)\n\n    def get_features(\n        self, idx: Collection[int], feature_names: Optional[Collection[str]] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get features for specified indices.\n        Args:\n            idx (Collection[int]): Indices of entries.\n            feature_names (Optional[Collection[str]]): Names of features to return.\n            If None, returns all available features.\n        Returns:\n            np.ndarray: Array of feature values.\n        \"\"\"\n        if feature_names is None:\n            return self._features[np.array(idx)]\n        col_indices = [self._feature_names.index(name) for name in feature_names]\n        return self._features[np.array(idx)][:, col_indices]\n\n    def get_labels(\n        self, idx: Collection[int], label_names: Optional[Collection[str]] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get labels for specified indices.\n        Args:\n            idx (Collection[int]): Indices of entries.\n            label_names (Optional[Collection[str]]): Names of labels to return.\n            If None, returns all available labels.\n        Returns:\n            np.ndarray: Array of label values.\n        \"\"\"\n        if label_names is None:\n            return self._labels[np.array(idx)]\n        col_indices = [self._label_names.index(name) for name in label_names]\n        return self._labels[np.array(idx)][:, col_indices]\n\n    def get_meta(\n        self, idx: Collection[int], meta_keys: Optional[Collection[str]] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get metadata for specified indices.\n        Args:\n            idx (Collection[int]): Indices of entries.\n            meta_keys (Optional[Collection[str]]): Names of metadata fields to return.\n            If None, returns all available metadata.\n\n        Returns:\n            np.ndarray: Array of metadata values.\n        \"\"\"\n        if meta_keys is None:\n            return self._meta_data[np.array(idx)]\n        col_indices = [self._meta_names.index(name) for name in meta_keys]\n        return self._meta_data[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.available_features","title":"<code>available_features</code>  <code>property</code>","text":"<p>List of available features. Returns:     list[str]: List of feature names</p>"},{"location":"api/#polymetrix.datasets.AbstractDataset.available_labels","title":"<code>available_labels</code>  <code>property</code>","text":"<p>List of available labels. Returns:     list[str]: List of label names</p>"},{"location":"api/#polymetrix.datasets.AbstractDataset.meta_info","title":"<code>meta_info</code>  <code>property</code>","text":"<p>List of available metadata fields. Returns:     list[str]: List of metadata field names</p>"},{"location":"api/#polymetrix.datasets.AbstractDataset.psmiles","title":"<code>psmiles</code>  <code>property</code>","text":"<p>Return the polymer SMILES strings. Returns:     np.ndarray: Array of polymer SMILES strings</p>"},{"location":"api/#polymetrix.datasets.AbstractDataset.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a dataset.\"\"\"\n    self._meta_data = None\n    self._features = None\n    self._labels = None\n    self._psmiles = None\n    self._feature_names = []\n    self._label_names = []\n    self._meta_names = []\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the features in the dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the features in the dataset.\"\"\"\n    return iter(self._features)\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of entries in the dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the number of entries in the dataset.\"\"\"\n    return len(self._features) if self._features is not None else 0\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset._load_data","title":"<code>_load_data(subset=None)</code>  <code>abstractmethod</code>","text":"<p>Load and prepare the dataset-specific data.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>Optional[Collection[int]]</code> <p>Indices to include in the dataset.</p> <code>None</code> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef _load_data(self, subset: Optional[Collection[int]] = None):\n    \"\"\"Load and prepare the dataset-specific data.\n\n    Args:\n        subset (Optional[Collection[int]]): Indices to include in the dataset.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.get_features","title":"<code>get_features(idx, feature_names=None)</code>","text":"<p>Get features for specified indices. Args:     idx (Collection[int]): Indices of entries.     feature_names (Optional[Collection[str]]): Names of features to return.     If None, returns all available features. Returns:     np.ndarray: Array of feature values.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_features(\n    self, idx: Collection[int], feature_names: Optional[Collection[str]] = None\n) -&gt; np.ndarray:\n    \"\"\"Get features for specified indices.\n    Args:\n        idx (Collection[int]): Indices of entries.\n        feature_names (Optional[Collection[str]]): Names of features to return.\n        If None, returns all available features.\n    Returns:\n        np.ndarray: Array of feature values.\n    \"\"\"\n    if feature_names is None:\n        return self._features[np.array(idx)]\n    col_indices = [self._feature_names.index(name) for name in feature_names]\n    return self._features[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.get_labels","title":"<code>get_labels(idx, label_names=None)</code>","text":"<p>Get labels for specified indices. Args:     idx (Collection[int]): Indices of entries.     label_names (Optional[Collection[str]]): Names of labels to return.     If None, returns all available labels. Returns:     np.ndarray: Array of label values.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_labels(\n    self, idx: Collection[int], label_names: Optional[Collection[str]] = None\n) -&gt; np.ndarray:\n    \"\"\"Get labels for specified indices.\n    Args:\n        idx (Collection[int]): Indices of entries.\n        label_names (Optional[Collection[str]]): Names of labels to return.\n        If None, returns all available labels.\n    Returns:\n        np.ndarray: Array of label values.\n    \"\"\"\n    if label_names is None:\n        return self._labels[np.array(idx)]\n    col_indices = [self._label_names.index(name) for name in label_names]\n    return self._labels[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.get_meta","title":"<code>get_meta(idx, meta_keys=None)</code>","text":"<p>Get metadata for specified indices. Args:     idx (Collection[int]): Indices of entries.     meta_keys (Optional[Collection[str]]): Names of metadata fields to return.     If None, returns all available metadata.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of metadata values.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_meta(\n    self, idx: Collection[int], meta_keys: Optional[Collection[str]] = None\n) -&gt; np.ndarray:\n    \"\"\"Get metadata for specified indices.\n    Args:\n        idx (Collection[int]): Indices of entries.\n        meta_keys (Optional[Collection[str]]): Names of metadata fields to return.\n        If None, returns all available metadata.\n\n    Returns:\n        np.ndarray: Array of metadata values.\n    \"\"\"\n    if meta_keys is None:\n        return self._meta_data[np.array(idx)]\n    col_indices = [self._meta_names.index(name) for name in meta_keys]\n    return self._meta_data[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.AbstractDataset.get_subset","title":"<code>get_subset(indices)</code>","text":"<p>Get a subset of the dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_subset(self, indices: Collection[int]) -&gt; \"AbstractDataset\":\n    \"\"\"Get a subset of the dataset.\"\"\"\n    if not all(0 &lt;= i &lt; len(self) for i in indices):\n        raise IndexError(\"Indices out of bounds.\")\n    subset = self.__class__()\n    subset._features = self._features[indices]\n    subset._labels = self._labels[indices]\n    subset._meta_data = self._meta_data[indices]\n    subset._psmiles = self._psmiles[indices] if self._psmiles is not None else None\n    subset._feature_names = self._feature_names.copy()\n    subset._label_names = self._label_names.copy()\n    subset._meta_names = self._meta_names.copy()\n    return subset\n</code></pre>"},{"location":"api/#polymetrix.datasets.CuratedGlassTempDataset","title":"<code>CuratedGlassTempDataset</code>","text":"<p>               Bases: <code>AbstractDataset</code></p> <p>Dataset for polymer glass transition temperature (Tg) data.</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>class CuratedGlassTempDataset(AbstractDataset):\n    \"\"\"Dataset for polymer glass transition temperature (Tg) data.\"\"\"\n\n    ALL_FEATURE_LEVELS = [\n        \"sidechainlevel\",\n        \"backbonelevel\",\n        \"fullpolymerlevel\",\n    ]\n    FEATURE_PREFIX = \"features.\"\n    LABEL_PREFIX = \"labels.\"\n    META_PREFIX = \"meta.\"\n\n    DEFAULT_VERSION = \"v1\"\n    DEFAULT_URL = \"https://zenodo.org/records/15210035/files/LAMALAB_CURATED_Tg_structured_polymerclass.csv?download=1\"\n\n    def __init__(\n        self,\n        feature_levels: List[str] = ALL_FEATURE_LEVELS,\n        subset: Optional[Collection[int]] = None,\n    ):\n        \"\"\"Initialize the Tg dataset.\n        Args:\n           feature_levels (List[str]): Feature levels to include\n           subset (Optional[Collection[int]]): Indices to include in the dataset\n        \"\"\"\n        super().__init__()\n        self._version = self.DEFAULT_VERSION\n        self._url = self.DEFAULT_URL\n        self._feature_levels = feature_levels\n\n        # Validate feature levels using set operations\n        if not set(self._feature_levels).issubset(self.ALL_FEATURE_LEVELS):\n            raise ValueError(\n                f\"feature_levels must be a subset of {self.ALL_FEATURE_LEVELS}, \"\n                f\"got {self._feature_levels}\"\n            )\n\n        self._load_data(subset)\n\n    def _load_data(self, subset: Optional[Collection[int]] = None):\n        \"\"\"Load and prepare the dataset.\"\"\"\n        csv_path = POLYMETRIX_PYSTOW_MODULE.ensure(\n            \"CuratedGlassTempDataset\",\n            self._version,\n            url=self._url,\n        )\n        self._df = pd.read_csv(str(csv_path)).reset_index(drop=True)\n\n        if subset is not None:\n            self._df = self._df.iloc[subset].reset_index(drop=True)\n\n        self._psmiles = self._df[\"PSMILES\"].to_numpy()\n\n        allowed_prefixes = [\n            f\"{level}.{self.FEATURE_PREFIX}\" for level in self._feature_levels\n        ]\n        self._feature_names = self._filter_columns(allowed_prefixes)\n\n        self._label_names = self._filter_columns([self.LABEL_PREFIX])\n        self._meta_names = self._filter_columns([self.META_PREFIX])\n\n        self._features = self._df[self._feature_names].to_numpy()\n        self._labels = self._df[self._label_names].to_numpy()\n        self._meta_data = self._df[self._meta_names].to_numpy()\n\n    def _filter_columns(self, prefixes: List[str]) -&gt; List[str]:\n        \"\"\"Helper to filter columns by prefix(es).\"\"\"\n        return [\n            col\n            for col in self._df.columns\n            if any(col.startswith(prefix) for prefix in prefixes)\n        ]\n\n    @property\n    def df(self) -&gt; pd.DataFrame:\n        return self._df\n\n    @property\n    def active_feature_levels(self) -&gt; List[str]:\n        return self._feature_levels\n\n    def get_subset(self, indices: Collection[int]) -&gt; \"CuratedGlassTempDataset\":\n        return CuratedGlassTempDataset(\n            feature_levels=self._feature_levels,\n            subset=indices,\n        )\n</code></pre>"},{"location":"api/#polymetrix.datasets.CuratedGlassTempDataset.__init__","title":"<code>__init__(feature_levels=ALL_FEATURE_LEVELS, subset=None)</code>","text":"<p>Initialize the Tg dataset. Args:    feature_levels (List[str]): Feature levels to include    subset (Optional[Collection[int]]): Indices to include in the dataset</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>def __init__(\n    self,\n    feature_levels: List[str] = ALL_FEATURE_LEVELS,\n    subset: Optional[Collection[int]] = None,\n):\n    \"\"\"Initialize the Tg dataset.\n    Args:\n       feature_levels (List[str]): Feature levels to include\n       subset (Optional[Collection[int]]): Indices to include in the dataset\n    \"\"\"\n    super().__init__()\n    self._version = self.DEFAULT_VERSION\n    self._url = self.DEFAULT_URL\n    self._feature_levels = feature_levels\n\n    # Validate feature levels using set operations\n    if not set(self._feature_levels).issubset(self.ALL_FEATURE_LEVELS):\n        raise ValueError(\n            f\"feature_levels must be a subset of {self.ALL_FEATURE_LEVELS}, \"\n            f\"got {self._feature_levels}\"\n        )\n\n    self._load_data(subset)\n</code></pre>"},{"location":"api/#polymetrix.datasets.CuratedGlassTempDataset._filter_columns","title":"<code>_filter_columns(prefixes)</code>","text":"<p>Helper to filter columns by prefix(es).</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>def _filter_columns(self, prefixes: List[str]) -&gt; List[str]:\n    \"\"\"Helper to filter columns by prefix(es).\"\"\"\n    return [\n        col\n        for col in self._df.columns\n        if any(col.startswith(prefix) for prefix in prefixes)\n    ]\n</code></pre>"},{"location":"api/#polymetrix.datasets.CuratedGlassTempDataset._load_data","title":"<code>_load_data(subset=None)</code>","text":"<p>Load and prepare the dataset.</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>def _load_data(self, subset: Optional[Collection[int]] = None):\n    \"\"\"Load and prepare the dataset.\"\"\"\n    csv_path = POLYMETRIX_PYSTOW_MODULE.ensure(\n        \"CuratedGlassTempDataset\",\n        self._version,\n        url=self._url,\n    )\n    self._df = pd.read_csv(str(csv_path)).reset_index(drop=True)\n\n    if subset is not None:\n        self._df = self._df.iloc[subset].reset_index(drop=True)\n\n    self._psmiles = self._df[\"PSMILES\"].to_numpy()\n\n    allowed_prefixes = [\n        f\"{level}.{self.FEATURE_PREFIX}\" for level in self._feature_levels\n    ]\n    self._feature_names = self._filter_columns(allowed_prefixes)\n\n    self._label_names = self._filter_columns([self.LABEL_PREFIX])\n    self._meta_names = self._filter_columns([self.META_PREFIX])\n\n    self._features = self._df[self._feature_names].to_numpy()\n    self._labels = self._df[self._label_names].to_numpy()\n    self._meta_data = self._df[self._meta_names].to_numpy()\n</code></pre>"},{"location":"api/#polymetrix.datasets.curated_tg_dataset","title":"<code>curated_tg_dataset</code>","text":""},{"location":"api/#polymetrix.datasets.curated_tg_dataset.CuratedGlassTempDataset","title":"<code>CuratedGlassTempDataset</code>","text":"<p>               Bases: <code>AbstractDataset</code></p> <p>Dataset for polymer glass transition temperature (Tg) data.</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>class CuratedGlassTempDataset(AbstractDataset):\n    \"\"\"Dataset for polymer glass transition temperature (Tg) data.\"\"\"\n\n    ALL_FEATURE_LEVELS = [\n        \"sidechainlevel\",\n        \"backbonelevel\",\n        \"fullpolymerlevel\",\n    ]\n    FEATURE_PREFIX = \"features.\"\n    LABEL_PREFIX = \"labels.\"\n    META_PREFIX = \"meta.\"\n\n    DEFAULT_VERSION = \"v1\"\n    DEFAULT_URL = \"https://zenodo.org/records/15210035/files/LAMALAB_CURATED_Tg_structured_polymerclass.csv?download=1\"\n\n    def __init__(\n        self,\n        feature_levels: List[str] = ALL_FEATURE_LEVELS,\n        subset: Optional[Collection[int]] = None,\n    ):\n        \"\"\"Initialize the Tg dataset.\n        Args:\n           feature_levels (List[str]): Feature levels to include\n           subset (Optional[Collection[int]]): Indices to include in the dataset\n        \"\"\"\n        super().__init__()\n        self._version = self.DEFAULT_VERSION\n        self._url = self.DEFAULT_URL\n        self._feature_levels = feature_levels\n\n        # Validate feature levels using set operations\n        if not set(self._feature_levels).issubset(self.ALL_FEATURE_LEVELS):\n            raise ValueError(\n                f\"feature_levels must be a subset of {self.ALL_FEATURE_LEVELS}, \"\n                f\"got {self._feature_levels}\"\n            )\n\n        self._load_data(subset)\n\n    def _load_data(self, subset: Optional[Collection[int]] = None):\n        \"\"\"Load and prepare the dataset.\"\"\"\n        csv_path = POLYMETRIX_PYSTOW_MODULE.ensure(\n            \"CuratedGlassTempDataset\",\n            self._version,\n            url=self._url,\n        )\n        self._df = pd.read_csv(str(csv_path)).reset_index(drop=True)\n\n        if subset is not None:\n            self._df = self._df.iloc[subset].reset_index(drop=True)\n\n        self._psmiles = self._df[\"PSMILES\"].to_numpy()\n\n        allowed_prefixes = [\n            f\"{level}.{self.FEATURE_PREFIX}\" for level in self._feature_levels\n        ]\n        self._feature_names = self._filter_columns(allowed_prefixes)\n\n        self._label_names = self._filter_columns([self.LABEL_PREFIX])\n        self._meta_names = self._filter_columns([self.META_PREFIX])\n\n        self._features = self._df[self._feature_names].to_numpy()\n        self._labels = self._df[self._label_names].to_numpy()\n        self._meta_data = self._df[self._meta_names].to_numpy()\n\n    def _filter_columns(self, prefixes: List[str]) -&gt; List[str]:\n        \"\"\"Helper to filter columns by prefix(es).\"\"\"\n        return [\n            col\n            for col in self._df.columns\n            if any(col.startswith(prefix) for prefix in prefixes)\n        ]\n\n    @property\n    def df(self) -&gt; pd.DataFrame:\n        return self._df\n\n    @property\n    def active_feature_levels(self) -&gt; List[str]:\n        return self._feature_levels\n\n    def get_subset(self, indices: Collection[int]) -&gt; \"CuratedGlassTempDataset\":\n        return CuratedGlassTempDataset(\n            feature_levels=self._feature_levels,\n            subset=indices,\n        )\n</code></pre>"},{"location":"api/#polymetrix.datasets.curated_tg_dataset.CuratedGlassTempDataset.__init__","title":"<code>__init__(feature_levels=ALL_FEATURE_LEVELS, subset=None)</code>","text":"<p>Initialize the Tg dataset. Args:    feature_levels (List[str]): Feature levels to include    subset (Optional[Collection[int]]): Indices to include in the dataset</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>def __init__(\n    self,\n    feature_levels: List[str] = ALL_FEATURE_LEVELS,\n    subset: Optional[Collection[int]] = None,\n):\n    \"\"\"Initialize the Tg dataset.\n    Args:\n       feature_levels (List[str]): Feature levels to include\n       subset (Optional[Collection[int]]): Indices to include in the dataset\n    \"\"\"\n    super().__init__()\n    self._version = self.DEFAULT_VERSION\n    self._url = self.DEFAULT_URL\n    self._feature_levels = feature_levels\n\n    # Validate feature levels using set operations\n    if not set(self._feature_levels).issubset(self.ALL_FEATURE_LEVELS):\n        raise ValueError(\n            f\"feature_levels must be a subset of {self.ALL_FEATURE_LEVELS}, \"\n            f\"got {self._feature_levels}\"\n        )\n\n    self._load_data(subset)\n</code></pre>"},{"location":"api/#polymetrix.datasets.curated_tg_dataset.CuratedGlassTempDataset._filter_columns","title":"<code>_filter_columns(prefixes)</code>","text":"<p>Helper to filter columns by prefix(es).</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>def _filter_columns(self, prefixes: List[str]) -&gt; List[str]:\n    \"\"\"Helper to filter columns by prefix(es).\"\"\"\n    return [\n        col\n        for col in self._df.columns\n        if any(col.startswith(prefix) for prefix in prefixes)\n    ]\n</code></pre>"},{"location":"api/#polymetrix.datasets.curated_tg_dataset.CuratedGlassTempDataset._load_data","title":"<code>_load_data(subset=None)</code>","text":"<p>Load and prepare the dataset.</p> Source code in <code>src/polymetrix/datasets/curated_tg_dataset.py</code> <pre><code>def _load_data(self, subset: Optional[Collection[int]] = None):\n    \"\"\"Load and prepare the dataset.\"\"\"\n    csv_path = POLYMETRIX_PYSTOW_MODULE.ensure(\n        \"CuratedGlassTempDataset\",\n        self._version,\n        url=self._url,\n    )\n    self._df = pd.read_csv(str(csv_path)).reset_index(drop=True)\n\n    if subset is not None:\n        self._df = self._df.iloc[subset].reset_index(drop=True)\n\n    self._psmiles = self._df[\"PSMILES\"].to_numpy()\n\n    allowed_prefixes = [\n        f\"{level}.{self.FEATURE_PREFIX}\" for level in self._feature_levels\n    ]\n    self._feature_names = self._filter_columns(allowed_prefixes)\n\n    self._label_names = self._filter_columns([self.LABEL_PREFIX])\n    self._meta_names = self._filter_columns([self.META_PREFIX])\n\n    self._features = self._df[self._feature_names].to_numpy()\n    self._labels = self._df[self._label_names].to_numpy()\n    self._meta_data = self._df[self._meta_names].to_numpy()\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset","title":"<code>dataset</code>","text":""},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset","title":"<code>AbstractDataset</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for polymer datasets.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>class AbstractDataset(ABC):\n    \"\"\"Base class for polymer datasets.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize a dataset.\"\"\"\n        self._meta_data = None\n        self._features = None\n        self._labels = None\n        self._psmiles = None\n        self._feature_names = []\n        self._label_names = []\n        self._meta_names = []\n\n    @abstractmethod\n    def _load_data(self, subset: Optional[Collection[int]] = None):\n        \"\"\"Load and prepare the dataset-specific data.\n\n        Args:\n            subset (Optional[Collection[int]]): Indices to include in the dataset.\n        \"\"\"\n        pass\n\n    def get_subset(self, indices: Collection[int]) -&gt; \"AbstractDataset\":\n        \"\"\"Get a subset of the dataset.\"\"\"\n        if not all(0 &lt;= i &lt; len(self) for i in indices):\n            raise IndexError(\"Indices out of bounds.\")\n        subset = self.__class__()\n        subset._features = self._features[indices]\n        subset._labels = self._labels[indices]\n        subset._meta_data = self._meta_data[indices]\n        subset._psmiles = self._psmiles[indices] if self._psmiles is not None else None\n        subset._feature_names = self._feature_names.copy()\n        subset._label_names = self._label_names.copy()\n        subset._meta_names = self._meta_names.copy()\n        return subset\n\n    @property\n    def available_features(self) -&gt; list[str]:\n        \"\"\"List of available features.\n        Returns:\n            list[str]: List of feature names\n        \"\"\"\n        return self._feature_names\n\n    @property\n    def available_labels(self) -&gt; list[str]:\n        \"\"\"List of available labels.\n        Returns:\n            list[str]: List of label names\n        \"\"\"\n        return self._label_names\n\n    @property\n    def meta_info(self) -&gt; list[str]:\n        \"\"\"List of available metadata fields.\n        Returns:\n            list[str]: List of metadata field names\n        \"\"\"\n        return self._meta_names\n\n    @property\n    def psmiles(self) -&gt; np.ndarray:\n        \"\"\"Return the polymer SMILES strings.\n        Returns:\n            np.ndarray: Array of polymer SMILES strings\n        \"\"\"\n        return self._psmiles\n\n    def __len__(self):\n        \"\"\"Return the number of entries in the dataset.\"\"\"\n        return len(self._features) if self._features is not None else 0\n\n    def __iter__(self):\n        \"\"\"Iterate over the features in the dataset.\"\"\"\n        return iter(self._features)\n\n    def get_features(\n        self, idx: Collection[int], feature_names: Optional[Collection[str]] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get features for specified indices.\n        Args:\n            idx (Collection[int]): Indices of entries.\n            feature_names (Optional[Collection[str]]): Names of features to return.\n            If None, returns all available features.\n        Returns:\n            np.ndarray: Array of feature values.\n        \"\"\"\n        if feature_names is None:\n            return self._features[np.array(idx)]\n        col_indices = [self._feature_names.index(name) for name in feature_names]\n        return self._features[np.array(idx)][:, col_indices]\n\n    def get_labels(\n        self, idx: Collection[int], label_names: Optional[Collection[str]] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get labels for specified indices.\n        Args:\n            idx (Collection[int]): Indices of entries.\n            label_names (Optional[Collection[str]]): Names of labels to return.\n            If None, returns all available labels.\n        Returns:\n            np.ndarray: Array of label values.\n        \"\"\"\n        if label_names is None:\n            return self._labels[np.array(idx)]\n        col_indices = [self._label_names.index(name) for name in label_names]\n        return self._labels[np.array(idx)][:, col_indices]\n\n    def get_meta(\n        self, idx: Collection[int], meta_keys: Optional[Collection[str]] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get metadata for specified indices.\n        Args:\n            idx (Collection[int]): Indices of entries.\n            meta_keys (Optional[Collection[str]]): Names of metadata fields to return.\n            If None, returns all available metadata.\n\n        Returns:\n            np.ndarray: Array of metadata values.\n        \"\"\"\n        if meta_keys is None:\n            return self._meta_data[np.array(idx)]\n        col_indices = [self._meta_names.index(name) for name in meta_keys]\n        return self._meta_data[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.available_features","title":"<code>available_features</code>  <code>property</code>","text":"<p>List of available features. Returns:     list[str]: List of feature names</p>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.available_labels","title":"<code>available_labels</code>  <code>property</code>","text":"<p>List of available labels. Returns:     list[str]: List of label names</p>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.meta_info","title":"<code>meta_info</code>  <code>property</code>","text":"<p>List of available metadata fields. Returns:     list[str]: List of metadata field names</p>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.psmiles","title":"<code>psmiles</code>  <code>property</code>","text":"<p>Return the polymer SMILES strings. Returns:     np.ndarray: Array of polymer SMILES strings</p>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a dataset.\"\"\"\n    self._meta_data = None\n    self._features = None\n    self._labels = None\n    self._psmiles = None\n    self._feature_names = []\n    self._label_names = []\n    self._meta_names = []\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the features in the dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the features in the dataset.\"\"\"\n    return iter(self._features)\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of entries in the dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the number of entries in the dataset.\"\"\"\n    return len(self._features) if self._features is not None else 0\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset._load_data","title":"<code>_load_data(subset=None)</code>  <code>abstractmethod</code>","text":"<p>Load and prepare the dataset-specific data.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>Optional[Collection[int]]</code> <p>Indices to include in the dataset.</p> <code>None</code> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef _load_data(self, subset: Optional[Collection[int]] = None):\n    \"\"\"Load and prepare the dataset-specific data.\n\n    Args:\n        subset (Optional[Collection[int]]): Indices to include in the dataset.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.get_features","title":"<code>get_features(idx, feature_names=None)</code>","text":"<p>Get features for specified indices. Args:     idx (Collection[int]): Indices of entries.     feature_names (Optional[Collection[str]]): Names of features to return.     If None, returns all available features. Returns:     np.ndarray: Array of feature values.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_features(\n    self, idx: Collection[int], feature_names: Optional[Collection[str]] = None\n) -&gt; np.ndarray:\n    \"\"\"Get features for specified indices.\n    Args:\n        idx (Collection[int]): Indices of entries.\n        feature_names (Optional[Collection[str]]): Names of features to return.\n        If None, returns all available features.\n    Returns:\n        np.ndarray: Array of feature values.\n    \"\"\"\n    if feature_names is None:\n        return self._features[np.array(idx)]\n    col_indices = [self._feature_names.index(name) for name in feature_names]\n    return self._features[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.get_labels","title":"<code>get_labels(idx, label_names=None)</code>","text":"<p>Get labels for specified indices. Args:     idx (Collection[int]): Indices of entries.     label_names (Optional[Collection[str]]): Names of labels to return.     If None, returns all available labels. Returns:     np.ndarray: Array of label values.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_labels(\n    self, idx: Collection[int], label_names: Optional[Collection[str]] = None\n) -&gt; np.ndarray:\n    \"\"\"Get labels for specified indices.\n    Args:\n        idx (Collection[int]): Indices of entries.\n        label_names (Optional[Collection[str]]): Names of labels to return.\n        If None, returns all available labels.\n    Returns:\n        np.ndarray: Array of label values.\n    \"\"\"\n    if label_names is None:\n        return self._labels[np.array(idx)]\n    col_indices = [self._label_names.index(name) for name in label_names]\n    return self._labels[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.get_meta","title":"<code>get_meta(idx, meta_keys=None)</code>","text":"<p>Get metadata for specified indices. Args:     idx (Collection[int]): Indices of entries.     meta_keys (Optional[Collection[str]]): Names of metadata fields to return.     If None, returns all available metadata.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of metadata values.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_meta(\n    self, idx: Collection[int], meta_keys: Optional[Collection[str]] = None\n) -&gt; np.ndarray:\n    \"\"\"Get metadata for specified indices.\n    Args:\n        idx (Collection[int]): Indices of entries.\n        meta_keys (Optional[Collection[str]]): Names of metadata fields to return.\n        If None, returns all available metadata.\n\n    Returns:\n        np.ndarray: Array of metadata values.\n    \"\"\"\n    if meta_keys is None:\n        return self._meta_data[np.array(idx)]\n    col_indices = [self._meta_names.index(name) for name in meta_keys]\n    return self._meta_data[np.array(idx)][:, col_indices]\n</code></pre>"},{"location":"api/#polymetrix.datasets.dataset.AbstractDataset.get_subset","title":"<code>get_subset(indices)</code>","text":"<p>Get a subset of the dataset.</p> Source code in <code>src/polymetrix/datasets/dataset.py</code> <pre><code>def get_subset(self, indices: Collection[int]) -&gt; \"AbstractDataset\":\n    \"\"\"Get a subset of the dataset.\"\"\"\n    if not all(0 &lt;= i &lt; len(self) for i in indices):\n        raise IndexError(\"Indices out of bounds.\")\n    subset = self.__class__()\n    subset._features = self._features[indices]\n    subset._labels = self._labels[indices]\n    subset._meta_data = self._meta_data[indices]\n    subset._psmiles = self._psmiles[indices] if self._psmiles is not None else None\n    subset._feature_names = self._feature_names.copy()\n    subset._label_names = self._label_names.copy()\n    subset._meta_names = self._meta_names.copy()\n    return subset\n</code></pre>"},{"location":"api/#polymetrix.embedding","title":"<code>embedding</code>","text":""},{"location":"api/#polymetrix.embedding.evaluate_model","title":"<code>evaluate_model(y_true, y_pred)</code>","text":"<p>Calculate evaluation metrics</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def evaluate_model(y_true, y_pred):\n    \"\"\"Calculate evaluation metrics\"\"\"\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n</code></pre>"},{"location":"api/#polymetrix.embedding.experiment_1_molformer_psmiles","title":"<code>experiment_1_molformer_psmiles(train_df, test_df)</code>","text":"<p>Experiment 1: MoLFormer pSMILES embeddings</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def experiment_1_molformer_psmiles(train_df, test_df):\n    \"\"\"Experiment 1: MoLFormer pSMILES embeddings\"\"\"\n    X_train, valid_train_indices = parse_molformer_embedding_column(\n        train_df, \"molformer_psmiles_embed\"\n    )\n    y_train = train_df.iloc[valid_train_indices][\"Tg(K)\"].values\n\n    X_test, valid_test_indices = parse_molformer_embedding_column(\n        test_df, \"molformer_psmiles_embed\"\n    )\n    y_test = test_df.iloc[valid_test_indices][\"Tg(K)\"].values\n\n    return run_experiment(X_train, y_train, X_test, y_test, \"MoLFormer pSMILES\")\n</code></pre>"},{"location":"api/#polymetrix.embedding.experiment_2_molformer_bigsmiles","title":"<code>experiment_2_molformer_bigsmiles(train_df, test_df)</code>","text":"<p>Experiment 2: MoLFormer BigSMILES embeddings</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def experiment_2_molformer_bigsmiles(train_df, test_df):\n    \"\"\"Experiment 2: MoLFormer BigSMILES embeddings\"\"\"\n    X_train, valid_train_indices = parse_molformer_embedding_column(\n        train_df, \"molformer_bigsmiles_embed\"\n    )\n    y_train = train_df.iloc[valid_train_indices][\"Tg(K)\"].values\n\n    X_test, valid_test_indices = parse_molformer_embedding_column(\n        test_df, \"molformer_bigsmiles_embed\"\n    )\n    y_test = test_df.iloc[valid_test_indices][\"Tg(K)\"].values\n\n    return run_experiment(X_train, y_train, X_test, y_test, \"MoLFormer BigSMILES\")\n</code></pre>"},{"location":"api/#polymetrix.embedding.experiment_3_molformer_combined","title":"<code>experiment_3_molformer_combined(train_df, test_df)</code>","text":"<p>Experiment 3: Combined MoLFormer pSMILES + BigSMILES embeddings (doubled dataset)</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def experiment_3_molformer_combined(train_df, test_df):\n    \"\"\"Experiment 3: Combined MoLFormer pSMILES + BigSMILES embeddings (doubled dataset)\"\"\"\n    # Get pSMILES embeddings\n    X_train_psmiles, valid_train_indices_psmiles = parse_molformer_embedding_column(\n        train_df, \"molformer_psmiles_embed\"\n    )\n    y_train_psmiles = train_df.iloc[valid_train_indices_psmiles][\"Tg(K)\"].values\n\n    # Get BigSMILES embeddings\n    X_train_bigsmiles, valid_train_indices_bigsmiles = parse_molformer_embedding_column(\n        train_df, \"molformer_bigsmiles_embed\"\n    )\n    y_train_bigsmiles = train_df.iloc[valid_train_indices_bigsmiles][\"Tg(K)\"].values\n\n    # Stack them vertically to double the training size\n    X_train_combined = np.vstack([X_train_psmiles, X_train_bigsmiles])\n    y_train_combined = np.concatenate([y_train_psmiles, y_train_bigsmiles])\n\n    # For test, just use pSMILES embeddings\n    X_test, valid_test_indices = parse_molformer_embedding_column(\n        test_df, \"molformer_psmiles_embed\"\n    )\n    y_test = test_df.iloc[valid_test_indices][\"Tg(K)\"].values\n\n    return run_experiment(\n        X_train_combined,\n        y_train_combined,\n        X_test,\n        y_test,\n        \"MoLFormer Combined (pSMILES + BigSMILES Doubled)\",\n    )\n</code></pre>"},{"location":"api/#polymetrix.embedding.load_datasets","title":"<code>load_datasets()</code>","text":"<p>Load training and test datasets</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def load_datasets():\n    \"\"\"Load training and test datasets\"\"\"\n    logging.info(\"Loading datasets...\")\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n    logging.info(f\"Train dataset shape: {train_df.shape}\")\n    logging.info(f\"Test dataset shape: {test_df.shape}\")\n    return train_df, test_df\n</code></pre>"},{"location":"api/#polymetrix.embedding.main","title":"<code>main()</code>","text":"<p>Main execution function with MoLFormer experiments</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def main():\n    \"\"\"Main execution function with MoLFormer experiments\"\"\"\n    print(\"\ud83d\ude80 Starting MoLFormer Polymer Tg Prediction Experiments\")\n    print(f\"\ud83d\udcca Train Dataset: {TRAIN_CSV_PATH}\")\n    print(f\"\ud83d\udcca Test Dataset: {TEST_CSV_PATH}\")\n    print(f\"\ud83c\udfaf Target: Tg(K)\")\n    print(f\"\ud83d\udd2c Model: GradientBoostingRegressor (default settings)\")\n    print(f\"\ud83c\udf31 Random Seeds: {RANDOM_SEEDS}\")\n    print(\"=\" * 80)\n\n    # Set random seed for reproducible subsampling\n    np.random.seed(42)\n\n    # Load datasets\n    train_df, test_df = load_datasets()\n\n    # Check the type of embedding columns\n    print(\n        f\"MoLFormer pSMILES embedding type: {type(train_df['molformer_psmiles_embed'].iloc[0])}\"\n    )\n    print(\n        f\"MoLFormer BigSMILES embedding type: {type(train_df['molformer_bigsmiles_embed'].iloc[0])}\"\n    )\n\n    if isinstance(train_df[\"molformer_psmiles_embed\"].iloc[0], list):\n        print(\n            f\"MoLFormer pSMILES embedding dimension: {len(train_df['molformer_psmiles_embed'].iloc[0])}\"\n        )\n    if isinstance(train_df[\"molformer_bigsmiles_embed\"].iloc[0], list):\n        print(\n            f\"MoLFormer BigSMILES embedding dimension: {len(train_df['molformer_bigsmiles_embed'].iloc[0])}\"\n        )\n\n    all_results = []\n\n    # Experiment 1: MoLFormer pSMILES\n    try:\n        result1 = experiment_1_molformer_psmiles(train_df, test_df)\n        all_results.append(result1)\n    except Exception as e:\n        logging.error(f\"Error in Experiment 1 (pSMILES): {e}\")\n        import traceback\n\n        traceback.print_exc()\n\n    # Experiment 2: MoLFormer BigSMILES\n    try:\n        result2 = experiment_2_molformer_bigsmiles(train_df, test_df)\n        all_results.append(result2)\n    except Exception as e:\n        logging.error(f\"Error in Experiment 2 (BigSMILES): {e}\")\n        import traceback\n\n        traceback.print_exc()\n\n    # Experiment 3: MoLFormer Combined\n    try:\n        result3 = experiment_3_molformer_combined(train_df, test_df)\n        all_results.append(result3)\n    except Exception as e:\n        logging.error(f\"Error in Experiment 3 (Combined): {e}\")\n        import traceback\n\n        traceback.print_exc()\n\n    # Analysis and Summary\n    if len(all_results) &gt;= 1:\n        logging.info(\"\\n\" + \"=\" * 120)\n        logging.info(\"\ud83d\udcca MOLFORMER EXPERIMENT ANALYSIS\")\n        logging.info(\"=\" * 120)\n\n        for result in all_results:\n            logging.info(f\"\\n{result['experiment']}:\")\n            logging.info(f\"  Training samples: {result['n_train']}\")\n            logging.info(f\"  Test samples: {result['n_test']}\")\n            logging.info(f\"  MAE: {result['mae_mean']:.3f} \u00b1 {result['mae_std']:.3f}\")\n            logging.info(\n                f\"  RMSE: {result['rmse_mean']:.3f} \u00b1 {result['rmse_std']:.3f}\"\n            )\n            logging.info(f\"  R\u00b2: {result['r2_mean']:.3f} \u00b1 {result['r2_std']:.3f}\")\n\n        # Performance comparison\n        if len(all_results) &gt;= 2:\n            logging.info(\"\\n\" + \"=\" * 80)\n            logging.info(\"\ud83d\udcc8 EMBEDDING TYPE COMPARISON\")\n            logging.info(\"=\" * 80)\n\n            # Find best performing model\n            best_mae = min([r[\"mae_mean\"] for r in all_results])\n            best_r2 = max([r[\"r2_mean\"] for r in all_results])\n\n            best_mae_model = next(r for r in all_results if r[\"mae_mean\"] == best_mae)\n            best_r2_model = next(r for r in all_results if r[\"r2_mean\"] == best_r2)\n\n            logging.info(f\"Best MAE: {best_mae_model['experiment']} ({best_mae:.3f})\")\n            logging.info(f\"Best R\u00b2: {best_r2_model['experiment']} ({best_r2:.3f})\")\n\n        # Save results\n        results_df = pd.DataFrame(all_results)\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n        output_csv = f\"molformer_polymer_tg_prediction_results_{timestamp}.csv\"\n        results_df.to_csv(output_csv, index=False)\n        logging.info(f\"\\n\ud83d\udcbe Results saved to: {output_csv}\")\n\n        print(f\"\\n\ud83d\udccb MOLFORMER EXPERIMENTS COMPLETED:\")\n        print(f\"Results saved to: {output_csv}\")\n\n    else:\n        logging.error(\"Insufficient results for analysis. Check experiment errors.\")\n</code></pre>"},{"location":"api/#polymetrix.embedding.parse_molformer_embedding_column","title":"<code>parse_molformer_embedding_column(df, column_name)</code>","text":"<p>Parse MoLFormer embedding column from list representation to numpy array</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def parse_molformer_embedding_column(df, column_name):\n    \"\"\"Parse MoLFormer embedding column from list representation to numpy array\"\"\"\n    embeddings = []\n    valid_indices = []\n\n    for i, embedding in enumerate(df[column_name]):\n        # Handle NaN values\n        if pd.isna(embedding):\n            continue\n\n        # Check if it's already a list\n        if isinstance(embedding, list):\n            emb_array = np.array(embedding)\n        else:\n            # Try to parse string representation of list\n            try:\n                import ast\n\n                if isinstance(embedding, str):\n                    emb_array = np.array(ast.literal_eval(embedding))\n                else:\n                    continue\n            except (ValueError, SyntaxError) as e:\n                logging.warning(f\"Error parsing embedding at row {i}: {e}\")\n                continue\n\n        embeddings.append(emb_array)\n        valid_indices.append(i)\n\n    if len(embeddings) == 0:\n        raise ValueError(f\"No valid embeddings found in column {column_name}\")\n\n    # Check for consistent dimensions\n    embedding_lengths = [len(emb) for emb in embeddings]\n    unique_lengths = set(embedding_lengths)\n\n    if len(unique_lengths) &gt; 1:\n        logging.warning(\n            f\"Inconsistent embedding dimensions in {column_name}: {unique_lengths}\"\n        )\n        # Use the most common dimension\n        from collections import Counter\n\n        most_common_length = Counter(embedding_lengths).most_common(1)[0][0]\n        logging.info(f\"Using most common dimension: {most_common_length}\")\n\n        # Filter embeddings to consistent dimension\n        filtered_embeddings = []\n        filtered_indices = []\n        for emb, idx in zip(embeddings, valid_indices):\n            if len(emb) == most_common_length:\n                filtered_embeddings.append(emb)\n                filtered_indices.append(idx)\n\n        embeddings = filtered_embeddings\n        valid_indices = filtered_indices\n\n    # Create numpy array\n    result = np.array(embeddings)\n    logging.info(f\"Successfully parsed {column_name}: shape {result.shape}\")\n    return result, valid_indices\n</code></pre>"},{"location":"api/#polymetrix.embedding.run_experiment","title":"<code>run_experiment(X_train, y_train, X_test, y_test, experiment_name)</code>","text":"<p>Run experiment with multiple seeds and return results</p> Source code in <code>src/polymetrix/embedding.py</code> <pre><code>def run_experiment(X_train, y_train, X_test, y_test, experiment_name):\n    \"\"\"Run experiment with multiple seeds and return results\"\"\"\n    logging.info(f\"\\n--- Running {experiment_name} ---\")\n    logging.info(f\"Training samples: {len(X_train)}\")\n    logging.info(f\"Test samples: {len(X_test)}\")\n    logging.info(f\"Feature dimension: {X_train.shape[1]}\")\n\n    results = []\n\n    for seed in RANDOM_SEEDS:\n        logging.info(f\"Running with random seed: {seed}\")\n\n        # Train model\n        model = GradientBoostingRegressor(random_state=seed)\n        model.fit(X_train, y_train)\n\n        # Predict\n        y_pred = model.predict(X_test)\n\n        # Evaluate\n        mae, rmse, r2 = evaluate_model(y_test, y_pred)\n        logging.info(f\"Seed {seed} - MAE: {mae:.3f}, RMSE: {rmse:.3f}, R\u00b2: {r2:.3f}\")\n\n        results.append({\"seed\": seed, \"mae\": mae, \"rmse\": rmse, \"r2\": r2})\n\n    # Calculate statistics\n    maes = [r[\"mae\"] for r in results]\n    rmses = [r[\"rmse\"] for r in results]\n    r2s = [r[\"r2\"] for r in results]\n\n    mae_mean, mae_std = np.mean(maes), np.std(maes, ddof=1)\n    rmse_mean, rmse_std = np.mean(rmses), np.std(rmses, ddof=1)\n    r2_mean, r2_std = np.mean(r2s), np.std(r2s, ddof=1)\n\n    logging.info(f\"\\n--- {experiment_name} FINAL RESULTS ---\")\n    logging.info(f\"MAE: {mae_mean:.3f} \u00b1 {mae_std:.3f}\")\n    logging.info(f\"RMSE: {rmse_mean:.3f} \u00b1 {rmse_std:.3f}\")\n    logging.info(f\"R\u00b2: {r2_mean:.3f} \u00b1 {r2_std:.3f}\")\n\n    return {\n        \"experiment\": experiment_name,\n        \"mae_mean\": mae_mean,\n        \"mae_std\": mae_std,\n        \"rmse_mean\": rmse_mean,\n        \"rmse_std\": rmse_std,\n        \"r2_mean\": r2_mean,\n        \"r2_std\": r2_std,\n        \"n_train\": len(X_train),\n        \"n_test\": len(X_test),\n    }\n</code></pre>"},{"location":"api/#polymetrix.embedding_copy","title":"<code>embedding_copy</code>","text":""},{"location":"api/#polymetrix.embedding_copy.evaluate_model","title":"<code>evaluate_model(y_true, y_pred)</code>","text":"<p>Calculate evaluation metrics</p> Source code in <code>src/polymetrix/embedding_copy.py</code> <pre><code>def evaluate_model(y_true, y_pred):\n    \"\"\"Calculate evaluation metrics\"\"\"\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    return mae, rmse, r2\n</code></pre>"},{"location":"api/#polymetrix.embedding_copy.load_datasets","title":"<code>load_datasets()</code>","text":"<p>Load training and test datasets</p> Source code in <code>src/polymetrix/embedding_copy.py</code> <pre><code>def load_datasets():\n    \"\"\"Load training and test datasets\"\"\"\n    logging.info(\"Loading datasets...\")\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    logging.info(f\"Train dataset shape: {train_df.shape}\")\n    logging.info(f\"Test dataset shape: {test_df.shape}\")\n\n    return train_df, test_df\n</code></pre>"},{"location":"api/#polymetrix.embedding_copy.main","title":"<code>main()</code>","text":"<p>Main execution function</p> Source code in <code>src/polymetrix/embedding_copy.py</code> <pre><code>def main():\n    \"\"\"Main execution function\"\"\"\n    print(\"\ud83d\ude80 Starting Polymer Tg Prediction Experiments\")\n    print(f\"\ud83d\udcca Train Dataset: {TRAIN_CSV_PATH}\")\n    print(f\"\ud83d\udcca Test Dataset: {TEST_CSV_PATH}\")\n    print(f\"\ud83c\udfaf Target: Tg(K)\")\n    print(f\"\ud83d\udd2c Model: GradientBoostingRegressor (default settings)\")\n    print(f\"\ud83c\udf31 Random Seeds: {RANDOM_SEEDS}\")\n    print(\"=\" * 80)\n\n    # Load datasets\n    train_df, test_df = load_datasets()\n\n    # Run experiments\n    all_results = []\n\n    # Task 1: Baseline ECFP\n    try:\n        result1 = task1_baseline_ecfp(train_df, test_df)\n        if result1:\n            all_results.append(result1)\n    except Exception as e:\n        logging.error(f\"Error in Task 1: {e}\")\n        import traceback\n\n        traceback.print_exc()\n\n    # Task 2: Combined embeddings\n    try:\n        result2 = task2_combined_embeddings(train_df, test_df)\n        if result2:\n            all_results.append(result2)\n    except Exception as e:\n        logging.error(f\"Error in Task 2: {e}\")\n        import traceback\n\n        traceback.print_exc()\n\n    # Summary\n    if all_results:\n        logging.info(\"\\n\" + \"=\" * 100)\n        logging.info(\"\ud83d\udcca FINAL EXPERIMENT SUMMARY\")\n        logging.info(\"=\" * 100)\n\n        for result in all_results:\n            logging.info(f\"\\n{result['task']}:\")\n            logging.info(f\"  Training samples: {result['n_train']}\")\n            logging.info(f\"  Test samples: {result['n_test']}\")\n            logging.info(f\"  MAE:  {result['mae_mean']:.3f} \u00b1 {result['mae_std']:.3f}\")\n            logging.info(\n                f\"  RMSE: {result['rmse_mean']:.3f} \u00b1 {result['rmse_std']:.3f}\"\n            )\n            logging.info(f\"  R\u00b2:   {result['r2_mean']:.3f} \u00b1 {result['r2_std']:.3f}\")\n\n        # Save results\n        results_df = pd.DataFrame(all_results)\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n        output_csv = f\"Application_combining_datasets_polymer_tg_prediction_results_{timestamp}.csv\"\n        results_df.to_csv(output_csv, index=False)\n\n        logging.info(f\"\\n\ud83d\udcbe Results saved to: {output_csv}\")\n\n        print(f\"\\n\ud83d\udccb EXPERIMENT COMPLETED:\")\n        print(f\"Results saved to: {output_csv}\")\n    else:\n        logging.error(\"No results generated. Check for errors in the experiments.\")\n</code></pre>"},{"location":"api/#polymetrix.embedding_copy.parse_embedding_column","title":"<code>parse_embedding_column(df, column_name)</code>","text":"<p>Parse embedding column from string representation to numpy array</p> Source code in <code>src/polymetrix/embedding_copy.py</code> <pre><code>def parse_embedding_column(df, column_name):\n    \"\"\"Parse embedding column from string representation to numpy array\"\"\"\n    embeddings = []\n    embedding_lengths = []\n\n    for i, embedding_str in enumerate(df[column_name]):\n        # Handle different string formats\n        embedding_str = str(embedding_str).strip()\n\n        # Skip if NaN or empty\n        if embedding_str == \"nan\" or embedding_str == \"\" or pd.isna(embedding_str):\n            continue\n\n        # Handle PyTorch tensor format: \"tensor([0.1, 0.2, ...])\"\n        if embedding_str.startswith(\"tensor(\"):\n            # Extract the array part from tensor([...])\n            start_idx = embedding_str.find(\"[\")\n            end_idx = embedding_str.rfind(\"]\")\n            if start_idx != -1 and end_idx != -1:\n                array_str = embedding_str[start_idx + 1 : end_idx]\n            else:\n                logging.warning(\n                    f\"Invalid tensor format at row {i}: {embedding_str[:50]}...\"\n                )\n                continue\n        # Handle simple array format: \"[0.1, 0.2, ...]\"\n        elif embedding_str.startswith(\"[\") and embedding_str.endswith(\"]\"):\n            array_str = embedding_str[1:-1]\n        else:\n            # Try to use as-is\n            array_str = embedding_str\n\n        # Parse the numbers\n        try:\n            # Split by comma and convert to float\n            values = [float(x.strip()) for x in array_str.split(\",\") if x.strip()]\n            if len(values) == 0:\n                logging.warning(f\"Empty embedding at row {i}\")\n                continue\n\n            embedding = np.array(values)\n            embeddings.append(embedding)\n            embedding_lengths.append(len(values))\n        except ValueError as e:\n            logging.warning(\n                f\"Error parsing embedding at row {i}: {embedding_str[:50]}... - {e}\"\n            )\n            continue\n\n    if len(embeddings) == 0:\n        raise ValueError(f\"No valid embeddings found in column {column_name}\")\n\n    # Check for consistent dimensions\n    unique_lengths = set(embedding_lengths)\n    if len(unique_lengths) &gt; 1:\n        logging.warning(\n            f\"Inconsistent embedding dimensions in {column_name}: {unique_lengths}\"\n        )\n        # Use the most common dimension\n        from collections import Counter\n\n        most_common_length = Counter(embedding_lengths).most_common(1)[0][0]\n        logging.info(f\"Using most common dimension: {most_common_length}\")\n\n        # Filter embeddings to consistent dimension\n        filtered_embeddings = []\n        for emb in embeddings:\n            if len(emb) == most_common_length:\n                filtered_embeddings.append(emb)\n\n        embeddings = filtered_embeddings\n        logging.info(\n            f\"Filtered to {len(embeddings)} embeddings with consistent dimension\"\n        )\n\n    if len(embeddings) == 0:\n        raise ValueError(\n            f\"No embeddings with consistent dimensions in column {column_name}\"\n        )\n\n    # Now create the numpy array\n    try:\n        result = np.array(embeddings)\n        logging.info(f\"Successfully parsed {column_name}: shape {result.shape}\")\n        return result\n    except Exception as e:\n        logging.error(f\"Failed to create numpy array for {column_name}: {e}\")\n        # Try creating it row by row to identify the problematic entries\n        max_len = max(len(emb) for emb in embeddings)\n        min_len = min(len(emb) for emb in embeddings)\n        logging.error(f\"Embedding length range: {min_len} to {max_len}\")\n        raise e\n</code></pre>"},{"location":"api/#polymetrix.embedding_copy.task1_baseline_ecfp","title":"<code>task1_baseline_ecfp(train_df, test_df)</code>","text":"<p>Task 1: Baseline model using ECFP fingerprints</p> Source code in <code>src/polymetrix/embedding_copy.py</code> <pre><code>def task1_baseline_ecfp(train_df, test_df):\n    \"\"\"Task 1: Baseline model using ECFP fingerprints\"\"\"\n    logging.info(\"\\n\" + \"=\" * 80)\n    logging.info(\"TASK 1: Baseline Model with ECFP Fingerprints\")\n    logging.info(\"=\" * 80)\n\n    # Prepare features and target\n    X_train = parse_embedding_column(train_df, \"ecfp_fingerprint\")\n    y_train = train_df[\"Tg(K)\"].values\n\n    X_test = parse_embedding_column(test_df, \"ecfp_fingerprint\")\n    y_test = test_df[\"Tg(K)\"].values\n\n    # Ensure we have matching indices\n    if len(X_train) != len(y_train):\n        # Need to filter y_train to match X_train\n        logging.warning(\n            f\"Mismatch in training data: X_train={len(X_train)}, y_train={len(y_train)}\"\n        )\n        # This is a more complex fix - for now, let's assume they match\n\n    if len(X_test) != len(y_test):\n        logging.warning(\n            f\"Mismatch in test data: X_test={len(X_test)}, y_test={len(y_test)}\"\n        )\n\n    logging.info(f\"Training features shape: {X_train.shape}\")\n    logging.info(f\"Test features shape: {X_test.shape}\")\n    logging.info(f\"Training samples: {len(y_train)}\")\n    logging.info(f\"Test samples: {len(y_test)}\")\n\n    results = []\n\n    # Run with different random seeds\n    for seed in RANDOM_SEEDS:\n        logging.info(f\"\\nRunning with random seed: {seed}\")\n\n        # Train model\n        model = GradientBoostingRegressor(random_state=seed)\n        model.fit(X_train, y_train)\n\n        # Predict\n        y_pred = model.predict(X_test)\n\n        # Evaluate\n        mae, rmse, r2 = evaluate_model(y_test, y_pred)\n\n        logging.info(f\"Seed {seed} - MAE: {mae:.3f}, RMSE: {rmse:.3f}, R\u00b2: {r2:.3f}\")\n\n        results.append({\"seed\": seed, \"mae\": mae, \"rmse\": rmse, \"r2\": r2})\n\n    # Calculate statistics\n    maes = [r[\"mae\"] for r in results]\n    rmses = [r[\"rmse\"] for r in results]\n    r2s = [r[\"r2\"] for r in results]\n\n    mae_mean, mae_std = np.mean(maes), np.std(maes, ddof=1)\n    rmse_mean, rmse_std = np.mean(rmses), np.std(rmses, ddof=1)\n    r2_mean, r2_std = np.mean(r2s), np.std(r2s, ddof=1)\n\n    logging.info(f\"\\n--- TASK 1 FINAL RESULTS ---\")\n    logging.info(f\"MAE:  {mae_mean:.3f} \u00b1 {mae_std:.3f}\")\n    logging.info(f\"RMSE: {rmse_mean:.3f} \u00b1 {rmse_std:.3f}\")\n    logging.info(f\"R\u00b2:   {r2_mean:.3f} \u00b1 {r2_std:.3f}\")\n\n    return {\n        \"task\": \"Baseline ECFP\",\n        \"mae_mean\": mae_mean,\n        \"mae_std\": mae_std,\n        \"rmse_mean\": rmse_mean,\n        \"rmse_std\": rmse_std,\n        \"r2_mean\": r2_mean,\n        \"r2_std\": r2_std,\n        \"n_train\": len(X_train),\n        \"n_test\": len(X_test),\n    }\n</code></pre>"},{"location":"api/#polymetrix.embedding_copy.task2_combined_embeddings","title":"<code>task2_combined_embeddings(train_df, test_df)</code>","text":"<p>Task 2: Combined embeddings model</p> Source code in <code>src/polymetrix/embedding_copy.py</code> <pre><code>def task2_combined_embeddings(train_df, test_df):\n    \"\"\"Task 2: Combined embeddings model\"\"\"\n    logging.info(\"\\n\" + \"=\" * 80)\n    logging.info(\"TASK 2: Combined Embeddings Model\")\n    logging.info(\"=\" * 80)\n\n    # Prepare test set using psmiles_embed to match combined training embeddings\n    X_test = parse_embedding_column(test_df, \"psmiles_bigsmiles_embed\")\n    y_test = test_df[\"Tg(K)\"].values\n\n    # Filter y_test to match X_test if needed\n    if len(X_test) != len(y_test):\n        logging.warning(\n            f\"Test data mismatch: X_test={len(X_test)}, y_test={len(y_test)}\"\n        )\n        # For now, assume they should match - this needs more sophisticated handling\n\n    logging.info(f\"Test features shape: {X_test.shape}\")\n    logging.info(f\"Test samples: {len(X_test)}\")\n\n    # Create combined training dataset\n    combined_X = []\n    combined_y = []\n\n    # Get the target dimension from test set\n    target_dim = X_test.shape[1]\n    logging.info(f\"Target embedding dimension: {target_dim}\")\n\n    # Add psmiles_embed data\n    if \"psmiles_bigsmiles_embed\" in train_df.columns:\n        try:\n            psmiles_X = parse_embedding_column(train_df, \"psmiles_bigsmiles_embed\")\n            if psmiles_X.shape[1] == target_dim:\n                # Get corresponding y values\n                psmiles_y = train_df[\"Tg(K)\"].values\n                if len(psmiles_X) != len(psmiles_y):\n                    # Need to match indices - this is complex, simplified for now\n                    min_len = min(len(psmiles_X), len(psmiles_y))\n                    psmiles_X = psmiles_X[:min_len]\n                    psmiles_y = psmiles_y[:min_len]\n\n                combined_X.append(psmiles_X)\n                combined_y.append(psmiles_y)\n                logging.info(\n                    f\"Added psmiles_embed: {len(psmiles_y)} samples, shape: {psmiles_X.shape}\"\n                )\n            else:\n                logging.warning(\n                    f\"psmiles_embed dimension mismatch: {psmiles_X.shape[1]} vs {target_dim}\"\n                )\n        except Exception as e:\n            logging.error(f\"Error processing psmiles_embed: {e}\")\n\n    # Add bigsmiles_embed data\n    if \"bigsmiles_psmiles_embed\" in train_df.columns:\n        try:\n            bigsmiles_X = parse_embedding_column(train_df, \"bigsmiles_psmiles_embed\")\n            if bigsmiles_X.shape[1] == target_dim:\n                bigsmiles_y = train_df[\"Tg(K)\"].values\n                if len(bigsmiles_X) != len(bigsmiles_y):\n                    min_len = min(len(bigsmiles_X), len(bigsmiles_y))\n                    bigsmiles_X = bigsmiles_X[:min_len]\n                    bigsmiles_y = bigsmiles_y[:min_len]\n\n                combined_X.append(bigsmiles_X)\n                combined_y.append(bigsmiles_y)\n                logging.info(\n                    f\"Added bigsmiles_embed: {len(bigsmiles_y)} samples, shape: {bigsmiles_X.shape}\"\n                )\n            else:\n                logging.warning(\n                    f\"bigsmiles_embed dimension mismatch: {bigsmiles_X.shape[1]} vs {target_dim}\"\n                )\n        except Exception as e:\n            logging.error(f\"Error processing bigsmiles_embed: {e}\")\n\n    # Add psmiles_embed_polymer_name data\n    if \"psmiles_polymer_name_embed\" in train_df.columns:\n        try:\n            psmiles_polymer_X = parse_embedding_column(\n                train_df, \"psmiles_polymer_name_embed\"\n            )\n            if psmiles_polymer_X.shape[1] == target_dim:\n                psmiles_polymer_y = train_df[\"Tg(K)\"].values\n                if len(psmiles_polymer_X) != len(psmiles_polymer_y):\n                    min_len = min(len(psmiles_polymer_X), len(psmiles_polymer_y))\n                    psmiles_polymer_X = psmiles_polymer_X[:min_len]\n                    psmiles_polymer_y = psmiles_polymer_y[:min_len]\n\n                combined_X.append(psmiles_polymer_X)\n                combined_y.append(psmiles_polymer_y)\n                logging.info(\n                    f\"Added psmiles_embed_polymer_name: {len(psmiles_polymer_y)} samples, shape: {psmiles_polymer_X.shape}\"\n                )\n            else:\n                logging.warning(\n                    f\"psmiles_embed_polymer_name dimension mismatch: {psmiles_polymer_X.shape[1]} vs {target_dim}\"\n                )\n        except Exception as e:\n            logging.error(f\"Error processing psmiles_embed_polymer_name: {e}\")\n\n    # Add polymer_name_embed data (if available)\n    if \"polymer_name_psmiles_embed\" in train_df.columns:\n        try:\n            # Filter out rows where polymer_name_embed is not null/empty\n            polymer_mask = train_df[\"polymer_name_psmiles_embed\"].notna()\n            if polymer_mask.sum() &gt; 0:\n                polymer_X = parse_embedding_column(\n                    train_df[polymer_mask], \"polymer_name_psmiles_embed\"\n                )\n                if polymer_X.shape[1] == target_dim:\n                    polymer_y = train_df[polymer_mask][\"Tg(K)\"].values\n                    if len(polymer_X) != len(polymer_y):\n                        min_len = min(len(polymer_X), len(polymer_y))\n                        polymer_X = polymer_X[:min_len]\n                        polymer_y = polymer_y[:min_len]\n\n                    combined_X.append(polymer_X)\n                    combined_y.append(polymer_y)\n                    logging.info(\n                        f\"Added polymer_name_embed: {len(polymer_y)} samples, shape: {polymer_X.shape}\"\n                    )\n                else:\n                    logging.warning(\n                        f\"polymer_name_embed dimension mismatch: {polymer_X.shape[1]} vs {target_dim}\"\n                    )\n        except Exception as e:\n            logging.error(f\"Error processing polymer_name_embed: {e}\")\n\n    # Check if we have any data\n    if len(combined_X) == 0:\n        logging.error(\"No embedding data found!\")\n        return None\n\n    # Stack all embeddings\n    try:\n        X_train_combined = np.vstack(combined_X)\n        y_train_combined = np.concatenate(combined_y)\n\n        logging.info(f\"Combined training data shape: {X_train_combined.shape}\")\n        logging.info(f\"Total training samples: {len(y_train_combined)}\")\n\n        # Verify dimensions match\n        if X_train_combined.shape[1] != X_test.shape[1]:\n            logging.error(\n                f\"Dimension mismatch: train={X_train_combined.shape[1]}, test={X_test.shape[1]}\"\n            )\n            return None\n\n    except Exception as e:\n        logging.error(f\"Error combining embeddings: {e}\")\n        return None\n\n    results = []\n\n    # Run with different random seeds\n    for seed in RANDOM_SEEDS:\n        logging.info(f\"\\nRunning with random seed: {seed}\")\n\n        # Train model\n        model = GradientBoostingRegressor(random_state=seed)\n        model.fit(X_train_combined, y_train_combined)\n\n        # Predict\n        y_pred = model.predict(X_test)\n\n        # Evaluate\n        mae, rmse, r2 = evaluate_model(y_test, y_pred)\n\n        logging.info(f\"Seed {seed} - MAE: {mae:.3f}, RMSE: {rmse:.3f}, R\u00b2: {r2:.3f}\")\n\n        results.append({\"seed\": seed, \"mae\": mae, \"rmse\": rmse, \"r2\": r2})\n\n    # Calculate statistics\n    maes = [r[\"mae\"] for r in results]\n    rmses = [r[\"rmse\"] for r in results]\n    r2s = [r[\"r2\"] for r in results]\n\n    mae_mean, mae_std = np.mean(maes), np.std(maes, ddof=1)\n    rmse_mean, rmse_std = np.mean(rmses), np.std(rmses, ddof=1)\n    r2_mean, r2_std = np.mean(r2s), np.std(r2s, ddof=1)\n\n    logging.info(f\"\\n--- TASK 2 FINAL RESULTS ---\")\n    logging.info(f\"MAE:  {mae_mean:.3f} \u00b1 {mae_std:.3f}\")\n    logging.info(f\"RMSE: {rmse_mean:.3f} \u00b1 {rmse_std:.3f}\")\n    logging.info(f\"R\u00b2:   {r2_mean:.3f} \u00b1 {r2_std:.3f}\")\n\n    return {\n        \"task\": \"Combined Embeddings\",\n        \"mae_mean\": mae_mean,\n        \"mae_std\": mae_std,\n        \"rmse_mean\": rmse_mean,\n        \"rmse_std\": rmse_std,\n        \"r2_mean\": r2_mean,\n        \"r2_std\": r2_std,\n        \"n_train\": len(y_train_combined),\n        \"n_test\": len(X_test),\n    }\n</code></pre>"},{"location":"api/#polymetrix.featurizers","title":"<code>featurizers</code>","text":""},{"location":"api/#polymetrix.featurizers.base_featurizer","title":"<code>base_featurizer</code>","text":""},{"location":"api/#polymetrix.featurizers.base_featurizer.BaseFeatureCalculator","title":"<code>BaseFeatureCalculator</code>","text":"Source code in <code>src/polymetrix/featurizers/base_featurizer.py</code> <pre><code>class BaseFeatureCalculator:\n    agg_funcs = {\n        \"mean\": np.mean,\n        \"min\": np.min,\n        \"max\": np.max,\n        \"sum\": np.sum,\n    }\n\n    def __init__(self, agg: List[str] = None):\n        if agg is None:\n            agg = [\"sum\"]\n        self.agg = agg\n\n    def _sanitize(self, mol: Chem.Mol, sanitize: bool) -&gt; None:\n        \"\"\"Handle molecule sanitization with kekulization exception handling.\"\"\"\n        if sanitize:\n            try:\n                Chem.SanitizeMol(\n                    mol, sanitizeOps=Chem.SANITIZE_ALL ^ Chem.SANITIZE_KEKULIZE\n                )\n            except Chem.AtomKekulizeException:\n                mol.UpdatePropertyCache()\n\n    def calculate(self, mol: Chem.Mol) -&gt; np.ndarray:\n        raise NotImplementedError(\"Calculate method must be implemented by subclasses\")\n\n    def feature_base_labels(self) -&gt; List[str]:\n        raise NotImplementedError(\n            \"Feature labels method must be implemented by subclasses\"\n        )\n\n    def feature_labels(self) -&gt; List[str]:\n        return [\n            f\"{label}_{agg}\" for label in self.feature_base_labels() for agg in self.agg\n        ]\n\n    def aggregate(self, features: List) -&gt; np.ndarray:\n        \"\"\"\n        Aggregates a list of features using the aggregation functions specified in self.agg.\n        If the features are numpy arrays, the aggregation is applied along the first axis.\n        Otherwise, the aggregation is applied directly (assuming the features are scalar numeric values).\n        \"\"\"\n        results = []\n        if not features:\n            return np.array([])\n\n        # Check whether features are numpy arrays by testing the first element.\n        first_elem = features[0]\n        if isinstance(first_elem, np.ndarray):\n            for agg_func in self.agg:\n                if agg_func not in self.agg_funcs:\n                    raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n                aggregated = self.agg_funcs[agg_func](features, axis=0)\n                results.append(aggregated)\n            return np.concatenate(results)\n        else:\n            for agg_func in self.agg:\n                if agg_func not in self.agg_funcs:\n                    raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n                results.append(self.agg_funcs[agg_func](features))\n            return np.array(results)\n\n    def get_feature_names(self) -&gt; List[str]:\n        raise NotImplementedError(\n            \"Get feature name method must be implemented by subclasses\"\n        )\n\n    def citations(self) -&gt; List[str]:\n        return []\n\n    def implementors(self) -&gt; List[str]:\n        return []\n</code></pre>"},{"location":"api/#polymetrix.featurizers.base_featurizer.BaseFeatureCalculator._sanitize","title":"<code>_sanitize(mol, sanitize)</code>","text":"<p>Handle molecule sanitization with kekulization exception handling.</p> Source code in <code>src/polymetrix/featurizers/base_featurizer.py</code> <pre><code>def _sanitize(self, mol: Chem.Mol, sanitize: bool) -&gt; None:\n    \"\"\"Handle molecule sanitization with kekulization exception handling.\"\"\"\n    if sanitize:\n        try:\n            Chem.SanitizeMol(\n                mol, sanitizeOps=Chem.SANITIZE_ALL ^ Chem.SANITIZE_KEKULIZE\n            )\n        except Chem.AtomKekulizeException:\n            mol.UpdatePropertyCache()\n</code></pre>"},{"location":"api/#polymetrix.featurizers.base_featurizer.BaseFeatureCalculator.aggregate","title":"<code>aggregate(features)</code>","text":"<p>Aggregates a list of features using the aggregation functions specified in self.agg. If the features are numpy arrays, the aggregation is applied along the first axis. Otherwise, the aggregation is applied directly (assuming the features are scalar numeric values).</p> Source code in <code>src/polymetrix/featurizers/base_featurizer.py</code> <pre><code>def aggregate(self, features: List) -&gt; np.ndarray:\n    \"\"\"\n    Aggregates a list of features using the aggregation functions specified in self.agg.\n    If the features are numpy arrays, the aggregation is applied along the first axis.\n    Otherwise, the aggregation is applied directly (assuming the features are scalar numeric values).\n    \"\"\"\n    results = []\n    if not features:\n        return np.array([])\n\n    # Check whether features are numpy arrays by testing the first element.\n    first_elem = features[0]\n    if isinstance(first_elem, np.ndarray):\n        for agg_func in self.agg:\n            if agg_func not in self.agg_funcs:\n                raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n            aggregated = self.agg_funcs[agg_func](features, axis=0)\n            results.append(aggregated)\n        return np.concatenate(results)\n    else:\n        for agg_func in self.agg:\n            if agg_func not in self.agg_funcs:\n                raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n            results.append(self.agg_funcs[agg_func](features))\n        return np.array(results)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.base_featurizer.MoleculeFeaturizer","title":"<code>MoleculeFeaturizer</code>","text":"<p>Base class for featurizers that work with general molecules.</p> Source code in <code>src/polymetrix/featurizers/base_featurizer.py</code> <pre><code>class MoleculeFeaturizer:\n    \"\"\"Base class for featurizers that work with general molecules.\"\"\"\n\n    def __init__(self, calculator: Optional[BaseFeatureCalculator] = None):\n        self.calculator = calculator\n\n    def featurize(self, molecule) -&gt; np.ndarray:\n        raise NotImplementedError(\"Featurize method must be implemented by subclasses\")\n\n    def feature_labels(self) -&gt; List[str]:\n        if self.calculator:\n            return [\n                f\"{label}_{self.__class__.__name__.lower()}\"\n                for label in self.calculator.feature_labels()\n            ]\n        else:\n            return [self.__class__.__name__.lower()]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer","title":"<code>chemical_featurizer</code>","text":""},{"location":"api/#polymetrix.featurizers.chemical_featurizer.BalabanJIndex","title":"<code>BalabanJIndex</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Measures molecular complexity and connectivity of atoms.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class BalabanJIndex(GenericScalarFeaturizer):\n    \"\"\"\n    Measures molecular complexity and connectivity of atoms.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(GraphDescriptors.BalabanJ, \"balaban_j_index\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.BondCounts","title":"<code>BondCounts</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of single, double, and triple bonds in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class BondCounts(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of single, double, and triple bonds in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        bond_types = {\n            Chem.BondType.SINGLE: 0,\n            Chem.BondType.DOUBLE: 0,\n            Chem.BondType.TRIPLE: 0,\n        }\n        for bond in mol.GetBonds():\n            if bond.GetBondType() in bond_types:\n                bond_types[bond.GetBondType()] += 1\n        return np.array(\n            [\n                bond_types[Chem.BondType.SINGLE],\n                bond_types[Chem.BondType.DOUBLE],\n                bond_types[Chem.BondType.TRIPLE],\n            ]\n        )\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"single_bonds\", \"double_bonds\", \"triple_bonds\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.BridgingRingsCount","title":"<code>BridgingRingsCount</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of bridging rings in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class BridgingRingsCount(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of bridging rings in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        ring_info = mol.GetRingInfo()\n        rings = ring_info.AtomRings()\n        bridging_rings = 0\n\n        for i in range(len(rings)):\n            for j in range(i + 1, len(rings)):\n                if len(set(rings[i]) &amp; set(rings[j])) &gt;= 2:\n                    bridging_rings += 1\n                    break\n\n        return np.array([bridging_rings])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"bridging_rings_count\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.FpDensityMorgan1","title":"<code>FpDensityMorgan1</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Calculates the density of the Morgan1 fingerprint.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class FpDensityMorgan1(GenericScalarFeaturizer):\n    \"\"\"\n    Calculates the density of the Morgan1 fingerprint.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.FpDensityMorgan1, \"fp_density_morgan1\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.FractionBicyclicRings","title":"<code>FractionBicyclicRings</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Calculates the fraction of bicyclic rings in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class FractionBicyclicRings(BaseFeatureCalculator):\n    \"\"\"\n    Calculates the fraction of bicyclic rings in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        ring_info = mol.GetRingInfo()\n        atom_rings = ring_info.AtomRings()\n        bicyclic_count = sum(\n            1\n            for i, ring1 in enumerate(atom_rings)\n            for ring2 in atom_rings[i + 1 :]\n            if set(ring1) &amp; set(ring2)\n        )\n        return np.array([bicyclic_count / len(atom_rings) if atom_rings else 0])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"fraction_bicyclic_rings\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.HalogenCounts","title":"<code>HalogenCounts</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of halogen atoms in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class HalogenCounts(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of halogen atoms in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        halogen_counts = {9: 0, 17: 0, 35: 0, 53: 0}  # F, Cl, Br, I\n        for atom in mol.GetAtoms():\n            atomic_num = atom.GetAtomicNum()\n            if atomic_num in halogen_counts:\n                halogen_counts[atomic_num] += 1\n\n        total_halogens = sum(halogen_counts.values())\n\n        return np.array(\n            [\n                total_halogens,\n                halogen_counts[9],\n                halogen_counts[17],\n                halogen_counts[35],\n                halogen_counts[53],\n            ]\n        )\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\n            \"total_halogens\",\n            \"fluorine_count\",\n            \"chlorine_count\",\n            \"bromine_count\",\n            \"iodine_count\",\n        ]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.HeteroatomCount","title":"<code>HeteroatomCount</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts heteroatoms (non-C, non-H) in heterocyclic rings.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class HeteroatomCount(BaseFeatureCalculator):\n    \"\"\"\n    Counts heteroatoms (non-C, non-H) in heterocyclic rings.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        return np.array([sum(1 for atom in mol.GetAtoms() if atom.GetAtomicNum() != 6)])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"heteroatom_count\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.HeteroatomDensity","title":"<code>HeteroatomDensity</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Density of heteroatoms in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class HeteroatomDensity(BaseFeatureCalculator):\n    \"\"\"\n    Density of heteroatoms in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        num_atoms = mol.GetNumAtoms()\n        num_heteroatoms = sum(1 for atom in mol.GetAtoms() if atom.GetAtomicNum() != 6)\n        return np.array([num_heteroatoms / num_atoms if num_atoms else 0])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"heteroatom_density\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.MaxEStateIndex","title":"<code>MaxEStateIndex</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Maximum electronic state index, reflecting charge distribution.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class MaxEStateIndex(GenericScalarFeaturizer):\n    \"\"\"\n    Maximum electronic state index, reflecting charge distribution.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.MaxEStateIndex, \"max_estate_index\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.MaxRingSize","title":"<code>MaxRingSize</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Calculates the size of the largest ring in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class MaxRingSize(BaseFeatureCalculator):\n    \"\"\"\n    Calculates the size of the largest ring in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        rings = mol.GetRingInfo().AtomRings()\n        return np.array([max(map(len, rings)) if rings else 0])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"max_ring_size\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.MolecularWeight","title":"<code>MolecularWeight</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Calculates the molecular weight of the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class MolecularWeight(GenericScalarFeaturizer):\n    \"\"\"\n    Calculates the molecular weight of the molecule.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.ExactMolWt, \"molecular_weight\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumAliphaticHeterocycles","title":"<code>NumAliphaticHeterocycles</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of aliphatic heterocycles in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumAliphaticHeterocycles(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of aliphatic heterocycles in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        num_heterocycles = 0\n        for ring in mol.GetRingInfo().AtomRings():\n            if any(mol.GetAtomWithIdx(atom).GetAtomicNum() != 6 for atom in ring):\n                num_heterocycles += 1\n        return np.array([num_heterocycles])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"num_aliphatic_heterocycles\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumAromaticRings","title":"<code>NumAromaticRings</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of aromatic rings in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumAromaticRings(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of aromatic rings in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        return np.array(\n            [\n                sum(\n                    1\n                    for ring in mol.GetRingInfo().AtomRings()\n                    if all(mol.GetAtomWithIdx(i).GetIsAromatic() for i in ring)\n                )\n            ]\n        )\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"num_aromatic_rings\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumAtoms","title":"<code>NumAtoms</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of atoms in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumAtoms(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of atoms in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = False) -&gt; np.ndarray:\n        return np.array([mol.GetNumAtoms()])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"num_atoms\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumHBondAcceptors","title":"<code>NumHBondAcceptors</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Counts Number of hydrogen bond acceptors.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumHBondAcceptors(GenericScalarFeaturizer):\n    \"\"\"\n    Counts Number of hydrogen bond acceptors.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.NumHAcceptors, \"num_hbond_acceptors\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumHBondDonors","title":"<code>NumHBondDonors</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Counts Number of hydrogen bond donors.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumHBondDonors(GenericScalarFeaturizer):\n    \"\"\"\n    Counts Number of hydrogen bond donors.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.NumHDonors, \"num_hbond_donors\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumNonAromaticRings","title":"<code>NumNonAromaticRings</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of non-aromatic rings in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumNonAromaticRings(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of non-aromatic rings in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        return np.array(\n            [\n                sum(\n                    1\n                    for ring in mol.GetRingInfo().AtomRings()\n                    if not all(mol.GetAtomWithIdx(i).GetIsAromatic() for i in ring)\n                )\n            ]\n        )\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"num_non_aromatic_rings\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumRings","title":"<code>NumRings</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of rings in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumRings(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of rings in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        return np.array([len(mol.GetRingInfo().AtomRings())])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"num_rings\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.NumRotatableBonds","title":"<code>NumRotatableBonds</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Counts Number of rotatable bonds.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class NumRotatableBonds(GenericScalarFeaturizer):\n    \"\"\"\n    Counts Number of rotatable bonds.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.NumRotatableBonds, \"num_rotatable_bonds\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.SlogPVSA1","title":"<code>SlogPVSA1</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Calculates the Surface area contributing to octanol solubility, linked to lipophilicity.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class SlogPVSA1(GenericScalarFeaturizer):\n    \"\"\"\n    Calculates the Surface area contributing to octanol solubility, linked to lipophilicity.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.SlogP_VSA1, \"slogp_vsa1\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.SmrVSA5","title":"<code>SmrVSA5</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Molar refractivity sum for atoms with specific surface area (2.45\u20132.75).</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class SmrVSA5(GenericScalarFeaturizer):\n    \"\"\"\n    Molar refractivity sum for atoms with specific surface area (2.45\u20132.75).\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.SMR_VSA5, \"smr_vsa5\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.Sp2CarbonCountFeaturizer","title":"<code>Sp2CarbonCountFeaturizer</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of sp2 hybridized carbon atoms in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class Sp2CarbonCountFeaturizer(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of sp2 hybridized carbon atoms in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        sp2_count = sum(\n            1\n            for atom in mol.GetAtoms()\n            if atom.GetHybridization() == Chem.HybridizationType.SP2\n        )\n        return np.array([sp2_count])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"sp2_carbon_count\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.Sp3CarbonCountFeaturizer","title":"<code>Sp3CarbonCountFeaturizer</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Counts the number of sp3 hybridized carbon atoms in the molecule.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class Sp3CarbonCountFeaturizer(BaseFeatureCalculator):\n    \"\"\"\n    Counts the number of sp3 hybridized carbon atoms in the molecule.\n    \"\"\"\n\n    def calculate(self, mol: Chem.Mol, sanitize: bool = True) -&gt; np.ndarray:\n        self._sanitize(mol, sanitize)\n        sp3_count = sum(\n            1\n            for atom in mol.GetAtoms()\n            if atom.GetHybridization() == Chem.HybridizationType.SP3\n        )\n        return np.array([sp3_count])\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"sp3_carbon_count\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.chemical_featurizer.TopologicalSurfaceArea","title":"<code>TopologicalSurfaceArea</code>","text":"<p>               Bases: <code>GenericScalarFeaturizer</code></p> <p>Calculates the topological polar surface area.</p> Source code in <code>src/polymetrix/featurizers/chemical_featurizer.py</code> <pre><code>class TopologicalSurfaceArea(GenericScalarFeaturizer):\n    \"\"\"\n    Calculates the topological polar surface area.\n    \"\"\"\n\n    def __init__(self, agg: List[str] = None):\n        super().__init__(Descriptors.TPSA, \"topological_surface_area\", agg=agg)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.comparator","title":"<code>comparator</code>","text":""},{"location":"api/#polymetrix.featurizers.comparator.PolymerMoleculeComparator","title":"<code>PolymerMoleculeComparator</code>","text":"<p>Comparator that computes various comparison metrics between polymer and molecule features.</p> Source code in <code>src/polymetrix/featurizers/comparator.py</code> <pre><code>class PolymerMoleculeComparator:\n    \"\"\"Comparator that computes various comparison metrics between polymer and molecule features.\"\"\"\n\n    comparators: ClassVar = {\n        \"absolute_difference\": lambda p, m: np.abs(p - m),\n        \"signed_difference\": lambda p, m: p - m,\n        \"product\": lambda p, m: p * m,\n        \"squared_distance\": lambda p, m: (p - m) ** 2,\n        \"euclidean_distance\": lambda p, m: np.sqrt((p - m) ** 2),\n    }\n\n    agg_funcs: ClassVar = {\n        \"mean\": np.mean,\n        \"min\": np.min,\n        \"max\": np.max,\n        \"sum\": np.sum,\n    }\n\n    def __init__(\n        self, polymer_featurizer, molecule_featurizer, comparisons=None, agg=None\n    ):\n        self.polymer_featurizer = polymer_featurizer\n        self.molecule_featurizer = molecule_featurizer\n        self.comparisons = (\n            comparisons if comparisons is not None else [\"absolute_difference\"]\n        )\n        self.agg = agg if agg is not None else []\n\n    def _concatenate_results(self, results):\n        return np.concatenate(results) if results else np.array([])\n\n    def compare(self, polymer, molecule):\n        \"\"\"Return comparison metrics between polymer and molecule features.\"\"\"\n        polymer_features = self.polymer_featurizer.featurize(polymer).flatten()\n        molecule_features = self.molecule_featurizer.featurize(molecule).flatten()\n\n        results = []\n        for comp_func in self.comparisons:\n            if comp_func not in self.comparators:\n                raise ValueError(f\"Unknown comparison function: {comp_func}\")\n            comparison_result = self.comparators[comp_func](\n                polymer_features, molecule_features\n            )\n            results.append(comparison_result)\n\n        if self.agg:\n            aggregated_results = self.aggregate(results)\n            results.append(aggregated_results)\n\n        return self._concatenate_results(results)\n\n    def aggregate(self, features):\n        \"\"\"Aggregate features across comparison methods.\"\"\"\n        results = []\n        for agg_func in self.agg:\n            if agg_func not in self.agg_funcs:\n                raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n            aggregated = self.agg_funcs[agg_func](features, axis=0)\n            results.append(aggregated)\n\n        return self._concatenate_results(results)\n\n    def _generate_labels(self, base_labels, suffix):\n        return [f\"{label}_{suffix}\" for label in base_labels]\n\n    def feature_labels(self):\n        \"\"\"Generate labels for comparison and aggregated features.\"\"\"\n        base_labels = self.polymer_featurizer.feature_labels()\n        labels = []\n\n        # Labels for comparison functions\n        for comp_func in self.comparisons:\n            labels.extend(self._generate_labels(base_labels, comp_func))\n\n        # Labels for aggregated results\n        if self.agg:\n            comparison_methods_str = \"_\".join(self.comparisons)\n            for agg_func in self.agg:\n                labels.extend(\n                    self._generate_labels(\n                        base_labels, f\"{comparison_methods_str}_{agg_func}\"\n                    )\n                )\n\n        return labels\n</code></pre>"},{"location":"api/#polymetrix.featurizers.comparator.PolymerMoleculeComparator.aggregate","title":"<code>aggregate(features)</code>","text":"<p>Aggregate features across comparison methods.</p> Source code in <code>src/polymetrix/featurizers/comparator.py</code> <pre><code>def aggregate(self, features):\n    \"\"\"Aggregate features across comparison methods.\"\"\"\n    results = []\n    for agg_func in self.agg:\n        if agg_func not in self.agg_funcs:\n            raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n        aggregated = self.agg_funcs[agg_func](features, axis=0)\n        results.append(aggregated)\n\n    return self._concatenate_results(results)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.comparator.PolymerMoleculeComparator.compare","title":"<code>compare(polymer, molecule)</code>","text":"<p>Return comparison metrics between polymer and molecule features.</p> Source code in <code>src/polymetrix/featurizers/comparator.py</code> <pre><code>def compare(self, polymer, molecule):\n    \"\"\"Return comparison metrics between polymer and molecule features.\"\"\"\n    polymer_features = self.polymer_featurizer.featurize(polymer).flatten()\n    molecule_features = self.molecule_featurizer.featurize(molecule).flatten()\n\n    results = []\n    for comp_func in self.comparisons:\n        if comp_func not in self.comparators:\n            raise ValueError(f\"Unknown comparison function: {comp_func}\")\n        comparison_result = self.comparators[comp_func](\n            polymer_features, molecule_features\n        )\n        results.append(comparison_result)\n\n    if self.agg:\n        aggregated_results = self.aggregate(results)\n        results.append(aggregated_results)\n\n    return self._concatenate_results(results)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.comparator.PolymerMoleculeComparator.feature_labels","title":"<code>feature_labels()</code>","text":"<p>Generate labels for comparison and aggregated features.</p> Source code in <code>src/polymetrix/featurizers/comparator.py</code> <pre><code>def feature_labels(self):\n    \"\"\"Generate labels for comparison and aggregated features.\"\"\"\n    base_labels = self.polymer_featurizer.feature_labels()\n    labels = []\n\n    # Labels for comparison functions\n    for comp_func in self.comparisons:\n        labels.extend(self._generate_labels(base_labels, comp_func))\n\n    # Labels for aggregated results\n    if self.agg:\n        comparison_methods_str = \"_\".join(self.comparisons)\n        for agg_func in self.agg:\n            labels.extend(\n                self._generate_labels(\n                    base_labels, f\"{comparison_methods_str}_{agg_func}\"\n                )\n            )\n\n    return labels\n</code></pre>"},{"location":"api/#polymetrix.featurizers.molecule","title":"<code>molecule</code>","text":""},{"location":"api/#polymetrix.featurizers.molecule.FullMolecularFeaturizer","title":"<code>FullMolecularFeaturizer</code>","text":"<p>               Bases: <code>MoleculeFeaturizer</code></p> <p>Featurizer for general molecules.</p> <p>This class can featurize any molecule from a Molecule object that contains a SMILES string and RDKit molecule object.</p> Source code in <code>src/polymetrix/featurizers/molecule.py</code> <pre><code>class FullMolecularFeaturizer(MoleculeFeaturizer):\n    \"\"\"Featurizer for general molecules.\n\n    This class can featurize any molecule from a Molecule object that contains\n    a SMILES string and RDKit molecule object.\n    \"\"\"\n\n    def featurize(self, molecule) -&gt; np.ndarray:\n        \"\"\"Featurize a molecule object.\n\n        Args:\n            molecule: A Molecule object with a mol property containing an RDKit molecule.\n\n        Returns:\n            np.ndarray: Feature vector calculated by the underlying calculator.\n        \"\"\"\n        if molecule.mol is None:\n            raise ValueError(\"Molecule object does not contain a valid RDKit molecule\")\n        return self.calculator.calculate(molecule.mol)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.molecule.FullMolecularFeaturizer.featurize","title":"<code>featurize(molecule)</code>","text":"<p>Featurize a molecule object.</p> <p>Parameters:</p> Name Type Description Default <code>molecule</code> <p>A Molecule object with a mol property containing an RDKit molecule.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Feature vector calculated by the underlying calculator.</p> Source code in <code>src/polymetrix/featurizers/molecule.py</code> <pre><code>def featurize(self, molecule) -&gt; np.ndarray:\n    \"\"\"Featurize a molecule object.\n\n    Args:\n        molecule: A Molecule object with a mol property containing an RDKit molecule.\n\n    Returns:\n        np.ndarray: Feature vector calculated by the underlying calculator.\n    \"\"\"\n    if molecule.mol is None:\n        raise ValueError(\"Molecule object does not contain a valid RDKit molecule\")\n    return self.calculator.calculate(molecule.mol)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.molecule.Molecule","title":"<code>Molecule</code>","text":"<p>A class to represent a general molecule from SMILES string.</p> <p>Attributes:</p> Name Type Description <code>smiles</code> <code>Optional[str]</code> <p>Optional[str], the SMILES string representing the molecule.</p> <code>mol</code> <code>Optional[Mol]</code> <p>Optional[Chem.Mol], the RDKit molecule object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided SMILES string is invalid or cannot be processed.</p> Source code in <code>src/polymetrix/featurizers/molecule.py</code> <pre><code>class Molecule:\n    \"\"\"A class to represent a general molecule from SMILES string.\n\n    Attributes:\n        smiles: Optional[str], the SMILES string representing the molecule.\n        mol: Optional[Chem.Mol], the RDKit molecule object.\n\n    Raises:\n        ValueError: If the provided SMILES string is invalid or cannot be processed.\n    \"\"\"\n\n    def __init__(self):\n        self._smiles: Optional[str] = None\n        self._mol: Optional[Chem.Mol] = None\n\n    @classmethod\n    def from_smiles(cls, smiles: str) -&gt; \"Molecule\":\n        \"\"\"Creates a Molecule instance from a SMILES string.\n\n        Args:\n            smiles: str, the SMILES string representing the molecule.\n\n        Returns:\n            Molecule: A new Molecule object initialized with the given SMILES string.\n\n        Raises:\n            ValueError: If the SMILES string is invalid.\n        \"\"\"\n        molecule = cls()\n        molecule.smiles = smiles\n        return molecule\n\n    @property\n    def smiles(self) -&gt; Optional[str]:\n        \"\"\"Gets the SMILES string of the molecule.\n\n        Returns:\n            Optional[str]: The SMILES string, or None if not set.\n        \"\"\"\n        return self._smiles\n\n    @smiles.setter\n    def smiles(self, value: str):\n        \"\"\"Sets the SMILES string and creates the RDKit molecule object.\n\n        Args:\n            value: str, the SMILES string to set.\n\n        Raises:\n            ValueError: If the SMILES string is invalid, cannot be processed, or contains polymer connection points (*).\n        \"\"\"\n        try:\n            # Check for asterisk atoms which indicate pSMILES (polymer SMILES)\n            if \"*\" in value:\n                raise ValueError(\n                    \"SMILES string contains asterisk atoms (*) which indicates a pSMILES string. Use Polymer.from_psmiles() instead for polymer molecules.\"\n                )\n\n            mol = Chem.MolFromSmiles(value)\n            if mol is None:\n                raise ValueError(\"Invalid SMILES string\")\n            self._smiles = value\n            self._mol = mol\n        except Exception as e:\n            raise ValueError(f\"Error processing SMILES: {str(e)}\") from e\n\n    @property\n    def mol(self) -&gt; Optional[Chem.Mol]:\n        \"\"\"Gets the RDKit molecule object.\n\n        Returns:\n            Optional[Chem.Mol]: The RDKit molecule object, or None if not set.\n        \"\"\"\n        return self._mol\n\n    def calculate_molecular_weight(self) -&gt; float:\n        \"\"\"Calculates the exact molecular weight of the molecule.\n\n        Returns:\n            float: The molecular weight of the molecule.\n        \"\"\"\n        if self._mol is None:\n            raise ValueError(\"No molecule set\")\n        return ExactMolWt(self._mol)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.molecule.Molecule.mol","title":"<code>mol</code>  <code>property</code>","text":"<p>Gets the RDKit molecule object.</p> <p>Returns:</p> Type Description <code>Optional[Mol]</code> <p>Optional[Chem.Mol]: The RDKit molecule object, or None if not set.</p>"},{"location":"api/#polymetrix.featurizers.molecule.Molecule.smiles","title":"<code>smiles</code>  <code>property</code> <code>writable</code>","text":"<p>Gets the SMILES string of the molecule.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Optional[str]: The SMILES string, or None if not set.</p>"},{"location":"api/#polymetrix.featurizers.molecule.Molecule.calculate_molecular_weight","title":"<code>calculate_molecular_weight()</code>","text":"<p>Calculates the exact molecular weight of the molecule.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The molecular weight of the molecule.</p> Source code in <code>src/polymetrix/featurizers/molecule.py</code> <pre><code>def calculate_molecular_weight(self) -&gt; float:\n    \"\"\"Calculates the exact molecular weight of the molecule.\n\n    Returns:\n        float: The molecular weight of the molecule.\n    \"\"\"\n    if self._mol is None:\n        raise ValueError(\"No molecule set\")\n    return ExactMolWt(self._mol)\n</code></pre>"},{"location":"api/#polymetrix.featurizers.molecule.Molecule.from_smiles","title":"<code>from_smiles(smiles)</code>  <code>classmethod</code>","text":"<p>Creates a Molecule instance from a SMILES string.</p> <p>Parameters:</p> Name Type Description Default <code>smiles</code> <code>str</code> <p>str, the SMILES string representing the molecule.</p> required <p>Returns:</p> Name Type Description <code>Molecule</code> <code>Molecule</code> <p>A new Molecule object initialized with the given SMILES string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the SMILES string is invalid.</p> Source code in <code>src/polymetrix/featurizers/molecule.py</code> <pre><code>@classmethod\ndef from_smiles(cls, smiles: str) -&gt; \"Molecule\":\n    \"\"\"Creates a Molecule instance from a SMILES string.\n\n    Args:\n        smiles: str, the SMILES string representing the molecule.\n\n    Returns:\n        Molecule: A new Molecule object initialized with the given SMILES string.\n\n    Raises:\n        ValueError: If the SMILES string is invalid.\n    \"\"\"\n    molecule = cls()\n    molecule.smiles = smiles\n    return molecule\n</code></pre>"},{"location":"api/#polymetrix.featurizers.multiple_featurizer","title":"<code>multiple_featurizer</code>","text":""},{"location":"api/#polymetrix.featurizers.multiple_featurizer.MultipleFeaturizer","title":"<code>MultipleFeaturizer</code>","text":"Source code in <code>src/polymetrix/featurizers/multiple_featurizer.py</code> <pre><code>class MultipleFeaturizer:\n    def __init__(self, featurizers: List[PolymerPartFeaturizer]):\n        self.featurizers = featurizers\n        self._last_polymer = None\n\n    def featurize(self, polymer) -&gt; np.ndarray:\n        self._last_polymer = polymer  # Store for label generation\n        features = []\n        for featurizer in self.featurizers:\n            feature = featurizer.featurize(polymer)\n            if isinstance(feature, (int, float)):\n                feature = np.array([feature])\n            features.append(feature.flatten())\n        return np.concatenate(features)\n\n    def feature_labels(self) -&gt; List[str]:\n        \"\"\"Return feature labels with '_with_terminalgroups' suffix when applicable.\"\"\"\n        labels = []\n        for featurizer in self.featurizers:\n            featurizer_labels = featurizer.feature_labels()\n            labels.extend(featurizer_labels)\n\n        # Add terminal groups suffix if last polymer had terminal groups\n        if (\n            hasattr(self, \"_last_polymer\")\n            and self._last_polymer\n            and (\n                (\n                    hasattr(self._last_polymer, \"backbone_terminal_groups\")\n                    and self._last_polymer.backbone_terminal_groups\n                )\n                or (\n                    hasattr(self._last_polymer, \"sidechain_terminal_groups\")\n                    and self._last_polymer.sidechain_terminal_groups\n                )\n            )\n        ):\n            labels = [\n                label.replace(\n                    \"_backbonefeaturizer\", \"_with_terminalgroups_backbonefeaturizer\"\n                )\n                .replace(\n                    \"_sidechainfeaturizer\", \"_with_terminalgroups_sidechainfeaturizer\"\n                )\n                .replace(\n                    \"_fullpolymerfeaturizer\",\n                    \"_with_terminalgroups_fullpolymerfeaturizer\",\n                )\n                for label in labels\n            ]\n\n        return labels\n\n    def citations(self) -&gt; List[str]:\n        citations = []\n        for featurizer in self.featurizers:\n            if hasattr(featurizer, \"calculator\") and featurizer.calculator:\n                citations.extend(featurizer.calculator.citations())\n        return list(set(citations))\n\n    def implementors(self) -&gt; List[str]:\n        implementors = []\n        for featurizer in self.featurizers:\n            if hasattr(featurizer, \"calculator\") and featurizer.calculator:\n                implementors.extend(featurizer.calculator.implementors())\n        return list(set(implementors))\n</code></pre>"},{"location":"api/#polymetrix.featurizers.multiple_featurizer.MultipleFeaturizer.feature_labels","title":"<code>feature_labels()</code>","text":"<p>Return feature labels with '_with_terminalgroups' suffix when applicable.</p> Source code in <code>src/polymetrix/featurizers/multiple_featurizer.py</code> <pre><code>def feature_labels(self) -&gt; List[str]:\n    \"\"\"Return feature labels with '_with_terminalgroups' suffix when applicable.\"\"\"\n    labels = []\n    for featurizer in self.featurizers:\n        featurizer_labels = featurizer.feature_labels()\n        labels.extend(featurizer_labels)\n\n    # Add terminal groups suffix if last polymer had terminal groups\n    if (\n        hasattr(self, \"_last_polymer\")\n        and self._last_polymer\n        and (\n            (\n                hasattr(self._last_polymer, \"backbone_terminal_groups\")\n                and self._last_polymer.backbone_terminal_groups\n            )\n            or (\n                hasattr(self._last_polymer, \"sidechain_terminal_groups\")\n                and self._last_polymer.sidechain_terminal_groups\n            )\n        )\n    ):\n        labels = [\n            label.replace(\n                \"_backbonefeaturizer\", \"_with_terminalgroups_backbonefeaturizer\"\n            )\n            .replace(\n                \"_sidechainfeaturizer\", \"_with_terminalgroups_sidechainfeaturizer\"\n            )\n            .replace(\n                \"_fullpolymerfeaturizer\",\n                \"_with_terminalgroups_fullpolymerfeaturizer\",\n            )\n            for label in labels\n        ]\n\n    return labels\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer","title":"<code>polymer</code>","text":""},{"location":"api/#polymetrix.featurizers.polymer.Polymer","title":"<code>Polymer</code>","text":"<p>Represents a polymer molecule with its backbone and sidechain information.</p> <p>Attributes:</p> Name Type Description <code>psmiles</code> <code>Optional[str]</code> <p>Optional[str], the pSMILES string of the polymer.</p> <code>backbone_terminal_groups</code> <code>Optional[Dict[str, str]]</code> <p>Optional[Dict[str, str]], maps connection point patterns to backbone terminal group SMILES.</p> <code>sidechain_terminal_groups</code> <code>Optional[Dict[str, str]]</code> <p>Optional[Dict[str, str]], maps connection point patterns to sidechain terminal group SMILES.</p> <code>graph</code> <p>Optional[nx.Graph], the NetworkX graph of the polymer structure.</p> <code>backbone_nodes</code> <p>Optional[List[int]], node indices forming the backbone.</p> <code>sidechain_nodes</code> <p>Optional[List[int]], node indices forming the sidechains.</p> <code>connection_points</code> <p>Optional[List[int]], node indices of connection points.</p> <code>_mol</code> <p>Optional[Chem.Mol], the RDKit molecule object (internal use).</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>class Polymer:\n    \"\"\"Represents a polymer molecule with its backbone and sidechain information.\n\n    Attributes:\n        psmiles: Optional[str], the pSMILES string of the polymer.\n        backbone_terminal_groups: Optional[Dict[str, str]], maps connection point patterns to backbone terminal group SMILES.\n        sidechain_terminal_groups: Optional[Dict[str, str]], maps connection point patterns to sidechain terminal group SMILES.\n        graph: Optional[nx.Graph], the NetworkX graph of the polymer structure.\n        backbone_nodes: Optional[List[int]], node indices forming the backbone.\n        sidechain_nodes: Optional[List[int]], node indices forming the sidechains.\n        connection_points: Optional[List[int]], node indices of connection points.\n        _mol: Optional[Chem.Mol], the RDKit molecule object (internal use).\n    \"\"\"\n\n    def __init__(self):\n        self._psmiles = None\n        self._backbone_terminal_groups = None\n        self._sidechain_terminal_groups = None\n        self.graph = None\n        self.backbone_nodes = None\n        self.sidechain_nodes = None\n        self.connection_points = None\n        self._mol = None\n\n    @property\n    def mol(self) -&gt; Optional[Chem.Mol]:\n        \"\"\"Returns the full polymer molecule, compatible with featurizers expecting a 'mol' attribute.\"\"\"\n        return self.full_polymer_mol\n\n    @classmethod\n    def from_psmiles(cls, psmiles: str) -&gt; \"Polymer\":\n        \"\"\"Creates a Polymer instance from a pSMILES string.\n\n        Args:\n            psmiles: The pSMILES string representing the polymer.\n\n        Returns:\n            A new Polymer instance.\n\n        Raises:\n            ValueError: If the pSMILES string is invalid.\n        \"\"\"\n        polymer = cls()\n        polymer.psmiles = psmiles\n        return polymer\n\n    @property\n    def psmiles(self) -&gt; Optional[str]:\n        \"\"\"The pSMILES string of the polymer.\"\"\"\n        return self._psmiles\n\n    @psmiles.setter\n    def psmiles(self, value: str):\n        \"\"\"Sets the pSMILES string and updates the polymer's structure.\n\n        Args:\n            value: The pSMILES string to set.\n\n        Raises:\n            ValueError: If the pSMILES string is None, empty, or invalid.\n        \"\"\"\n        if not value or not isinstance(value, str):\n            raise ValueError(\"pSMILES cannot be None or empty\")\n        try:\n            mol = Chem.MolFromSmiles(value)\n            if mol is None:\n                raise ValueError(\"Invalid pSMILES string\")\n            self._psmiles = value\n            self._mol = mol\n            self.graph = self._mol_to_nx(mol)\n            self._identify_connection_points()\n            self._identify_backbone_and_sidechain()\n        except Exception as e:\n            raise ValueError(f\"Error processing pSMILES: {str(e)}\") from e\n\n    @property\n    def backbone_terminal_groups(self) -&gt; Optional[Dict[str, str]]:\n        \"\"\"Maps connection point patterns to backbone terminal group SMILES.\"\"\"\n        return self._backbone_terminal_groups\n\n    @backbone_terminal_groups.setter\n    def backbone_terminal_groups(self, value: Dict[str, str]):\n        \"\"\"Sets terminal groups for backbone connection points.\"\"\"\n        self._backbone_terminal_groups = value\n\n    @property\n    def sidechain_terminal_groups(self) -&gt; Optional[Dict[str, str]]:\n        \"\"\"Maps connection point patterns to sidechain terminal group SMILES.\"\"\"\n        return self._sidechain_terminal_groups\n\n    @sidechain_terminal_groups.setter\n    def sidechain_terminal_groups(self, value: Dict[str, str]):\n        \"\"\"Sets terminal groups for sidechain connection points.\"\"\"\n        self._sidechain_terminal_groups = value\n\n    @staticmethod\n    def _mol_to_nx(mol: Chem.Mol) -&gt; nx.Graph:\n        \"\"\"Converts an RDKit molecule to a NetworkX graph.\n\n        Args:\n            mol: The RDKit molecule to convert.\n\n        Returns:\n            A NetworkX graph representing the molecule's structure.\n        \"\"\"\n        G = nx.Graph()\n        for atom in mol.GetAtoms():\n            G.add_node(\n                atom.GetIdx(),\n                atomic_num=atom.GetAtomicNum(),\n                element=atom.GetSymbol(),\n                formal_charge=atom.GetFormalCharge(),\n                is_aromatic=atom.GetIsAromatic(),\n            )\n        for bond in mol.GetBonds():\n            G.add_edge(\n                bond.GetBeginAtomIdx(),\n                bond.GetEndAtomIdx(),\n                bond_type=bond.GetBondType(),\n                is_aromatic=bond.GetIsAromatic(),\n            )\n        return G\n\n    def _identify_connection_points(self):\n        \"\"\"Identifies connection points (asterisk atoms) in the polymer graph.\"\"\"\n        self.connection_points = [\n            node for node, data in self.graph.nodes(data=True) if data[\"element\"] == \"*\"\n        ]\n\n    def _identify_backbone_and_sidechain(self):\n        \"\"\"Classifies nodes into backbone and sidechain components.\"\"\"\n        self.backbone_nodes, self.sidechain_nodes = classify_backbone_and_sidechains(\n            self.graph\n        )\n\n    @property\n    def backbone_molecule(self) -&gt; Chem.Mol:\n        \"\"\"Gets the backbone molecule.\"\"\"\n        return self._get_backbone_molecule(include_terminal_groups=True)\n\n    def _get_backbone_molecule(self, include_terminal_groups: bool = True) -&gt; Chem.Mol:\n        \"\"\"Internal method to get backbone molecule with optional terminal groups.\"\"\"\n        backbone_mol = self._extract_substructure_mol(self.backbone_nodes)\n        if include_terminal_groups and self._backbone_terminal_groups:\n            backbone_mol = insert_terminal_group(\n                backbone_mol, self._backbone_terminal_groups, is_sidechain=False\n            )\n        return backbone_mol\n\n    @property\n    def sidechain_molecules(self) -&gt; List[Chem.Mol]:\n        \"\"\"Gets the sidechain molecules.\"\"\"\n        return self._get_sidechain_molecules(include_terminal_groups=True)\n\n    def _get_sidechain_molecules(\n        self, include_terminal_groups: bool = True\n    ) -&gt; List[Chem.Mol]:\n        \"\"\"Internal method to get sidechain molecules with optional terminal groups.\"\"\"\n        sidechain_components = list(\n            nx.connected_components(self.graph.subgraph(self.sidechain_nodes))\n        )\n        sidechain_mols = []\n        for component_nodes in sidechain_components:\n            mol = self._extract_substructure_mol(list(component_nodes))\n            if include_terminal_groups and self._sidechain_terminal_groups:\n                mol = insert_terminal_group(\n                    mol, self._sidechain_terminal_groups, is_sidechain=True\n                )\n            sidechain_mols.append(mol)\n        return sidechain_mols\n\n    @property\n    def full_polymer_mol(self) -&gt; Chem.Mol:\n        \"\"\"Gets the full polymer molecule.\"\"\"\n        return self._get_full_polymer_mol(include_terminal_groups=True)\n\n    def _get_full_polymer_mol(self, include_terminal_groups: bool = True) -&gt; Chem.Mol:\n        \"\"\"Internal method to get full polymer molecule with optional terminal groups.\"\"\"\n        if include_terminal_groups and self._backbone_terminal_groups:\n            return insert_terminal_group(\n                self._mol, self._backbone_terminal_groups, is_sidechain=False\n            )\n        return self._mol\n\n    def _extract_substructure_mol(self, node_indices: List[int]) -&gt; Chem.Mol:\n        \"\"\"Extracts a substructure molecule from the main molecule using node indices.\"\"\"\n        if not node_indices:\n            return Chem.MolFromSmiles(\"\")\n        mol = RWMol()\n        old_to_new_idx = {}\n        for old_idx in node_indices:\n            atom = self._mol.GetAtomWithIdx(old_idx)\n            new_atom = Atom(atom.GetAtomicNum())\n            new_atom.SetFormalCharge(atom.GetFormalCharge())\n            if atom.GetIsAromatic():\n                new_atom.SetIsAromatic(True)\n            new_idx = mol.AddAtom(new_atom)\n            old_to_new_idx[old_idx] = new_idx\n        for bond in self._mol.GetBonds():\n            begin_idx = bond.GetBeginAtomIdx()\n            end_idx = bond.GetEndAtomIdx()\n            if begin_idx in old_to_new_idx and end_idx in old_to_new_idx:\n                mol.AddBond(\n                    old_to_new_idx[begin_idx],\n                    old_to_new_idx[end_idx],\n                    bond.GetBondType(),\n                )\n        return mol.GetMol()\n\n    def get_backbone_and_sidechain_molecules(\n        self,\n    ) -&gt; Tuple[List[Chem.Mol], List[Chem.Mol]]:\n        \"\"\"Extracts RDKit molecules for the backbone and sidechains.\n\n        Returns:\n            A tuple of (list of backbone molecules, list of sidechain molecules).\n        \"\"\"\n        return [self.backbone_molecule], self.sidechain_molecules\n\n    def get_backbone_and_sidechain_graphs(self) -&gt; Tuple[nx.Graph, List[nx.Graph]]:\n        \"\"\"Extracts NetworkX graphs for the backbone and sidechains.\n\n        Returns:\n            A tuple of (backbone graph, list of sidechain graphs).\n        \"\"\"\n        backbone_graph = self.graph.subgraph(self.backbone_nodes)\n        sidechain_graphs = [\n            self.graph.subgraph(nodes)\n            for nodes in nx.connected_components(\n                self.graph.subgraph(self.sidechain_nodes)\n            )\n        ]\n        return backbone_graph, sidechain_graphs\n\n    def calculate_molecular_weight(self) -&gt; float:\n        \"\"\"Calculates the exact molecular weight of the polymer.\n\n        Returns:\n            The molecular weight of the polymer.\n        \"\"\"\n        return ExactMolWt(self._mol) if self._mol else 0.0\n\n    def get_connection_points(self) -&gt; List[int]:\n        \"\"\"Gets the connection point node indices.\n\n        Returns:\n            List of node indices representing connection points.\n        \"\"\"\n        return self.connection_points\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.backbone_molecule","title":"<code>backbone_molecule</code>  <code>property</code>","text":"<p>Gets the backbone molecule.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.backbone_terminal_groups","title":"<code>backbone_terminal_groups</code>  <code>property</code> <code>writable</code>","text":"<p>Maps connection point patterns to backbone terminal group SMILES.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.full_polymer_mol","title":"<code>full_polymer_mol</code>  <code>property</code>","text":"<p>Gets the full polymer molecule.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.mol","title":"<code>mol</code>  <code>property</code>","text":"<p>Returns the full polymer molecule, compatible with featurizers expecting a 'mol' attribute.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.psmiles","title":"<code>psmiles</code>  <code>property</code> <code>writable</code>","text":"<p>The pSMILES string of the polymer.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.sidechain_molecules","title":"<code>sidechain_molecules</code>  <code>property</code>","text":"<p>Gets the sidechain molecules.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.sidechain_terminal_groups","title":"<code>sidechain_terminal_groups</code>  <code>property</code> <code>writable</code>","text":"<p>Maps connection point patterns to sidechain terminal group SMILES.</p>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._extract_substructure_mol","title":"<code>_extract_substructure_mol(node_indices)</code>","text":"<p>Extracts a substructure molecule from the main molecule using node indices.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def _extract_substructure_mol(self, node_indices: List[int]) -&gt; Chem.Mol:\n    \"\"\"Extracts a substructure molecule from the main molecule using node indices.\"\"\"\n    if not node_indices:\n        return Chem.MolFromSmiles(\"\")\n    mol = RWMol()\n    old_to_new_idx = {}\n    for old_idx in node_indices:\n        atom = self._mol.GetAtomWithIdx(old_idx)\n        new_atom = Atom(atom.GetAtomicNum())\n        new_atom.SetFormalCharge(atom.GetFormalCharge())\n        if atom.GetIsAromatic():\n            new_atom.SetIsAromatic(True)\n        new_idx = mol.AddAtom(new_atom)\n        old_to_new_idx[old_idx] = new_idx\n    for bond in self._mol.GetBonds():\n        begin_idx = bond.GetBeginAtomIdx()\n        end_idx = bond.GetEndAtomIdx()\n        if begin_idx in old_to_new_idx and end_idx in old_to_new_idx:\n            mol.AddBond(\n                old_to_new_idx[begin_idx],\n                old_to_new_idx[end_idx],\n                bond.GetBondType(),\n            )\n    return mol.GetMol()\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._get_backbone_molecule","title":"<code>_get_backbone_molecule(include_terminal_groups=True)</code>","text":"<p>Internal method to get backbone molecule with optional terminal groups.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def _get_backbone_molecule(self, include_terminal_groups: bool = True) -&gt; Chem.Mol:\n    \"\"\"Internal method to get backbone molecule with optional terminal groups.\"\"\"\n    backbone_mol = self._extract_substructure_mol(self.backbone_nodes)\n    if include_terminal_groups and self._backbone_terminal_groups:\n        backbone_mol = insert_terminal_group(\n            backbone_mol, self._backbone_terminal_groups, is_sidechain=False\n        )\n    return backbone_mol\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._get_full_polymer_mol","title":"<code>_get_full_polymer_mol(include_terminal_groups=True)</code>","text":"<p>Internal method to get full polymer molecule with optional terminal groups.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def _get_full_polymer_mol(self, include_terminal_groups: bool = True) -&gt; Chem.Mol:\n    \"\"\"Internal method to get full polymer molecule with optional terminal groups.\"\"\"\n    if include_terminal_groups and self._backbone_terminal_groups:\n        return insert_terminal_group(\n            self._mol, self._backbone_terminal_groups, is_sidechain=False\n        )\n    return self._mol\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._get_sidechain_molecules","title":"<code>_get_sidechain_molecules(include_terminal_groups=True)</code>","text":"<p>Internal method to get sidechain molecules with optional terminal groups.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def _get_sidechain_molecules(\n    self, include_terminal_groups: bool = True\n) -&gt; List[Chem.Mol]:\n    \"\"\"Internal method to get sidechain molecules with optional terminal groups.\"\"\"\n    sidechain_components = list(\n        nx.connected_components(self.graph.subgraph(self.sidechain_nodes))\n    )\n    sidechain_mols = []\n    for component_nodes in sidechain_components:\n        mol = self._extract_substructure_mol(list(component_nodes))\n        if include_terminal_groups and self._sidechain_terminal_groups:\n            mol = insert_terminal_group(\n                mol, self._sidechain_terminal_groups, is_sidechain=True\n            )\n        sidechain_mols.append(mol)\n    return sidechain_mols\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._identify_backbone_and_sidechain","title":"<code>_identify_backbone_and_sidechain()</code>","text":"<p>Classifies nodes into backbone and sidechain components.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def _identify_backbone_and_sidechain(self):\n    \"\"\"Classifies nodes into backbone and sidechain components.\"\"\"\n    self.backbone_nodes, self.sidechain_nodes = classify_backbone_and_sidechains(\n        self.graph\n    )\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._identify_connection_points","title":"<code>_identify_connection_points()</code>","text":"<p>Identifies connection points (asterisk atoms) in the polymer graph.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def _identify_connection_points(self):\n    \"\"\"Identifies connection points (asterisk atoms) in the polymer graph.\"\"\"\n    self.connection_points = [\n        node for node, data in self.graph.nodes(data=True) if data[\"element\"] == \"*\"\n    ]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer._mol_to_nx","title":"<code>_mol_to_nx(mol)</code>  <code>staticmethod</code>","text":"<p>Converts an RDKit molecule to a NetworkX graph.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Mol</code> <p>The RDKit molecule to convert.</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>A NetworkX graph representing the molecule's structure.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>@staticmethod\ndef _mol_to_nx(mol: Chem.Mol) -&gt; nx.Graph:\n    \"\"\"Converts an RDKit molecule to a NetworkX graph.\n\n    Args:\n        mol: The RDKit molecule to convert.\n\n    Returns:\n        A NetworkX graph representing the molecule's structure.\n    \"\"\"\n    G = nx.Graph()\n    for atom in mol.GetAtoms():\n        G.add_node(\n            atom.GetIdx(),\n            atomic_num=atom.GetAtomicNum(),\n            element=atom.GetSymbol(),\n            formal_charge=atom.GetFormalCharge(),\n            is_aromatic=atom.GetIsAromatic(),\n        )\n    for bond in mol.GetBonds():\n        G.add_edge(\n            bond.GetBeginAtomIdx(),\n            bond.GetEndAtomIdx(),\n            bond_type=bond.GetBondType(),\n            is_aromatic=bond.GetIsAromatic(),\n        )\n    return G\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.calculate_molecular_weight","title":"<code>calculate_molecular_weight()</code>","text":"<p>Calculates the exact molecular weight of the polymer.</p> <p>Returns:</p> Type Description <code>float</code> <p>The molecular weight of the polymer.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def calculate_molecular_weight(self) -&gt; float:\n    \"\"\"Calculates the exact molecular weight of the polymer.\n\n    Returns:\n        The molecular weight of the polymer.\n    \"\"\"\n    return ExactMolWt(self._mol) if self._mol else 0.0\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.from_psmiles","title":"<code>from_psmiles(psmiles)</code>  <code>classmethod</code>","text":"<p>Creates a Polymer instance from a pSMILES string.</p> <p>Parameters:</p> Name Type Description Default <code>psmiles</code> <code>str</code> <p>The pSMILES string representing the polymer.</p> required <p>Returns:</p> Type Description <code>Polymer</code> <p>A new Polymer instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the pSMILES string is invalid.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>@classmethod\ndef from_psmiles(cls, psmiles: str) -&gt; \"Polymer\":\n    \"\"\"Creates a Polymer instance from a pSMILES string.\n\n    Args:\n        psmiles: The pSMILES string representing the polymer.\n\n    Returns:\n        A new Polymer instance.\n\n    Raises:\n        ValueError: If the pSMILES string is invalid.\n    \"\"\"\n    polymer = cls()\n    polymer.psmiles = psmiles\n    return polymer\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.get_backbone_and_sidechain_graphs","title":"<code>get_backbone_and_sidechain_graphs()</code>","text":"<p>Extracts NetworkX graphs for the backbone and sidechains.</p> <p>Returns:</p> Type Description <code>Tuple[Graph, List[Graph]]</code> <p>A tuple of (backbone graph, list of sidechain graphs).</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def get_backbone_and_sidechain_graphs(self) -&gt; Tuple[nx.Graph, List[nx.Graph]]:\n    \"\"\"Extracts NetworkX graphs for the backbone and sidechains.\n\n    Returns:\n        A tuple of (backbone graph, list of sidechain graphs).\n    \"\"\"\n    backbone_graph = self.graph.subgraph(self.backbone_nodes)\n    sidechain_graphs = [\n        self.graph.subgraph(nodes)\n        for nodes in nx.connected_components(\n            self.graph.subgraph(self.sidechain_nodes)\n        )\n    ]\n    return backbone_graph, sidechain_graphs\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.get_backbone_and_sidechain_molecules","title":"<code>get_backbone_and_sidechain_molecules()</code>","text":"<p>Extracts RDKit molecules for the backbone and sidechains.</p> <p>Returns:</p> Type Description <code>Tuple[List[Mol], List[Mol]]</code> <p>A tuple of (list of backbone molecules, list of sidechain molecules).</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def get_backbone_and_sidechain_molecules(\n    self,\n) -&gt; Tuple[List[Chem.Mol], List[Chem.Mol]]:\n    \"\"\"Extracts RDKit molecules for the backbone and sidechains.\n\n    Returns:\n        A tuple of (list of backbone molecules, list of sidechain molecules).\n    \"\"\"\n    return [self.backbone_molecule], self.sidechain_molecules\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.Polymer.get_connection_points","title":"<code>get_connection_points()</code>","text":"<p>Gets the connection point node indices.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List of node indices representing connection points.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def get_connection_points(self) -&gt; List[int]:\n    \"\"\"Gets the connection point node indices.\n\n    Returns:\n        List of node indices representing connection points.\n    \"\"\"\n    return self.connection_points\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.add_degree_one_nodes_to_backbone","title":"<code>add_degree_one_nodes_to_backbone(graph, backbone)</code>","text":"<p>Adds degree-1 nodes connected to backbone nodes to the backbone list, avoiding duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The input graph to analyze.</p> required <code>backbone</code> <code>List[int]</code> <p>Initial list of backbone node indices.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>Updated backbone list including degree-1 nodes, with no duplicates.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def add_degree_one_nodes_to_backbone(graph: nx.Graph, backbone: List[int]) -&gt; List[int]:\n    \"\"\"Adds degree-1 nodes connected to backbone nodes to the backbone list, avoiding duplicates.\n\n    Args:\n        graph: The input graph to analyze.\n        backbone: Initial list of backbone node indices.\n\n    Returns:\n        Updated backbone list including degree-1 nodes, with no duplicates.\n    \"\"\"\n    for node in graph.nodes:\n        if graph.degree[node] == 1 and node not in backbone:\n            neighbor = next(iter(graph.neighbors(node)))\n            if neighbor in backbone:\n                backbone.append(node)\n    return backbone\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.attach_terminal_to_atom","title":"<code>attach_terminal_to_atom(mol, target_idx, terminal_mol, attachment_idx=None)</code>","text":"<p>Attaches a terminal group to a specific atom in the molecule.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>RWMol</code> <p>The molecule being modified.</p> required <code>target_idx</code> <code>int</code> <p>Index of the target atom to attach the terminal group.</p> required <code>terminal_mol</code> <code>Mol</code> <p>The terminal group molecule.</p> required <code>attachment_idx</code> <code>int</code> <p>Index of the attachment point in the terminal group (optional for sidechains).</p> <code>None</code> <p>Returns:</p> Type Description <code>RWMol</code> <p>The modified molecule.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def attach_terminal_to_atom(\n    mol: RWMol,\n    target_idx: int,\n    terminal_mol: Chem.Mol,\n    attachment_idx: int = None,\n) -&gt; RWMol:\n    \"\"\"Attaches a terminal group to a specific atom in the molecule.\n\n    Args:\n        mol: The molecule being modified.\n        target_idx: Index of the target atom to attach the terminal group.\n        terminal_mol: The terminal group molecule.\n        attachment_idx: Index of the attachment point in the terminal group (optional for sidechains).\n\n    Returns:\n        The modified molecule.\n    \"\"\"\n    atom_mapping = {}\n    for atom in terminal_mol.GetAtoms():\n        new_atom = Atom(atom.GetAtomicNum())\n        new_atom.SetFormalCharge(atom.GetFormalCharge())\n        new_idx = mol.AddAtom(new_atom)\n        atom_mapping[atom.GetIdx()] = new_idx\n    for bond in terminal_mol.GetBonds():\n        begin_idx = bond.GetBeginAtomIdx()\n        end_idx = bond.GetEndAtomIdx()\n        if begin_idx in atom_mapping and end_idx in atom_mapping:\n            mol.AddBond(\n                atom_mapping[begin_idx], atom_mapping[end_idx], bond.GetBondType()\n            )\n    first_terminal_atom_idx = next(iter(atom_mapping.keys()))\n    mol.AddBond(target_idx, atom_mapping[first_terminal_atom_idx], Chem.BondType.SINGLE)\n    return mol\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.classify_backbone_and_sidechains","title":"<code>classify_backbone_and_sidechains(graph)</code>","text":"<p>Classifies nodes into backbone and sidechain components based on paths and cycles.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The input graph to classify.</p> required <p>Returns:</p> Type Description <code>Tuple[List[int], List[int]]</code> <p>A tuple of (backbone nodes, sidechain nodes).</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def classify_backbone_and_sidechains(graph: nx.Graph) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"Classifies nodes into backbone and sidechain components based on paths and cycles.\n\n    Args:\n        graph: The input graph to classify.\n\n    Returns:\n        A tuple of (backbone nodes, sidechain nodes).\n    \"\"\"\n    shortest_paths = find_shortest_paths_between_stars(graph)\n    cycles = find_cycles_including_paths(graph, shortest_paths)\n    backbone_nodes = set()\n    for cycle in cycles:\n        backbone_nodes.update(cycle)\n    for path in shortest_paths:\n        backbone_nodes.update(path)\n    backbone_nodes = add_degree_one_nodes_to_backbone(graph, list(backbone_nodes))\n    sidechain_nodes = [node for node in graph.nodes if node not in backbone_nodes]\n    return list(backbone_nodes), sidechain_nodes\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.find_cycles_including_paths","title":"<code>find_cycles_including_paths(graph, paths)</code>","text":"<p>Identifies cycles that include nodes from the given paths.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The input graph to analyze.</p> required <code>paths</code> <code>List[List[int]]</code> <p>List of paths whose nodes are used to filter cycles.</p> required <p>Returns:</p> Type Description <code>List[List[int]]</code> <p>List of cycles, where each cycle is a list of node indices.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def find_cycles_including_paths(\n    graph: nx.Graph, paths: List[List[int]]\n) -&gt; List[List[int]]:\n    \"\"\"Identifies cycles that include nodes from the given paths.\n\n    Args:\n        graph: The input graph to analyze.\n        paths: List of paths whose nodes are used to filter cycles.\n\n    Returns:\n        List of cycles, where each cycle is a list of node indices.\n    \"\"\"\n    all_cycles = nx.cycle_basis(graph)\n    path_nodes = {node for path in paths for node in path}\n    return [cycle for cycle in all_cycles if any(node in path_nodes for node in cycle)]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.find_shortest_paths_between_stars","title":"<code>find_shortest_paths_between_stars(graph)</code>","text":"<p>Finds shortest paths between all pairs of asterisk (*) nodes in the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The input graph to analyze.</p> required <p>Returns:</p> Type Description <code>List[List[int]]</code> <p>List of shortest paths, where each path is a list of node indices.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def find_shortest_paths_between_stars(graph: nx.Graph) -&gt; List[List[int]]:\n    \"\"\"Finds shortest paths between all pairs of asterisk (*) nodes in the graph.\n\n    Args:\n        graph: The input graph to analyze.\n\n    Returns:\n        List of shortest paths, where each path is a list of node indices.\n    \"\"\"\n    star_nodes = [\n        node for node, data in graph.nodes(data=True) if data[\"element\"] == \"*\"\n    ]\n    shortest_paths = []\n    for i in range(len(star_nodes)):\n        for j in range(i + 1, len(star_nodes)):\n            try:\n                path = nx.shortest_path(\n                    graph, source=star_nodes[i], target=star_nodes[j]\n                )\n                shortest_paths.append(path)\n            except nx.NetworkXNoPath:\n                continue\n    return shortest_paths\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.insert_terminal_group","title":"<code>insert_terminal_group(mol, terminal_groups, is_sidechain=False)</code>","text":"<p>Inserts terminal groups into a molecule by replacing connection points or attaching to sidechains.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Mol</code> <p>The RDKit molecule to modify.</p> required <code>terminal_groups</code> <code>Dict[str, str]</code> <p>Dictionary mapping patterns to terminal group SMILES.</p> required <code>is_sidechain</code> <code>bool</code> <p>If True, attach terminal groups to sidechains; else, replace backbone connection points.</p> <code>False</code> <p>Returns:</p> Type Description <code>Mol</code> <p>A new RDKit molecule with terminal groups inserted.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def insert_terminal_group(\n    mol: Chem.Mol, terminal_groups: Dict[str, str], is_sidechain: bool = False\n) -&gt; Chem.Mol:\n    \"\"\"Inserts terminal groups into a molecule by replacing connection points or attaching to sidechains.\n\n    Args:\n        mol: The RDKit molecule to modify.\n        terminal_groups: Dictionary mapping patterns to terminal group SMILES.\n        is_sidechain: If True, attach terminal groups to sidechains; else, replace backbone connection points.\n\n    Returns:\n        A new RDKit molecule with terminal groups inserted.\n    \"\"\"\n    if not terminal_groups:\n        return mol\n\n    mol_copy = RWMol(mol)\n\n    if is_sidechain:\n        for pattern, terminal_smiles in terminal_groups.items():\n            terminal_mol = Chem.MolFromSmiles(\n                terminal_smiles.replace(\"*\", \"\")\n            )  # Remove asterisk for attachment\n            if terminal_mol is None:\n                logging.warning(f\"Invalid terminal group SMILES '{terminal_smiles}'\")\n                continue\n            target_idx = 0  # Attach to the first atom of the sidechain\n            mol_copy = attach_terminal_to_atom(\n                mol_copy, target_idx, terminal_mol, attachment_idx=None\n            )\n    else:\n        asterisk_atoms = [\n            atom.GetIdx() for atom in mol_copy.GetAtoms() if atom.GetSymbol() == \"*\"\n        ]\n        for pattern, terminal_smiles in terminal_groups.items():\n            if pattern == \"[*]\":\n                terminal_mol = Chem.MolFromSmiles(terminal_smiles)\n                if terminal_mol is None:\n                    logging.warning(\n                        f\"Invalid terminal group SMILES '{terminal_smiles}'\"\n                    )\n                    continue\n                attachment_idx = None\n                for atom in terminal_mol.GetAtoms():\n                    if atom.GetSymbol() == \"*\":\n                        attachment_idx = atom.GetIdx()\n                        break\n                if attachment_idx is None:\n                    logging.warning(\n                        f\"No attachment point (*) found in terminal group '{terminal_smiles}'\"\n                    )\n                    continue\n                for ast_idx in sorted(asterisk_atoms, reverse=True):\n                    mol_copy = replace_asterisk_with_terminal(\n                        mol_copy, ast_idx, terminal_mol, attachment_idx\n                    )\n\n    return mol_copy.GetMol()\n</code></pre>"},{"location":"api/#polymetrix.featurizers.polymer.replace_asterisk_with_terminal","title":"<code>replace_asterisk_with_terminal(mol, asterisk_idx, terminal_mol, attachment_idx)</code>","text":"<p>Replaces a single asterisk atom with a terminal group.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>RWMol</code> <p>The molecule being modified.</p> required <code>asterisk_idx</code> <code>int</code> <p>Index of the asterisk atom to replace.</p> required <code>terminal_mol</code> <code>Mol</code> <p>The terminal group molecule.</p> required <code>attachment_idx</code> <code>int</code> <p>Index of the attachment point in the terminal group.</p> required <p>Returns:</p> Type Description <code>RWMol</code> <p>The modified molecule.</p> Source code in <code>src/polymetrix/featurizers/polymer.py</code> <pre><code>def replace_asterisk_with_terminal(\n    mol: RWMol, asterisk_idx: int, terminal_mol: Chem.Mol, attachment_idx: int\n) -&gt; RWMol:\n    \"\"\"Replaces a single asterisk atom with a terminal group.\n\n    Args:\n        mol: The molecule being modified.\n        asterisk_idx: Index of the asterisk atom to replace.\n        terminal_mol: The terminal group molecule.\n        attachment_idx: Index of the attachment point in the terminal group.\n\n    Returns:\n        The modified molecule.\n    \"\"\"\n    asterisk_atom = mol.GetAtomWithIdx(asterisk_idx)\n    neighbors = [n.GetIdx() for n in asterisk_atom.GetNeighbors()]\n    if not neighbors:\n        for atom in terminal_mol.GetAtoms():\n            if atom.GetSymbol() != \"*\":\n                new_atom = Atom(atom.GetAtomicNum())\n                new_atom.SetFormalCharge(atom.GetFormalCharge())\n                mol.ReplaceAtom(asterisk_idx, new_atom)\n                break\n        return mol\n    neighbor_idx = neighbors[0]\n    bond = mol.GetBondBetweenAtoms(asterisk_idx, neighbor_idx)\n    bond_type = bond.GetBondType() if bond else Chem.BondType.SINGLE\n    mol.RemoveAtom(asterisk_idx)\n    if neighbor_idx &gt; asterisk_idx:\n        neighbor_idx -= 1\n    atom_mapping = {}\n    for atom in terminal_mol.GetAtoms():\n        if atom.GetIdx() != attachment_idx:\n            new_atom = Atom(atom.GetAtomicNum())\n            new_atom.SetFormalCharge(atom.GetFormalCharge())\n            new_idx = mol.AddAtom(new_atom)\n            atom_mapping[atom.GetIdx()] = new_idx\n    for bond in terminal_mol.GetBonds():\n        begin_idx = bond.GetBeginAtomIdx()\n        end_idx = bond.GetEndAtomIdx()\n        if begin_idx == attachment_idx or end_idx == attachment_idx:\n            continue\n        if begin_idx in atom_mapping and end_idx in atom_mapping:\n            mol.AddBond(\n                atom_mapping[begin_idx], atom_mapping[end_idx], bond.GetBondType()\n            )\n    for bond in terminal_mol.GetBonds():\n        if bond.GetBeginAtomIdx() == attachment_idx:\n            connection_atom_idx = bond.GetEndAtomIdx()\n        elif bond.GetEndAtomIdx() == attachment_idx:\n            connection_atom_idx = bond.GetBeginAtomIdx()\n        else:\n            continue\n        if connection_atom_idx in atom_mapping:\n            mol.AddBond(neighbor_idx, atom_mapping[connection_atom_idx], bond_type)\n            break\n    return mol\n</code></pre>"},{"location":"api/#polymetrix.featurizers.sidechain_backbone_featurizer","title":"<code>sidechain_backbone_featurizer</code>","text":""},{"location":"api/#polymetrix.featurizers.sidechain_backbone_featurizer.SidechainDiversityFeaturizer","title":"<code>SidechainDiversityFeaturizer</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Computes the number of structurally diverse sidechains in a polymer based on graph isomorphism.</p> Source code in <code>src/polymetrix/featurizers/sidechain_backbone_featurizer.py</code> <pre><code>class SidechainDiversityFeaturizer(BaseFeatureCalculator):\n    \"\"\"Computes the number of structurally diverse sidechains in a polymer based on graph isomorphism.\"\"\"\n\n    def featurize(self, polymer) -&gt; np.ndarray:\n        sidechain_graphs = polymer.get_backbone_and_sidechain_graphs()[1]\n        unique_hashes = set()\n        for scg in sidechain_graphs:\n            graph_hash = nx.weisfeiler_lehman_graph_hash(scg)\n            unique_hashes.add(graph_hash)\n        return np.array([len(unique_hashes)])\n\n    def feature_labels(self) -&gt; List[str]:\n        return [\"num_diverse_sidechains\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.sidechain_backbone_featurizer.SidechainLengthToStarAttachmentDistanceRatioFeaturizer","title":"<code>SidechainLengthToStarAttachmentDistanceRatioFeaturizer</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Computes aggregated ratios of sidechain lengths to the shortest backbone distance from the polymer's star node (*) to each sidechain's attachment point.</p> Source code in <code>src/polymetrix/featurizers/sidechain_backbone_featurizer.py</code> <pre><code>class SidechainLengthToStarAttachmentDistanceRatioFeaturizer(BaseFeatureCalculator):\n    \"\"\"Computes aggregated ratios of sidechain lengths to the shortest backbone distance from the polymer's star node (*) to each sidechain's attachment point.\"\"\"\n\n    def _compute_min_backbone_length(self, sidechain, star_nodes, star_paths, graph):\n        \"\"\"Calculate the minimum backbone distance from any star node to the sidechain's attachment point.\"\"\"\n        min_backbone_length = float(\"inf\")\n        side_nodes = set(sidechain.nodes())\n        for node in side_nodes:\n            neighbors = set(graph.neighbors(node))\n            backbone_neighbors = neighbors - side_nodes\n            if backbone_neighbors:\n                attachment_point = next(iter(backbone_neighbors))\n                for star in star_nodes:\n                    if attachment_point in star_paths[star]:\n                        path_length = star_paths[star][attachment_point] + 1\n                        min_backbone_length = min(min_backbone_length, path_length)\n        return min_backbone_length\n\n    def featurize(self, polymer) -&gt; np.ndarray:\n        graph = polymer.graph\n        star_nodes = [\n            node for node, data in graph.nodes(data=True) if data[\"element\"] == \"*\"\n        ]\n        backbone_graphs, sidechain_graphs = polymer.get_backbone_and_sidechain_graphs()\n\n        if not sidechain_graphs or not backbone_graphs:\n            return np.zeros(len(self.agg))\n\n        sidechain_lengths = [len(sc.nodes()) for sc in sidechain_graphs]\n        star_paths = {\n            star: nx.single_source_shortest_path_length(graph, star)\n            for star in star_nodes\n        }\n\n        backbone_lengths = [\n            self._compute_min_backbone_length(sidechain, star_nodes, star_paths, graph)\n            for sidechain in sidechain_graphs\n        ]\n\n        ratios = [\n            s_length / b_length\n            for s_length, b_length in zip(sidechain_lengths, backbone_lengths)\n            if b_length &gt; 0\n        ]\n        if not ratios:\n            return np.zeros(len(self.agg))\n\n        agg_ratios = self.aggregate(ratios)\n        return np.array(agg_ratios)\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"sidechainlength_to_star_attachment_distance_ratio\"]\n</code></pre>"},{"location":"api/#polymetrix.featurizers.sidechain_backbone_featurizer.SidechainLengthToStarAttachmentDistanceRatioFeaturizer._compute_min_backbone_length","title":"<code>_compute_min_backbone_length(sidechain, star_nodes, star_paths, graph)</code>","text":"<p>Calculate the minimum backbone distance from any star node to the sidechain's attachment point.</p> Source code in <code>src/polymetrix/featurizers/sidechain_backbone_featurizer.py</code> <pre><code>def _compute_min_backbone_length(self, sidechain, star_nodes, star_paths, graph):\n    \"\"\"Calculate the minimum backbone distance from any star node to the sidechain's attachment point.\"\"\"\n    min_backbone_length = float(\"inf\")\n    side_nodes = set(sidechain.nodes())\n    for node in side_nodes:\n        neighbors = set(graph.neighbors(node))\n        backbone_neighbors = neighbors - side_nodes\n        if backbone_neighbors:\n            attachment_point = next(iter(backbone_neighbors))\n            for star in star_nodes:\n                if attachment_point in star_paths[star]:\n                    path_length = star_paths[star][attachment_point] + 1\n                    min_backbone_length = min(min_backbone_length, path_length)\n    return min_backbone_length\n</code></pre>"},{"location":"api/#polymetrix.featurizers.sidechain_backbone_featurizer.StarToSidechainMinDistanceFeaturizer","title":"<code>StarToSidechainMinDistanceFeaturizer</code>","text":"<p>               Bases: <code>BaseFeatureCalculator</code></p> <p>Computes aggregated minimum backbone distances from star nodes (*) to sidechains in a polymer.</p> Source code in <code>src/polymetrix/featurizers/sidechain_backbone_featurizer.py</code> <pre><code>class StarToSidechainMinDistanceFeaturizer(BaseFeatureCalculator):\n    \"\"\"Computes aggregated minimum backbone distances from star nodes (*) to sidechains in a polymer.\"\"\"\n\n    def featurize(self, polymer) -&gt; np.ndarray:\n        graph = polymer.graph\n        star_nodes = [\n            node for node, data in graph.nodes(data=True) if data[\"element\"] == \"*\"\n        ]\n        sidechain_graphs = polymer.get_backbone_and_sidechain_graphs()[1]\n\n        distances = []\n        for sidechain in sidechain_graphs:\n            valid_dists = [\n                nx.shortest_path_length(graph, star, node) - 1\n                for star in star_nodes\n                for node in sidechain.nodes()\n                if nx.has_path(graph, star, node)\n            ]\n            if valid_dists:\n                distances.append(min(valid_dists))\n\n        if not distances:\n            return np.zeros(len(self.agg))\n\n        return self.aggregate(distances)\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return [\"star_to_sidechain_min_distance\"]\n</code></pre>"},{"location":"api/#polymetrix.kmeans","title":"<code>kmeans</code>","text":""},{"location":"api/#polymetrix.kmeans.parse_fingerprint","title":"<code>parse_fingerprint(fp_string)</code>","text":"<p>Parse fingerprint string to numpy array</p> Source code in <code>src/polymetrix/kmeans.py</code> <pre><code>def parse_fingerprint(fp_string):\n    \"\"\"Parse fingerprint string to numpy array\"\"\"\n    try:\n        # If it's a string representation of a list\n        if isinstance(fp_string, str):\n            # Remove any brackets and split by spaces or commas\n            fp_string = fp_string.strip(\"[]\")\n            # Try different parsing methods\n            if \",\" in fp_string:\n                fp_array = np.array([float(x.strip()) for x in fp_string.split(\",\")])\n            else:\n                fp_array = np.array([float(x.strip()) for x in fp_string.split()])\n        else:\n            # If it's already a numeric type\n            fp_array = np.array(fp_string)\n        return fp_array\n    except:\n        # If parsing fails, return None\n        return None\n</code></pre>"},{"location":"api/#polymetrix.splitters","title":"<code>splitters</code>","text":""},{"location":"api/#polymetrix.splitters.splitters","title":"<code>splitters</code>","text":""},{"location":"api/#polymetrix.splitters.splitters.PolymerClassSplitter","title":"<code>PolymerClassSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Splitter based on polymer class</p> Source code in <code>src/polymetrix/splitters/splitters.py</code> <pre><code>class PolymerClassSplitter(BaseSplitter):\n    \"\"\"Splitter based on polymer class\"\"\"\n\n    def __init__(\n        self,\n        ds: AbstractDataset,\n        column_name: str = \"meta.polymer_class\",\n        shuffle: bool = True,\n        random_state: Optional[Union[int, np.random.RandomState]] = None,\n        **kwargs,\n    ) -&gt; None:\n        self._column_name = column_name\n        super().__init__(ds=ds, shuffle=shuffle, random_state=random_state, **kwargs)\n\n    def _get_groups(self) -&gt; Collection[str]:\n        col_idx = self._ds._meta_names.index(self._column_name)\n        metadata = self._ds._meta_data[:, col_idx]\n        return metadata.flatten()\n</code></pre>"},{"location":"api/#polymetrix.splitters.splitters.TgSplitter","title":"<code>TgSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Splitter based on Tg values</p> Source code in <code>src/polymetrix/splitters/splitters.py</code> <pre><code>class TgSplitter(BaseSplitter):\n    \"\"\"Splitter based on Tg values\"\"\"\n\n    def __init__(\n        self,\n        ds: AbstractDataset,\n        tg_q: Optional[Collection[float]] = None,\n        label_name: str = \"labels.Exp_Tg(K)\",\n        shuffle: bool = True,\n        random_state: Optional[Union[int, np.random.RandomState]] = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Initialize TgSplitter\n\n        Args:\n            ds: Dataset to split\n            tg_q: Quantiles to bin Tg values into groups\n            label_name: Name of the label to use for splitting\n            shuffle: Whether to shuffle the dataset\n            random_state: Random state for shuffling\n            **kwargs: Additional arguments to pass to BaseSplitter\n        \"\"\"\n        self._grouping_q = tg_q\n        self._label_name = label_name\n        super().__init__(ds=ds, shuffle=shuffle, random_state=random_state, **kwargs)\n\n    def _get_groups(self) -&gt; Collection[int]:\n        \"\"\"Bin Tg values into quantile-based groups\"\"\"\n        tg_values = self._ds.get_labels(\n            idx=range(len(self._ds)), label_names=[self._label_name]\n        ).flatten()\n        return quantile_binning(tg_values, self._grouping_q)\n</code></pre>"},{"location":"api/#polymetrix.splitters.splitters.TgSplitter.__init__","title":"<code>__init__(ds, tg_q=None, label_name='labels.Exp_Tg(K)', shuffle=True, random_state=None, **kwargs)</code>","text":"<p>Initialize TgSplitter</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>AbstractDataset</code> <p>Dataset to split</p> required <code>tg_q</code> <code>Optional[Collection[float]]</code> <p>Quantiles to bin Tg values into groups</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Name of the label to use for splitting</p> <code>'labels.Exp_Tg(K)'</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the dataset</p> <code>True</code> <code>random_state</code> <code>Optional[Union[int, RandomState]]</code> <p>Random state for shuffling</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments to pass to BaseSplitter</p> <code>{}</code> Source code in <code>src/polymetrix/splitters/splitters.py</code> <pre><code>def __init__(\n    self,\n    ds: AbstractDataset,\n    tg_q: Optional[Collection[float]] = None,\n    label_name: str = \"labels.Exp_Tg(K)\",\n    shuffle: bool = True,\n    random_state: Optional[Union[int, np.random.RandomState]] = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Initialize TgSplitter\n\n    Args:\n        ds: Dataset to split\n        tg_q: Quantiles to bin Tg values into groups\n        label_name: Name of the label to use for splitting\n        shuffle: Whether to shuffle the dataset\n        random_state: Random state for shuffling\n        **kwargs: Additional arguments to pass to BaseSplitter\n    \"\"\"\n    self._grouping_q = tg_q\n    self._label_name = label_name\n    super().__init__(ds=ds, shuffle=shuffle, random_state=random_state, **kwargs)\n</code></pre>"},{"location":"api/#polymetrix.splitters.splitters.TgSplitter._get_groups","title":"<code>_get_groups()</code>","text":"<p>Bin Tg values into quantile-based groups</p> Source code in <code>src/polymetrix/splitters/splitters.py</code> <pre><code>def _get_groups(self) -&gt; Collection[int]:\n    \"\"\"Bin Tg values into quantile-based groups\"\"\"\n    tg_values = self._ds.get_labels(\n        idx=range(len(self._ds)), label_names=[self._label_name]\n    ).flatten()\n    return quantile_binning(tg_values, self._grouping_q)\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>When contributing to this repository, please first discuss the change you wish to make via issue, email, or any other method with the owners of this repository before making a change.</p> <p>Please note we have a code of conduct, please follow it in all your interactions with the project.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/#1-fork-the-repository","title":"1. Fork the Repository","text":"<p>Fork the repository by clicking on the 'Fork' button in the top right corner of the repository page. This will create a copy of this repository in your GitHub account.</p>"},{"location":"contributing/#2-clone-the-repository","title":"2. Clone the Repository","text":"<p>Clone the forked repository to your local machine. Open a terminal and run the following command: <pre><code>git clone\n</code></pre></p>"},{"location":"contributing/#3-create-a-new-branch","title":"3. Create a New Branch","text":"<p>Create a new branch to work on the changes. Run the following command to create a new branch: <pre><code>git checkout -b &lt;branch-name&gt;\n</code></pre></p>"},{"location":"contributing/#4-make-changes","title":"4. Make Changes","text":"<p>Make the necessary changes in the codebase.</p>"},{"location":"contributing/#5-commit-changes","title":"5. Commit Changes","text":"<p>Commit the changes to the branch. Run the following command to commit the changes: <pre><code>git commit -m \"Your commit message\"\n</code></pre></p>"},{"location":"contributing/#6-push-changes","title":"6. Push Changes","text":"<p>Push the changes to the forked repository. Run the following command to push the changes: <pre><code>git push origin &lt;branch-name&gt;\n</code></pre></p>"},{"location":"contributing/#7-create-a-pull-request","title":"7. Create a Pull Request","text":"<p>Go to the forked repository on GitHub and click on the 'New Pull Request' button. Fill in the details of the pull request and submit it.</p>"},{"location":"contributing/#what-you-can-contribute","title":"What You Can Contribute","text":"<p>You can contribute to the project in the following ways: - Featurizers: Enhance the polymer analysis capabilities by adding new featurizers. - Datasets: Contribute new polymer datasets (e.g., glass transition temperature, tensile strength). - Documentation: Improve the documentation to make it more user-friendly. - Feature Requests: Suggest new features that you would like to see in the project.</p>"},{"location":"contributing/#detailed-contribution-guidelines","title":"Detailed Contribution Guidelines","text":""},{"location":"contributing/#contributing-featurizers","title":"Contributing Featurizers","text":"<p>You can enhance the polymer analysis capabilities by adding new featurizers to the <code>PolyMetriX/src/polymetrix/featurizers/</code> directory. Within this folder, you can extend functionality by modifying either the <code>chemical_featurizer.py</code> or <code>sidechain_backbone_featurizer.py</code> modules.</p> <p>If you are introducing new featurizers that capture spatial geometry, consider creating a new module, such as <code>geometry.py</code>. Here's how you can contribute a new featurizer:</p> <ol> <li>Create a new Featurizer class in <code>PolyMetriX/src/polymetrix/featurizers/{module}.py</code>:<ul> <li>Subclass <code>BaseFeatureCalculator</code> or <code>PolymerPartFeaturizer</code> (e.g., for sidechains, backbone, or full polymer).</li> <li>Implement the <code>calculate()</code> method (or <code>featurize()</code> for polymer-specific featurizers) to compute your feature.</li> <li>Define <code>feature_base_labels()</code> to name your feature(s).</li> </ul> </li> </ol> <p>Example: <pre><code>class MyNewFeaturizer(BaseFeatureCalculator):\n    def calculate(self, polymer: Polymer) -&gt; np.ndarray:\n        # Compute your feature here\n        return feature_values\n\n    def feature_base_labels(self) -&gt; List[str]:\n        return ['my_new_feature']\n</code></pre></p> <ol> <li>Test your featurizer by adding a test case in <code>PolyMetriX/tests/test_featurizer.py</code>. We use <code>pytest</code> to run the tests.</li> </ol>"},{"location":"contributing/#contributing-datasets","title":"Contributing Datasets","text":"<p>You can contribute new polymer datasets (e.g., glass transition temperature, tensile strength) to the <code>datasets</code> folder. Datasets should follow a standard format and use <code>pystow</code> for retrieval. 1. Create a Dataset Class:     - Subclass AbstractDataset in PolyMetriX/src/polymetrix/datasets/.     - Define the dataset\u2019s properties (e.g., PSMILES, features, labels).     - We use zenodo for versioning datasets.     - Use <code>pystow</code> to load the dataset from a URL.</p> <p>Example: <pre><code>class CuratedDensityDataset(AbstractDataset):\n    def __init__(self, subset: Optional[Collection[int]] = None):\n        super().__init__()\n        default_version = \"latest\"  \n        default_url = \"https://example.com/default_dataset.csv\"  \n\n        csv_path = POLYMETRIX_PYSTOW_MODULE.ensure(\n            \"CuratedDensityDataset\", default_version, url=default_url\n        )\n        self._df = pd.read_csv(csv_path).reset_index(drop=True)\n\n        if subset is not None:\n            self._df = self._df.iloc[subset].reset_index(drop=True)\n\n        self._psmiles = self._df[\"PSMILES\"].to_numpy()\n        self._features = self._df[\n            [col for col in self._df.columns if col.startswith(\"features.\")]\n        ].to_numpy()\n        self._labels = self._df[\n            [col for col in self._df.columns if col.startswith(\"labels.\")]\n        ].to_numpy()\n</code></pre> 2. Dataset Format     - CSV columns must include:         - PSMILES: Polymer SMILES string.         - <code>features.&lt;name&gt;</code>: Feature columns (e.g., features.molecular_weight).         - <code>labels.&lt;name&gt;</code>: Label columns (e.g., labels.density).         - Optional:<code>meta.&lt;name&gt;</code> for metadata columns.</p> <ol> <li> <p>Test your dataset by adding a test case in <code>PolyMetriX/tests/test_datasets.py</code>. We use <code>pytest</code> to run the tests.</p> </li> <li> <p>Submit a pull request to the main repository.</p> </li> </ol>"},{"location":"contributing/#contributing-documentation","title":"Contributing Documentation","text":"<p>You can contribute to the project\u2019s documentation by improving the existing documentation or adding new sections. The documentation is located in the <code>docs</code> folder.</p> <ol> <li>Edit the existing documentation or add new documentation in the <code>docs</code> folder.</li> <li>Submit a pull request to the main repository.</li> </ol> <p>The project uses <code>mkdocs</code> to generate the documentation. You can preview the documentation locally by running the following command: <pre><code>mkdocs serve\n</code></pre> That's it! You have successfully contributed to the project.</p>"},{"location":"datasets/","title":"Datasets","text":""},{"location":"datasets/#curatedglasstempdataset","title":"<code>CuratedGlassTempDataset</code>","text":"<pre><code>from polymetrix.datasets import CuratedGlassTempDataset\n\ndataset = CuratedGlassTempDataset()\n\nprint(\"Available features:\", dataset.available_features)\nprint(\"Available labels:\", dataset.available_labels)\nprint(\"Available metadata:\", dataset.meta_info)\n</code></pre> <p>This will output the list of available features, labels, and metadata for the dataset.</p> <p>Since, the dataset has been curated for the glass transition temperature (Tg) data for the polymers, the available labels are <code>labels.Exp_Tg(K)</code> and the available features are the list of features that are available in the dataset. In addition, this dataset also contains metadata information about the polymer, PSMILES, source, Tg range, number of points, Tg values, reliability, and standard deviation of the data.</p> <p>The <code>meta.source</code> contain the following names of the sources from which the data has been obtained for Tg dataset along with links to the sources:</p> <ul> <li><code>Schrodinger</code> - Schrodinger</li> <li><code>Mattioni</code> - Mattioni</li> <li><code>Uchicago</code> - Uchicago</li> <li><code>Liu</code> - Liu</li> <li><code>Nguyen</code> - Nguyen</li> <li><code>Wu</code> - Wu</li> <li><code>Qiu</code> - Qiu</li> <li><code>GREA</code> - GREA</li> <li><code>Xie</code> - Xie</li> </ul> <p>For the same polymer, different glass transition temperature values are reported from various sources. For this reason, we have considered the median value of the Tg values for the same polymer from these sources as the Tg value listed in the <code>labels.Exp_Tg(K)</code> column. Additionally, we have provided the reliability of the data in the <code>meta.reliability</code> column. The reliability of the data is assigned on the occurrence of polymer and Z-score \u2264 2. The reliability of the data is categorized into three categories:</p> <ul> <li><code>Black</code> - This category indicates that the reliability of the data is uncertain because the polymers are unique, and there is limited information available. This is based on our estimate.</li> <li><code>Yellow</code> - This category suggests that the data is moderately reliable based on our estimate, as the polymer has two different Tg values from different sources with a Z-score \u2264 2.</li> <li><code>Gold</code> - This category means the data is highly reliable because the polymer has more than two different Tg values from different sources and Z-score \u2264 2.</li> <li><code>Red</code> - This category indicates that the data is unreliable because the polymer has different Tg values from different sources with a Z-score &gt; 2.</li> </ul> <p>The <code>meta.tg_range</code> column contains the range of the glass transition temperature for the polymer for multiple sources. The <code>meta.tg_values</code> column contains the Tg values for the polymer from different sources in a list. The <code>meta.num_of_points</code> column contains the number of data points for the polymer that has different Tg values from different sources. The <code>meta.stdev</code> column represents the standard deviation of the Tg values for the polymer. The <code>meta.polymer_class</code> column contains the polymer class of the polymer. The polymer class has 22 different classes, which are listed below.</p> <ul> <li><code>Polyimides</code> - 1765</li> <li><code>Polyoxides</code> - 1748</li> <li><code>Polyesters</code> - 660</li> <li><code>Polyacrylics</code> - 617</li> <li><code>Polyamides</code> - 486</li> <li><code>Polyimines</code> - 265</li> <li><code>Polyvinyls</code> - 254</li> <li><code>Polystyrenes</code> - 241</li> <li><code>Polysiloxanes</code> - 238</li> <li><code>Polysulfides</code> - 216</li> <li><code>Polycarbonates</code> - 160</li> <li><code>Polyurethanes</code> - 123</li> <li><code>Polyphosphazenes</code> - 107</li> <li><code>Polyphenylenes</code> - 104</li> <li><code>Polyolefins</code> - 55</li> <li><code>Polydienes</code> - 41</li> <li><code>Polyhalo-olefins</code> - 40</li> <li><code>Polyureas</code> - 39</li> <li><code>Polyanhydrides</code> - 28</li> <li><code>Polyketones</code> - 7</li> <li><code>Polyethers</code> - 1</li> <li><code>Other class</code> - 172</li> </ul> <p>The figures below illustrate the data filtering funnel and the data curation workflow for the glass transition temperature (Tg) dataset. In the data filtering funnel, B1, B2, B3, and B4 represent the sources (<code>Schrodinger</code>, <code>liu</code>, <code>Mattioni</code>, and <code>Wu</code>), all of which originated from the Bicerano handbook. We first corrected these sources and then merged the data from all sources to create the curated dataset for the glass transition temperature (Tg) data of polymers.</p> <p> Caption 1: Correction to Bicerano sources</p> <p> Caption 2: Data Curation Workflow</p>"},{"location":"featurizers/","title":"Features Available in PolyMetriX","text":"<p>The featurizers in PolyMetriX are classified into two categories: Chemical Featurizers: These focus on capturing the chemical characteristics of polymers, such as types of atoms, functional groups, and chemical bonds, providing insights into how molecular composition influences behavior. Topological Featurizers: These emphasize the structural and spatial arrangement of polymer components, assessing topology like connectivity and branching to understand their impact on material performance.</p>"},{"location":"featurizers/#featurizers-overview","title":"Featurizers Overview","text":"<p>Below is a detailed table of the featurizers available in PolyMetriX:</p> Featurizer Name Description Type of Featurizer NumHBondDonors Counts hydrogen bond donors, indicating ability to form hydrogen bonds with water. Chemical NumHBondAcceptors Counts hydrogen bond acceptors, reflecting interaction potential with water. Chemical NumRotatableBonds Counts rotatable bonds, providing insights into flexibility and conformational freedom. Chemical NumRings Counts total rings, affecting structural stability and molecular interactions. Chemical NumNonAromaticRings Counts non-aromatic rings in the polymer structure. Chemical NumAromaticRings Counts aromatic rings, influencing stability and reactivity. Chemical NumAtoms Counts total atoms in the polymer. Chemical TopologicalSurfaceArea Measures polar surface area, affecting interactions with polar solvents like water. Chemical FractionBicyclicRings Fraction of bicyclic rings, impacting rigidity and thermal stability. Chemical NumAliphaticHeterocycles Counts non-aromatic heterocycles with heteroatoms (e.g., N, O, S). Chemical SlogPVSA1 Surface area contributing to octanol solubility, linked to lipophilicity. Chemical BalabanJIndex Measures molecular complexity and connectivity of atoms. Chemical MolecularWeight Calculates molecular weight, influencing solubility and other properties. Chemical Sp3CarbonCountFeaturizer Counts sp3 carbons, providing info on 3D structure and solubility. Chemical Sp2CarbonCountFeaturizer Counts sp2 carbons, indicating aromaticity and reactivity. Chemical MaxEStateIndex Maximum electronic state index, reflecting charge distribution. Chemical SmrVSA5 Molar refractivity sum for atoms with specific surface area (2.45\u20132.75). Chemical FpDensityMorgan1 Density of substructure info in Morgan fingerprint. Chemical HalogenCounts Counts halogen atoms (F, Cl, Br, I) in the molecule. Chemical BondCounts Counts total bonds, indicating structural complexity and reactivity. Chemical BridgingRingsCount Counts bridging rings, affecting structural stability and rigidity. Chemical MaxRingSize Calculates the largest ring size in the molecule. Chemical HeteroatomCount Counts heteroatoms (non-C, non-H) in heterocyclic rings. Chemical HeteroatomDensity Density of heteroatoms in the molecule. Chemical HeteroatomDistanceStats Statistics on distances between heteroatoms. Chemical NumSideChainFeaturizer Counts sidechains, influencing crystallinity and density. Topological NumBackBoneFeaturizer Counts backbone atoms in the polymer. Topological SideChainLengthFeaturizer Measures sidechain length in the polymer. Topological BackBoneLengthFeaturizer Measures backbone length in the polymer. Topological SidechainLengthToStarAttachmentDistanceRatioFeaturizer Ratio of sidechain length to minimum distance from star nodes. Topological StarToSidechainMinDistanceFeaturizer Minimum distance from star nodes to sidechains in edges. Topological SidechainDiversityFeaturizer Counts structurally diverse sidechains using Weisfeiler-Lehman graph hash. Topological"},{"location":"how_to_guides/","title":"How To Guides","text":""},{"location":"how_to_guides/#featurization","title":"Featurization","text":""},{"location":"how_to_guides/#applying-a-single-featurizer-to-a-polymer","title":"Applying a single featurizer to a polymer","text":"<pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.chemical_featurizer import MolecularWeight\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import FullPolymerFeaturizer\n\n# initialize the FullPolymerFeaturizer class with required featurizers\nfeaturizer = FullPolymerFeaturizer(MolecularWeight()) # (1)\n\npolymer = Polymer.from_psmiles('*CCCCCCNC(=O)c1ccc(C(=O)N*)c(Sc2ccccc2)c1') # (2)\nresult = featurizer.featurize(polymer)\n</code></pre> <ol> <li><code>polymetrix</code> uses <code>Featurizer</code> objects similar to <code>matminer</code> or <code>mofdscribe</code>, which follows the <code>sklearn</code> API. The <code>FullPolymerFeaturizer</code> class is used to apply a featurizer to the entire polymer repeating unit.</li> <li><code>polymetrix</code> is built around the <code>Polymer</code> class, which is used to represent a polymer molecule. The <code>from_psmiles</code> method is used to create a polymer molecule from a polymer SMILES string.</li> </ol> <p>The result will be a NumPy array of MolecularWeight value for the given polymer.</p>"},{"location":"how_to_guides/#combining-multiple-featurizers-for-a-polymer","title":"Combining multiple featurizers for a polymer","text":"<pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.chemical_featurizer import MolecularWeight, NumHBondDonors, NumHBondAcceptors, NumRotatableBonds\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import FullPolymerFeaturizer\nfrom polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer\n\n# initialize the FullPolymerFeaturizer class with required featurizers\nmol_weight_featurizer = FullPolymerFeaturizer(MolecularWeight())\nhbond_donors = FullPolymerFeaturizer(NumHBondDonors())\nhbond_acceptors = FullPolymerFeaturizer(NumHBondAcceptors())\nrotatable_bonds = FullPolymerFeaturizer(NumRotatableBonds())\n\nfeaturizer = MultipleFeaturizer([mol_weight_featurizer, hbond_donors, hbond_acceptors, rotatable_bonds]) # (1)\npolymer = Polymer.from_psmiles('*CCCCCCNC(=O)c1ccc(C(=O)N*)c(Sc2ccccc2)c1')\nresult = featurizer.featurize(polymer)\n</code></pre> <ol> <li>The advantage of using <code>MultipleFeaturizer</code> is that it allows you to combine multiple featurizers into a single featurizer object. This way, you can apply multiple featurizers to the polymer in a single step. The <code>MultipleFeaturizer</code> behaves like a \"regular\" featurizer, so you can use it in the same way as a single featurizer.</li> </ol> <p>The result will be a NumPy array of <code>mol_weight_featurizer, hbond_donors, hbond_acceptors, rotatable_bonds</code> values for the given polymer.</p>"},{"location":"how_to_guides/#featurizers-for-the-sidechain-level-of-the-polymer","title":"Featurizers for the sidechain level of the polymer","text":"<p>The below image shows the difference between side chain and backbone of a polymer, Where the side chain is the part of the polymer that is not part of the main chain (highlighted in purple) and the backbone is the main chain of the polymer (highlighted in black). </p> <pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import NumAtoms\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import SideChainFeaturizer, NumSideChainFeaturizer\n\n# initialize the SideChainFeaturizer class with required featurizers\nnum_sidechains = NumSideChainFeaturizer()\nsidechain_length = SideChainFeaturizer(NumAtoms(agg=[\"sum\", \"mean\", \"max\", \"min\"]))\n\nfeaturizer = MultipleFeaturizer([num_sidechains, sidechain_length])\npolymer = Polymer.from_psmiles('*CCCCCCCCOc1ccc(C(c2ccc(O*)cc2)(C(F)(F)F)C(F)(F)F)cc1')\nresult = featurizer.featurize(polymer)\n</code></pre> <p>The result will be a NumPy array of <code>num_sidechains</code> and <code>sidechain_length</code> values for the given polymer.</p>"},{"location":"how_to_guides/#featurizers-for-the-backbone-level-of-the-polymer","title":"Featurizers for the backbone level of the polymer","text":"<pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import NumAtoms\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import SideChainFeaturizer, NumSideChainFeaturizer, BackBoneFeaturizer, NumBackBoneFeaturizer\n\n# initialize the BackBoneFeaturizer class with required featurizers\nnum_backbones = NumBackBoneFeaturizer()\nbackbone_length = BackBoneFeaturizer(NumAtoms(agg=[\"sum\"])) # Polymer cannot have more than one backbone\n\nfeaturizer = MultipleFeaturizer([num_backbones, backbone_length])\npolymer = Polymer.from_psmiles('*CCCCCCCCOc1ccc(C(c2ccc(O*)cc2)(C(F)(F)F)C(F)(F)F)cc1')\nresult = featurizer.featurize(polymer)\n</code></pre> <p>The result will be a NumPy array of <code>num_backbones</code> and <code>backbone_length</code> values for the given polymer.</p>"},{"location":"how_to_guides/#applying-featurizers-to-a-molecule","title":"Applying featurizers to a molecule","text":"<pre><code>from polymetrix.featurizers.molecule import Molecule, FullMolecularFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import MolecularWeight\n\n# initialize the FullMolecularFeaturizer class with required featurizers\nfeaturizer = FullMolecularFeaturizer(MolecularWeight())\nmolecule = Molecule.from_smiles('CC(=O)OC1=CC=CC=C1C(=O)O') # (1)\nresult = featurizer.featurize(molecule)\n</code></pre> <p>The result will be a NumPy array of MolecularWeight value for the given molecule.</p>"},{"location":"how_to_guides/#applying-multiple-featurizers-to-a-molecule","title":"Applying multiple featurizers to a molecule","text":"<pre><code>from polymetrix.featurizers.molecule import Molecule, FullMolecularFeaturizer\nfrom polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import (\n    MolecularWeight,\n    NumHBondDonors,\n    NumHBondAcceptors,\n    NumRotatableBonds\n)\n\n# initialize the FullMolecularFeaturizer class with required featurizers\nmol_weight_featurizer = FullMolecularFeaturizer(MolecularWeight())\nhbond_donors = FullMolecularFeaturizer(NumHBondDonors())\nhbond_acceptors = FullMolecularFeaturizer(NumHBondAcceptors())\nrotatable_bonds = FullMolecularFeaturizer(NumRotatableBonds())\nfeaturizer = MultipleFeaturizer([mol_weight_featurizer, hbond_donors, hbond_acceptors, rotatable_bonds]) # (1)\nmolecule = Molecule.from_smiles('CC(=O)OC1=CC=CC=C1C(=O)O') # (2)\nresult = featurizer.featurize(molecule)\n</code></pre> <p>The result will be a NumPy array of <code>mol_weight_featurizer, hbond_donors, hbond_acceptors, rotatable_bonds</code> values for the given molecule.</p>"},{"location":"how_to_guides/#comparator","title":"Comparator","text":""},{"location":"how_to_guides/#comparing-a-polymer-with-a-molecule-given-a-featurizer","title":"Comparing a polymer with a molecule given a featurizer","text":"<pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.molecule import Molecule, FullMolecularFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import MolecularWeight, NumHBondDonors, NumHBondAcceptors, NumRotatableBonds\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import FullPolymerFeaturizer\nfrom polymetrix.featurizers.comparator import PolymerMoleculeComparator\n\n# initialize with required featurizers\npolymer_featurizer = FullPolymerFeaturizer(MolecularWeight())\nmolecule_featurizer = FullMolecularFeaturizer(MolecularWeight())\n\npolymer = Polymer.from_psmiles('*CCCCCCNC(=O)c1ccc(C(=O)N*)c(Sc2ccccc2)c1')\nmolecule = Molecule.from_smiles('CC(=O)OC1=CC=CC=C1C(=O)O')\n\ncomparator = PolymerMoleculeComparator(polymer_featurizer, molecule_featurizer) # (1)\ndifference = comparator.compare(polymer, molecule) # (2)\n</code></pre> <p>The <code>PolymerMoleculeComparator</code> class is used to compare a polymer with a molecule given a featurizer. The <code>compare</code> method returns the difference between the polymer and the molecule in terms of the features extracted by the featurizers.</p>"},{"location":"how_to_guides/#comparing-a-polymer-with-a-molecule-given-multiple-featurizers","title":"Comparing a polymer with a molecule given multiple featurizers","text":"<pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.molecule import Molecule, FullMolecularFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import MolecularWeight, NumHBondDonors, NumHBondAcceptors, NumRotatableBonds\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import FullPolymerFeaturizer\nfrom polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer\nfrom polymetrix.featurizers.comparator import PolymerMoleculeComparator\n\n# initialize with required featurizers\npolymer_featurizers = [\n    FullPolymerFeaturizer(MolecularWeight()),\n    FullPolymerFeaturizer(NumHBondDonors()),\n    FullPolymerFeaturizer(NumHBondAcceptors()),\n    FullPolymerFeaturizer(NumRotatableBonds())\n]\n\nmolecule_featurizers = [\n    FullMolecularFeaturizer(MolecularWeight()),\n    FullMolecularFeaturizer(NumHBondDonors()),\n    FullMolecularFeaturizer(NumHBondAcceptors()),\n    FullMolecularFeaturizer(NumRotatableBonds())\n]\n\npolymer = Polymer.from_psmiles('*CCCCCCNC(=O)c1ccc(C(=O)N*)c(Sc2ccccc2)c1')\nmolecule = Molecule.from_smiles('CC(=O)OC1=CC=CC=C1C(=O)O')\n\npolymer_featurizer = MultipleFeaturizer(polymer_featurizers) # (1)\nmolecule_featurizer = MultipleFeaturizer(molecule_featurizers) # (2)\n\ncomparator = PolymerMoleculeComparator(\n    polymer_multi,\n    molecule_multi,\n    comparisons=[\"absolute_difference\", \"signed_difference\", \"product\", \"squared_distance\", \"euclidean_distance\"],\n    agg=[\"mean\", \"max\", \"min\", \"sum\"]\n) # (3)\ndifference = comparator.compare(polymer, molecule) # (4)\n</code></pre> <p>The <code>MultipleFeaturizer</code> class is used to combine multiple featurizers into a single featurizer object. The <code>PolymerMoleculeComparator</code> class is then used to compare the polymer and molecule using the combined featurizers. The <code>compare</code> method returns the difference between the polymer and the molecule in terms of the features extracted by the featurizers.</p>"},{"location":"how_to_guides/#adding-terminal-groups-to-polymers-sidechain-backbone-and-full-polymer","title":"Adding terminal groups to polymers (sidechain, backbone and full polymer)","text":"<p>When working with polymers, you may want to add terminal groups to the polymer backbone or sidechains. This can be done by specifying the terminal groups in the <code>terminal_groups</code> attribute of the <code>Polymer</code> class.</p> <pre><code>from polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import NumBackBoneFeaturizer, BackBoneFeaturizer, MultipleFeaturizer, FullPolymerFeaturizer\nfrom polymetrix.featurizers.chemical_featurizer import NumRings, NumAtoms, TopologicalSurfaceArea\n\n\npolymer = Polymer.from_psmiles(\"[*]=C(C#N)NC(=O)c1ccc(C(=O)NC(=[*])C#N)cc1\")\n\n# Add terminal groups for the sidechain and backbone\npolymer.backbone_terminal_groups = {\"[*]\": \"*O\"}\npolymer.sidechain_terminal_groups = {\"[*]\": \"*CCO\"}\n\n# Featurizers for the backbone and sidechain with terminal groups\nbackbone_featurizers = [\n    NumBackBoneFeaturizer(),\n    BackBoneFeaturizer(NumRings()),\n    BackBoneFeaturizer(NumAtoms()),\n    BackBoneFeaturizer(TopologicalSurfaceArea()),\n]\n\nbackbone_multi_featurizer = MultipleFeaturizer(backbone_featurizers)\nfeatures = backbone_multi_featurizer.featurize(polymer)\n\n# Sidechain featurizers with terminal groups\nsidechain_featurizers = [\n    NumSideChainFeaturizer(),\n    SideChainFeaturizer(NumAtoms()),\n    SideChainFeaturizer(NumHBondDonors()),\n    SideChainFeaturizer(TopologicalSurfaceArea()),\n]\n\nsidechain_multi_featurizer = MultipleFeaturizer(sidechain_featurizers)\nfeatures = sidechain_multi_featurizer.featurize(polymer)\n\n# Full polymer featurizers with terminal groups\nfull_polymer_featurizers = [\n    FullPolymerFeaturizer(NumAtoms()),\n    FullPolymerFeaturizer(NumHBondDonors()),\n    FullPolymerFeaturizer(TopologicalSurfaceArea()),\n]\nfull_multi_featurizer = MultipleFeaturizer(full_polymer_featurizers)\nfeatures = full_multi_featurizer.featurize(polymer)\n</code></pre> <p>The above code demonstrates how to add terminal groups to the polymer backbone and sidechains, and how to apply featurizers to the polymer with these terminal groups. The <code>backbone_terminal_groups</code> and <code>sidechain_terminal_groups</code> attributes are used to specify the terminal groups for the backbone and sidechains, respectively. The featurizers are then applied to the polymer with the terminal groups included.</p>"},{"location":"how_to_guides/#datasets","title":"Datasets","text":""},{"location":"how_to_guides/#loading-datasets","title":"Loading datasets","text":"<p>Additionally, you can load the curated dataset for glass transition temperature (Tg) data for the polymers using this package.</p> <pre><code># Import necessary modules\nfrom polymetrix.datasets import CuratedGlassTempDataset\n\n# Load the dataset\ndataset = CuratedGlassTempDataset()\n</code></pre> <p>The dataset will be a class object that contains the data for the curated dataset for glass transition temperature (Tg) data for the polymers along with chemical and topological featurizers for the polymers.</p>"},{"location":"how_to_guides/#obtaining-features-and-labels-from-the-dataset","title":"Obtaining features and labels from the dataset","text":"<pre><code>from polymetrix.datasets import CuratedGlassTempDataset\n\ndataset = CuratedGlassTempDataset()\nfeatures = dataset.get_features(idx=range(len(dataset))\ntarget = dataset.get_labels(idx=range(len(dataset)))\n</code></pre> <p>This will output the array of features and labels for the dataset, Which can be used for training/testing the model.</p>"},{"location":"how_to_guides/#obtaining-a-subset-of-the-dataset","title":"Obtaining a subset of the dataset","text":"<pre><code>from polymetrix.datasets import CuratedGlassTempDataset\n\ndataset = CuratedGlassTempDataset()\nfeatures = dataset.get_features(idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntarget = dataset.get_labels(idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n</code></pre> <p>This will output the array of features and labels for the first 10 data points in the dataset, Which can be used for training/testing the model.</p>"},{"location":"installation/","title":"Installation","text":"<p>The most recent code can be installed directly from GitHub with:</p> <pre><code>$ pip install git+https://github.com/lamalab-org/PolyMetriX.git\n</code></pre> <p>To install in development mode, use the following:</p> <pre><code>$ git clone https://github.com/lamalab-org/PolyMetriX.git\n$ cd polymetrix\n$ pip install -e .\n</code></pre>"},{"location":"polymer/","title":"Polymer Graphs","text":"<p>The <code>Polymer</code> class in <code>PolyMetriX</code> is designed to distinguish between the backbone and side chains of a polymer. It identifies which atoms in a polymer belong to the backbone and which belong to the side chains. </p> <p>This is achieved by converting the <code>PSMILES</code> representation into a graph-based representation using the <code>NetworkX</code> library. By utilizing graph theory concepts such as <code>shortest path</code>, <code>cycles</code>, <code>connected components</code>, and the <code>degree</code> of nodes, the <code>Polymer</code> class classifies the backbone and side chain atoms within a polymer.</p>"},{"location":"polymer/#graph-theory-concepts","title":"Graph Theory Concepts","text":"<ol> <li>Nodes and Edges: In the context of a polymer, nodes represent atoms and edges represent bonds between atoms.</li> <li>Shortest Path: The shortest path between two nodes is the smallest number of edges that must be traversed to reach one node from the other.</li> <li>Cycles: A cycle is a path that starts and ends at the same node, forming a closed loop.</li> <li>Connected Components: A connected component is a subgraph in which every node is reachable from every other node.</li> <li>Degree of a Node: The degree of a node is the number of edges incident to that node.</li> </ol>"},{"location":"polymer/#distinguishing-backbone-and-side-chains","title":"Distinguishing Backbone and Side Chains","text":"<p>The process of classifying nodes into backbone and side chain components is handled by the <code>classify_backbone_and_sidechains</code> helper function in the <code>Polymer</code> class. This function uses the following steps to identify the backbone and side chain atoms:</p> <ol> <li> <p>Graph Construction: The <code>PSMILES</code> representation of the polymer is converted into a graph using the <code>NetworkX</code> library. </p> </li> <li> <p>Shortest Paths Between Connection Points: The algorithm identifies all shortest paths between pairs of asterisk (*) nodes. These paths often correspond to the main chain or repeating units of the polymer, forming the initial backbone.</p> </li> <li> <p>Cycles Detection: Cycles (closed loops) in the graph that include nodes from these shortest paths are identified. In polymers, cycles can represent cyclic structures (e.g.,(aromatic) rings) within the backbone. Nodes in these cycles are added to the backbone.</p> </li> <li> <p>Degree-1 Nodes: Nodes with a degree of 1 (connected to only one other node) that are attached to the backbone are also included in the backbone. These are typically terminal groups.</p> </li> <li> <p>Connected Components: The remaining nodes in the graph that are not part of the backbone are considered side chain atoms. These atoms are connected to the backbone but are not part of the main chain.</p> </li> </ol> <p>By following these steps, the <code>Polymer</code> class can accurately distinguish between the backbone and side chain atoms of a polymer.</p>"},{"location":"polymer/#step-by-step-example","title":"Step-by-Step Example","text":"<p>Let\u2019s walk through an example using a simple polymer, Poly(isobutyl acrylate) represented by the following <code>PSMILES</code> notation:</p> <pre><code>PSMILES: [*]CC(C(OCC(C)C)=O)[*]\n</code></pre> <p>Step 1: Initialize the Polymer <pre><code>from polymetrix.featurizers.polymer import Polymer\npsmiles = Polymer(\"[*]CC(C(OCC(C)C)=O)[*]\")\npolymer = Polymer.from_psmiles(psmiles)\n</code></pre> The PSMILES is parsed into an <code>RDKit</code> molecule and converted to a <code>NetworkX</code> graph (<code>_mol_to_nx</code>).</p> <p>Step 2: Identify Connection Points <pre><code>connection_points = polymer.get_connection_points()\nprint(\"Connection Points:\", connection_points)\n</code></pre> Output: <pre><code>Connection Points: [0, 10]\n</code></pre> The * atoms (nodes 0 and 10) are identified as connection points.</p> <p>Step 3: Find Shortest Paths The <code>find_shortest_paths_between_stars</code> function computes the shortest path between nodes 0 and 10. <pre><code>from polymetrix.featurizers.polymer import find_shortest_paths_between_stars\npaths = find_shortest_paths_between_stars(polymer.graph)\nprint(\"Shortest Paths:\", paths)\n</code></pre> <pre><code>Output:\nShortest Paths: [[0, 1, 2, 10]]\n</code></pre> Step 4: Identify Cycles The <code>find_cycles_including_paths</code> function identifies cycles that include the shortest paths found in the previous step. <pre><code>from polymetrix.featurizers.polymer import find_cycles_including_paths\ncycles = find_cycles_including_paths(polymer.graph, paths)\nprint(\"Cycles:\", cycles)\n</code></pre> Output: <pre><code>Cycles: []\n</code></pre> Here, there are no cycles that include the shortest paths.</p> <p>Step 5: Classify Backbone and Sidechains The <code>classify_backbone_and_sidechains</code> function combines the paths and adds degree-1 nodes <pre><code>from polymetrix.featurizers.polymer import classify_backbone_and_sidechains\nbackbone, sidechains = classify_backbone_and_sidechains(polymer.graph, paths)\nprint(\"Backbone Nodes:\", backbone)\nprint(\"Sidechain Nodes:\", sidechains)\n</code></pre> Output: <pre><code>Backbone Nodes: [0, 1, 2, 10]\nSidechain Nodes: [3, 4, 5, 6, 7, 8, 9]\n</code></pre> The backbone nodes are identified as nodes 0, 1, 2, and 10, while the side chain nodes are the remaining nodes.</p> <p>The below figure illustrates the classification of backbone and side chain atoms in the polymer graph: </p>"},{"location":"splitters/","title":"Splitters","text":"<p>Splitters are used to split the dataset into training, validation, and test sets. The splitters are designed to ensure that the training, validation, and test sets are distinct and do not overlap. The splitter are used to prevent the data leakage and these splitters tests the model's generalization ability. In the PolyMetriX, we have implemented only Tgsplitter. The other splitters like KennardStoneSplitter and LOCOCVSplitter are imported from the MOFDScribe package. See documentation for MOFDScribe for more information on these splitters here.</p>"},{"location":"splitters/#tgsplitter","title":"TgSplitter","text":"<p>Splitter that uses the glass transition temperature (Tg) to split the dataset.</p> <p>This splitter sorts structures by their Tg values and groups them using quantile binning. The grouping helps ensure different folds contain distinct Tg ranges, creating stringent validation conditions. The splitter also ensures that different folds contain different ranges of Tg values. This splitter can also be called as property based extrapolation splitter.</p>"},{"location":"splitters/#example","title":"Example","text":"<pre><code>from polymetrix.datasets import CuratedGlassTempDataset\nfrom polymetrix.splitters.splitters import TgSplitter\n\ndataset = CuratedGlassTempDataset(version, url)\n\nsplitter = TgSplitter(\n    ds=dataset,\n    tg_q=np.linspace(0, 1, 3), # Quantile bins for Tg values\n    shuffle=True,\n    random_state=42\n)\n\ntrain_idx, valid_idx, test_idx = splitter.train_valid_test_split(frac_train=0.6, frac_valid=0.1)\nprint(f\"Train: {len(train_idx)}, Valid: {len(valid_idx)}, Test: {len(test_idx)}\")\n</code></pre> <p>The splitter outputs the indices for each subset, ensuring that the training, validation, and test sets contain distinct Tg ranges. The splitter also ensures that the training, validation, and test sets contain different ranges of Tg values.</p>"},{"location":"splitters/#kennardstonesplitter","title":"KennardStoneSplitter","text":"<p>Splitter that uses the Kennard-Stone algorithm to split the dataset. This method selects the most dissimilar data points as the training set and the remaining data points as the test set. The splitter ensures that the training set contains the most diverse data points. To know more about the Kennard-Stone algorithm, see the documentation here.</p>"},{"location":"splitters/#example_1","title":"Example","text":"<pre><code>from polymetrix.datasets import CuratedGlassTempDataset\nfrom mofdscribe.splitters.splitters import KennardStoneSplitter\n\ndataset = CuratedGlassTempDataset(version, url)\nfeature_names = dataset.available_features \n\nsplitter = KennardStoneSplitter(\n    ds=dataset,\n    feature_names=feature_names,  \n    scale=True,  \n    centrality_measure=\"mean\",\n    metric=\"euclidean\"\n)\n\n# Different splitting methods\n\n# Train-test split\ntrain_idx, test_idx = splitter.train_test_split(frac_train=0.7) \n\n# Train-validation-test split\ntrain_idx, valid_idx, test_idx = splitter.train_valid_test_split(frac_train=0.7, frac_valid=0.15)\n\n# 5-fold cross-validation\nfor fold, (train_index, test_index) in enumerate(splitter.k_fold(k=5)):\n    print(f\"Fold {fold}: Train: {len(train_index)}, Test: {len(test_index)}\")\n</code></pre> <p>The splitter outputs the indices for each subset, using Kennard-Stone's deterministic selection to ensure the training set contains maximally diverse, space-filling samples that optimally represent the feature space. The validation/test sets then automatically inherit structurally distinct data points not selected in this representative training subset.</p>"},{"location":"splitters/#lococvsplitter","title":"LOCOCVSplitter","text":"<p>Leave-One-Cluster-Out Cross-Validation (LOCOCV) splitter that uses the cluster information to split the dataset. This method ensures that the training and validation sets contain distinct clusters. There is no overlap between the training and validation sets, and the training set contains all clusters except the one in the validation set. To know more about the LOCOCV algorithm, see the documentation here.</p>"},{"location":"splitters/#example_2","title":"Example","text":"<p><pre><code>from polymetrix.datasets import CuratedGlassTempDataset\nfrom mofdscribe.splitters.splitters import LOCOCV\n\ndataset = CuratedGlassTempDataset(version, url)\nfeature_names = dataset.available_features \n\nloco = LOCOCV(\n    ds=dataset,\n    feature_names=feature_names, \n    n_pca_components=2,  \n    random_state=42,\n    scaled=True  \n)\n\n# Different splitting methods\n\n# Train-test split  \ntrain_idx, test_idx = loco.train_test_split(frac_train=0.7)\n\n# Train-validation-test split\ntrain_idx, valid_idx, test_idx = loco.train_valid_test_split(frac_train=0.7, frac_valid=0.15)\n\n# 5-fold cross-validation\nfor fold, (train_index, test_index) in enumerate(loco.k_fold(k=5)):\n    print(f\"Fold {fold}: Train: {len(train_index)}, Test: {len(test_index)}\")\n</code></pre> The resulting output will be the number of indices in the training, validation, and test sets. The splitter will ensure that the training and validation sets contain distinct clusters.</p>"},{"location":"train_test_splitters/","title":"Training model","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\n</pre> %reload_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import numpy as np\nimport logging\nfrom polymetrix.datasets.curated_tg_dataset import CuratedGlassTempDataset\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split, KFold\nfrom mofdscribe.splitters.splitters import LOCOCV\nfrom polymetrix.splitters.splitters import TgSplitter, PolymerClassSplitter\n</pre> import numpy as np import logging from polymetrix.datasets.curated_tg_dataset import CuratedGlassTempDataset from sklearn.ensemble import GradientBoostingRegressor from sklearn.metrics import mean_absolute_error from sklearn.model_selection import train_test_split, KFold from mofdscribe.splitters.splitters import LOCOCV from polymetrix.splitters.splitters import TgSplitter, PolymerClassSplitter In\u00a0[3]: Copied! <pre># Configuration\nRANDOM_STATE = 42\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n\n# Load dataset\ndataset = CuratedGlassTempDataset(\n    feature_levels=[\"sidechainlevel\", \"backbonelevel\", \"fullpolymerlevel\"]\n)\n\n# Extract features and labels\nX = dataset.get_features(idx=np.arange(len(dataset)))\ny = dataset.get_labels(idx=np.arange(len(dataset)), label_names=[\"labels.Exp_Tg(K)\"]).ravel()\n\n# Dataset info logging\nlogging.info(f\"Number of samples: {len(dataset)}\")\nlogging.info(f\"Feature columns: {dataset.available_features}\")\nlogging.info(f\"Active feature levels: {dataset.active_feature_levels}\")\nlogging.info(f\"Available metadata: {dataset.meta_info}\")\n</pre> # Configuration RANDOM_STATE = 42  # Initialize logging logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")  # Load dataset dataset = CuratedGlassTempDataset(     feature_levels=[\"sidechainlevel\", \"backbonelevel\", \"fullpolymerlevel\"] )  # Extract features and labels X = dataset.get_features(idx=np.arange(len(dataset))) y = dataset.get_labels(idx=np.arange(len(dataset)), label_names=[\"labels.Exp_Tg(K)\"]).ravel()  # Dataset info logging logging.info(f\"Number of samples: {len(dataset)}\") logging.info(f\"Feature columns: {dataset.available_features}\") logging.info(f\"Active feature levels: {dataset.active_feature_levels}\") logging.info(f\"Available metadata: {dataset.meta_info}\") <pre>INFO: Number of samples: 7367\n</pre> <pre>INFO: Feature columns: ['sidechainlevel.features.num_atoms_sidechainfeaturizer_sum', 'sidechainlevel.features.num_atoms_sidechainfeaturizer_mean', 'sidechainlevel.features.num_atoms_sidechainfeaturizer_max', 'sidechainlevel.features.num_atoms_sidechainfeaturizer_min', 'sidechainlevel.features.numsidechainfeaturizer', 'sidechainlevel.features.sidechainlength_to_star_attachment_distance_ratio_mean', 'sidechainlevel.features.sidechainlength_to_star_attachment_distance_ratio_min', 'sidechainlevel.features.sidechainlength_to_star_attachment_distance_ratio_max', 'sidechainlevel.features.sidechainlength_to_star_attachment_distance_ratio_sum', 'sidechainlevel.features.star_to_sidechain_min_distance_mean', 'sidechainlevel.features.star_to_sidechain_min_distance_min', 'sidechainlevel.features.star_to_sidechain_min_distance_max', 'sidechainlevel.features.star_to_sidechain_min_distance_sum', 'sidechainlevel.features.num_diverse_sidechains', 'sidechainlevel.features.balaban_j_index_sidechainfeaturizer_sum', 'sidechainlevel.features.num_hbond_donors_sidechainfeaturizer_sum', 'sidechainlevel.features.num_hbond_acceptors_sidechainfeaturizer_sum', 'sidechainlevel.features.num_rotatable_bonds_sidechainfeaturizer_sum', 'sidechainlevel.features.num_rings_sidechainfeaturizer_sum', 'sidechainlevel.features.num_non_aromatic_rings_sidechainfeaturizer_sum', 'sidechainlevel.features.num_aromatic_rings_sidechainfeaturizer_sum', 'sidechainlevel.features.topological_surface_area_sidechainfeaturizer_sum', 'sidechainlevel.features.fraction_bicyclic_rings_sidechainfeaturizer_sum', 'sidechainlevel.features.num_aliphatic_heterocycles_sidechainfeaturizer_sum', 'sidechainlevel.features.slogp_vsa1_sidechainfeaturizer_sum', 'sidechainlevel.features.molecular_weight_sidechainfeaturizer_sum', 'sidechainlevel.features.sp3_carbon_count_sidechainfeaturizer_sum', 'sidechainlevel.features.sp2_carbon_count_sidechainfeaturizer_sum', 'sidechainlevel.features.max_estate_index_sidechainfeaturizer_sum', 'sidechainlevel.features.smr_vsa5_sidechainfeaturizer_sum', 'sidechainlevel.features.fp_density_morgan1_sidechainfeaturizer_sum', 'sidechainlevel.features.total_halogens_sidechainfeaturizer_sum', 'sidechainlevel.features.fluorine_count_sidechainfeaturizer_sum', 'sidechainlevel.features.chlorine_count_sidechainfeaturizer_sum', 'sidechainlevel.features.bromine_count_sidechainfeaturizer_sum', 'sidechainlevel.features.single_bonds_sidechainfeaturizer_sum', 'sidechainlevel.features.double_bonds_sidechainfeaturizer_sum', 'sidechainlevel.features.triple_bonds_sidechainfeaturizer_sum', 'sidechainlevel.features.bridging_rings_count_sidechainfeaturizer_sum', 'sidechainlevel.features.max_ring_size_sidechainfeaturizer_sum', 'sidechainlevel.features.heteroatom_density_sidechainfeaturizer_sum', 'sidechainlevel.features.heteroatom_count_sidechainfeaturizer_sum', 'backbonelevel.features.num_atoms_sum_backbonefeaturizer', 'backbonelevel.features.numbackbonefeaturizer', 'backbonelevel.features.balaban_j_index_sum_backbonefeaturizer', 'backbonelevel.features.num_hbond_donors_sum_backbonefeaturizer', 'backbonelevel.features.num_hbond_acceptors_sum_backbonefeaturizer', 'backbonelevel.features.num_rotatable_bonds_sum_backbonefeaturizer', 'backbonelevel.features.num_rings_sum_backbonefeaturizer', 'backbonelevel.features.num_non_aromatic_rings_sum_backbonefeaturizer', 'backbonelevel.features.num_aromatic_rings_sum_backbonefeaturizer', 'backbonelevel.features.topological_surface_area_sum_backbonefeaturizer', 'backbonelevel.features.fraction_bicyclic_rings_sum_backbonefeaturizer', 'backbonelevel.features.num_aliphatic_heterocycles_sum_backbonefeaturizer', 'backbonelevel.features.slogp_vsa1_sum_backbonefeaturizer', 'backbonelevel.features.molecular_weight_sum_backbonefeaturizer', 'backbonelevel.features.sp3_carbon_count_sum_backbonefeaturizer', 'backbonelevel.features.sp2_carbon_count_sum_backbonefeaturizer', 'backbonelevel.features.max_estate_index_sum_backbonefeaturizer', 'backbonelevel.features.smr_vsa5_sum_backbonefeaturizer', 'backbonelevel.features.fp_density_morgan1_sum_backbonefeaturizer', 'backbonelevel.features.total_halogens_sum_backbonefeaturizer', 'backbonelevel.features.fluorine_count_sum_backbonefeaturizer', 'backbonelevel.features.chlorine_count_sum_backbonefeaturizer', 'backbonelevel.features.bromine_count_sum_backbonefeaturizer', 'backbonelevel.features.single_bonds_sum_backbonefeaturizer', 'backbonelevel.features.double_bonds_sum_backbonefeaturizer', 'backbonelevel.features.triple_bonds_sum_backbonefeaturizer', 'backbonelevel.features.bridging_rings_count_sum_backbonefeaturizer', 'backbonelevel.features.max_ring_size_sum_backbonefeaturizer', 'backbonelevel.features.heteroatom_density_sum_backbonefeaturizer', 'backbonelevel.features.heteroatom_count_sum_backbonefeaturizer', 'fullpolymerlevel.features.balaban_j_index_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_hbond_donors_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_hbond_acceptors_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_rotatable_bonds_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_rings_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_non_aromatic_rings_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_aromatic_rings_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.topological_surface_area_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.fraction_bicyclic_rings_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.num_aliphatic_heterocycles_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.slogp_vsa1_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.molecular_weight_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.sp3_carbon_count_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.sp2_carbon_count_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.max_estate_index_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.smr_vsa5_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.fp_density_morgan1_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.total_halogens_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.fluorine_count_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.chlorine_count_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.bromine_count_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.single_bonds_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.double_bonds_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.triple_bonds_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.bridging_rings_count_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.max_ring_size_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.heteroatom_density_sum_fullpolymerfeaturizer', 'fullpolymerlevel.features.heteroatom_count_sum_fullpolymerfeaturizer']\n</pre> <pre>INFO: Active feature levels: ['sidechainlevel', 'backbonelevel', 'fullpolymerlevel']\n</pre> <pre>INFO: Available metadata: ['meta.polymer', 'meta.source', 'meta.tg_range', 'meta.tg_values', 'meta.num_of_points', 'meta.std', 'meta.reliability', 'meta.polymer_class']\n</pre> In\u00a0[4]: Copied! <pre>def train_and_evaluate(X_train, X_test, y_train, y_test):\n    model = GradientBoostingRegressor(random_state=RANDOM_STATE)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    return mean_absolute_error(y_test, preds)\n\ndef log_splits(X_train, X_valid, X_test):\n    \"\"\"Log split sizes\"\"\"\n    logging.info(f\"Training set: {len(X_train)} samples\")\n    logging.info(f\"Validation set: {len(X_valid) if X_valid is not None else 0} samples\") \n    logging.info(f\"Test set: {len(X_test)} samples\")\n</pre> def train_and_evaluate(X_train, X_test, y_train, y_test):     model = GradientBoostingRegressor(random_state=RANDOM_STATE)     model.fit(X_train, y_train)     preds = model.predict(X_test)     return mean_absolute_error(y_test, preds)  def log_splits(X_train, X_valid, X_test):     \"\"\"Log split sizes\"\"\"     logging.info(f\"Training set: {len(X_train)} samples\")     logging.info(f\"Validation set: {len(X_valid) if X_valid is not None else 0} samples\")      logging.info(f\"Test set: {len(X_test)} samples\") In\u00a0[5]: Copied! <pre># Random split\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X, y, test_size=0.3, random_state=RANDOM_STATE\n)\nX_valid, X_test, y_valid, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE\n)\n\nlog_splits(X_train, X_valid, X_test)\n\n# Evaluation\nvalid_mae = train_and_evaluate(X_train, X_valid, y_train, y_valid)\ntest_mae = train_and_evaluate(X_train, X_test, y_train, y_test)\nlogging.info(f\"Validation MAE: {valid_mae:.2f}, Test MAE: {test_mae:.2f}\")\n</pre> # Random split X_train, X_temp, y_train, y_temp = train_test_split(     X, y, test_size=0.3, random_state=RANDOM_STATE ) X_valid, X_test, y_valid, y_test = train_test_split(     X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE )  log_splits(X_train, X_valid, X_test)  # Evaluation valid_mae = train_and_evaluate(X_train, X_valid, y_train, y_valid) test_mae = train_and_evaluate(X_train, X_test, y_train, y_test) logging.info(f\"Validation MAE: {valid_mae:.2f}, Test MAE: {test_mae:.2f}\") <pre>INFO: Training set: 5156 samples\n</pre> <pre>INFO: Validation set: 1105 samples\n</pre> <pre>INFO: Test set: 1106 samples\n</pre> <pre>INFO: Validation MAE: 32.40, Test MAE: 34.29\n</pre> In\u00a0[6]: Copied! <pre>kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\ncv_scores = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n    fold_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx])\n    cv_scores.append(fold_mae)\n    logging.info(f\"Fold {fold} MAE: {fold_mae:.2f}\")\n\nlogging.info(f\"CV MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\")\n</pre> kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE) cv_scores = []  for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):     fold_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx])     cv_scores.append(fold_mae)     logging.info(f\"Fold {fold} MAE: {fold_mae:.2f}\")  logging.info(f\"CV MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\")  <pre>INFO: Fold 1 MAE: 33.48\n</pre> <pre>INFO: Fold 2 MAE: 33.85\n</pre> <pre>INFO: Fold 3 MAE: 32.67\n</pre> <pre>INFO: Fold 4 MAE: 34.19\n</pre> <pre>INFO: Fold 5 MAE: 32.32\n</pre> <pre>INFO: CV MAE: 33.30 \u00b1 0.70\n</pre> In\u00a0[7]: Copied! <pre>loco = LOCOCV(\n    ds=dataset,\n    feature_names=dataset.available_features,\n    n_pca_components=3,\n    random_state=RANDOM_STATE,\n    scaled=True\n)\n\n# Single split\ntrain_idx, valid_idx, test_idx = loco.train_valid_test_split()\nlog_splits(X[train_idx], X[valid_idx], X[test_idx])\n\n# Evaluation\nvalid_mae = train_and_evaluate(X[train_idx], X[valid_idx], y[train_idx], y[valid_idx])\ntest_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx])\nlogging.info(f\"LOCOCV MAE: Valid {valid_mae:.2f}, Test {test_mae:.2f}\")\n</pre> loco = LOCOCV(     ds=dataset,     feature_names=dataset.available_features,     n_pca_components=3,     random_state=RANDOM_STATE,     scaled=True )  # Single split train_idx, valid_idx, test_idx = loco.train_valid_test_split() log_splits(X[train_idx], X[valid_idx], X[test_idx])  # Evaluation valid_mae = train_and_evaluate(X[train_idx], X[valid_idx], y[train_idx], y[valid_idx]) test_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx]) logging.info(f\"LOCOCV MAE: Valid {valid_mae:.2f}, Test {test_mae:.2f}\") <pre>INFO: Training set: 3194 samples\n</pre> <pre>INFO: Validation set: 980 samples\n</pre> <pre>INFO: Test set: 3193 samples\n</pre> <pre>INFO: LOCOCV MAE: Valid 48.16, Test 42.82\n</pre> In\u00a0[8]: Copied! <pre># LOCOCV 5-Fold\nloco_cv = LOCOCV(\n    ds=dataset,\n    feature_names=dataset.available_features,\n    n_pca_components=5,  # For 5-fold CV\n    random_state=RANDOM_STATE,\n    scaled=True\n)\n\ncv_scores = []\nfor fold, (train_idx, test_idx) in enumerate(loco_cv.k_fold(k=5), 1):\n    fold_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx])\n    cv_scores.append(fold_mae)\n    logging.info(f\"LOCOCV Fold {fold} MAE: {fold_mae:.2f}\")\n\nlogging.info(f\"LOCOCV 5-Fold MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\")\n</pre> # LOCOCV 5-Fold loco_cv = LOCOCV(     ds=dataset,     feature_names=dataset.available_features,     n_pca_components=5,  # For 5-fold CV     random_state=RANDOM_STATE,     scaled=True )  cv_scores = [] for fold, (train_idx, test_idx) in enumerate(loco_cv.k_fold(k=5), 1):     fold_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx])     cv_scores.append(fold_mae)     logging.info(f\"LOCOCV Fold {fold} MAE: {fold_mae:.2f}\")  logging.info(f\"LOCOCV 5-Fold MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\")  <pre>INFO: LOCOCV Fold 1 MAE: 35.51\n</pre> <pre>INFO: LOCOCV Fold 2 MAE: 39.48\n</pre> <pre>INFO: LOCOCV Fold 3 MAE: 37.49\n</pre> <pre>INFO: LOCOCV Fold 4 MAE: 56.57\n</pre> <pre>INFO: LOCOCV Fold 5 MAE: 37.71\n</pre> <pre>INFO: LOCOCV 5-Fold MAE: 41.35 \u00b1 7.71\n</pre> In\u00a0[9]: Copied! <pre>tg_splitter = TgSplitter(\n    ds=dataset,\n    tg_q=np.linspace(0, 1, 5),\n    shuffle=True,\n    random_state=RANDOM_STATE\n)\n\n# Single split\ntrain_idx, valid_idx, test_idx = tg_splitter.train_valid_test_split(\n    frac_train=0.7,\n    frac_valid=0.1\n)\nlog_splits(X[train_idx], X[valid_idx], X[test_idx])\n\n# Evaluation\nvalid_mae = train_and_evaluate(X[train_idx], X[valid_idx], y[train_idx], y[valid_idx])\ntest_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx])\nlogging.info(f\"TgSplitter MAE: Valid {valid_mae:.2f}, Test {test_mae:.2f}\")\n</pre> tg_splitter = TgSplitter(     ds=dataset,     tg_q=np.linspace(0, 1, 5),     shuffle=True,     random_state=RANDOM_STATE )  # Single split train_idx, valid_idx, test_idx = tg_splitter.train_valid_test_split(     frac_train=0.7,     frac_valid=0.1 ) log_splits(X[train_idx], X[valid_idx], X[test_idx])  # Evaluation valid_mae = train_and_evaluate(X[train_idx], X[valid_idx], y[train_idx], y[valid_idx]) test_mae = train_and_evaluate(X[train_idx], X[test_idx], y[train_idx], y[test_idx]) logging.info(f\"TgSplitter MAE: Valid {valid_mae:.2f}, Test {test_mae:.2f}\") <pre>INFO: Training set: 3693 samples\n</pre> <pre>INFO: Validation set: 1842 samples\n</pre> <pre>INFO: Test set: 1832 samples\n</pre> <pre>INFO: TgSplitter MAE: Valid 34.13, Test 88.98\n</pre> In\u00a0[10]: Copied! <pre># TgSplitter Grouped K-Fold\ntg_splitter_cv = TgSplitter(\n    ds=dataset,\n    tg_q=np.linspace(0, 1, 6),  # 5 groups for 5-fold\n    shuffle=True,\n    random_state=RANDOM_STATE\n)\n\ngroups = tg_splitter_cv._get_groups()\nunique_groups = np.unique(groups)\ncv_scores = []\n\nfor fold, test_group in enumerate(unique_groups, 1):\n    train_mask = groups != test_group\n    test_mask = groups == test_group\n    \n    fold_mae = train_and_evaluate(X[train_mask], X[test_mask], y[train_mask], y[test_mask])\n    cv_scores.append(fold_mae)\n    logging.info(f\"TgSplitter Fold {fold} MAE: {fold_mae:.2f}\")\n\nlogging.info(f\"TgSplitter 5-Fold MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\")\n</pre> # TgSplitter Grouped K-Fold tg_splitter_cv = TgSplitter(     ds=dataset,     tg_q=np.linspace(0, 1, 6),  # 5 groups for 5-fold     shuffle=True,     random_state=RANDOM_STATE )  groups = tg_splitter_cv._get_groups() unique_groups = np.unique(groups) cv_scores = []  for fold, test_group in enumerate(unique_groups, 1):     train_mask = groups != test_group     test_mask = groups == test_group          fold_mae = train_and_evaluate(X[train_mask], X[test_mask], y[train_mask], y[test_mask])     cv_scores.append(fold_mae)     logging.info(f\"TgSplitter Fold {fold} MAE: {fold_mae:.2f}\")  logging.info(f\"TgSplitter 5-Fold MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\") <pre>INFO: TgSplitter Fold 1 MAE: 89.37\n</pre> <pre>INFO: TgSplitter Fold 2 MAE: 33.59\n</pre> <pre>INFO: TgSplitter Fold 3 MAE: 47.56\n</pre> <pre>INFO: TgSplitter Fold 4 MAE: 45.61\n</pre> <pre>INFO: TgSplitter Fold 5 MAE: 92.25\n</pre> <pre>INFO: TgSplitter 5-Fold MAE: 61.68 \u00b1 24.28\n</pre> In\u00a0[11]: Copied! <pre># Perform cross-validation\npolymer_class_splitter = PolymerClassSplitter(\n    ds=dataset,\n    column_name=\"meta.polymer_class\",\n    shuffle=True,\n    random_state=RANDOM_STATE\n)\ngroups = polymer_class_splitter._get_groups()\nunique_groups = np.unique(groups)\ncv_scores = []\n\nfor fold, test_group in enumerate(unique_groups, 1):\n    train_mask = groups != test_group\n    test_mask = groups == test_group\n    \n    X_train, X_test = X[train_mask], X[test_mask]\n    y_train, y_test = y[train_mask], y[test_mask]\n\n    fold_mae = train_and_evaluate(X_train, X_test, y_train, y_test)\n    cv_scores.append(fold_mae)\n    logging.info(f\"PolymerClassSplitter Fold {fold} MAE: {fold_mae:.2f}\")\n    \nlogging.info(f\"PolymerClassSplitter 5-Fold MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\")\n</pre>  # Perform cross-validation polymer_class_splitter = PolymerClassSplitter(     ds=dataset,     column_name=\"meta.polymer_class\",     shuffle=True,     random_state=RANDOM_STATE ) groups = polymer_class_splitter._get_groups() unique_groups = np.unique(groups) cv_scores = []  for fold, test_group in enumerate(unique_groups, 1):     train_mask = groups != test_group     test_mask = groups == test_group          X_train, X_test = X[train_mask], X[test_mask]     y_train, y_test = y[train_mask], y[test_mask]      fold_mae = train_and_evaluate(X_train, X_test, y_train, y_test)     cv_scores.append(fold_mae)     logging.info(f\"PolymerClassSplitter Fold {fold} MAE: {fold_mae:.2f}\")      logging.info(f\"PolymerClassSplitter 5-Fold MAE: {np.mean(cv_scores):.2f} \u00b1 {np.std(cv_scores):.2f}\") <pre>INFO: PolymerClassSplitter Fold 1 MAE: 27.31\n</pre> <pre>INFO: PolymerClassSplitter Fold 2 MAE: 41.66\n</pre> <pre>INFO: PolymerClassSplitter Fold 3 MAE: 55.80\n</pre> <pre>INFO: PolymerClassSplitter Fold 4 MAE: 56.94\n</pre> <pre>INFO: PolymerClassSplitter Fold 5 MAE: 36.62\n</pre> <pre>INFO: PolymerClassSplitter Fold 6 MAE: 54.76\n</pre> <pre>INFO: PolymerClassSplitter Fold 7 MAE: 33.94\n</pre> <pre>INFO: PolymerClassSplitter Fold 8 MAE: 0.43\n</pre> <pre>INFO: PolymerClassSplitter Fold 9 MAE: 56.45\n</pre> <pre>INFO: PolymerClassSplitter Fold 10 MAE: 37.78\n</pre> <pre>INFO: PolymerClassSplitter Fold 11 MAE: 44.94\n</pre> <pre>INFO: PolymerClassSplitter Fold 12 MAE: 32.84\n</pre> <pre>INFO: PolymerClassSplitter Fold 13 MAE: 40.48\n</pre> <pre>INFO: PolymerClassSplitter Fold 14 MAE: 34.29\n</pre> <pre>INFO: PolymerClassSplitter Fold 15 MAE: 43.33\n</pre> <pre>INFO: PolymerClassSplitter Fold 16 MAE: 87.03\n</pre> <pre>INFO: PolymerClassSplitter Fold 17 MAE: 51.60\n</pre> <pre>INFO: PolymerClassSplitter Fold 18 MAE: 46.00\n</pre> <pre>INFO: PolymerClassSplitter Fold 19 MAE: 46.32\n</pre> <pre>INFO: PolymerClassSplitter Fold 20 MAE: 60.15\n</pre> <pre>INFO: PolymerClassSplitter Fold 21 MAE: 47.20\n</pre> <pre>INFO: PolymerClassSplitter Fold 22 MAE: 49.00\n</pre> <pre>INFO: PolymerClassSplitter 5-Fold MAE: 44.77 \u00b1 15.65\n</pre>"},{"location":"train_test_splitters/#evaluation-and-modeling-functions","title":"Evaluation and modeling functions\u00b6","text":""},{"location":"train_test_splitters/#1-random-split","title":"1: Random Split\u00b6","text":"<p>Traditional train/valid/test split</p>"},{"location":"train_test_splitters/#random-kfold-split","title":"Random kfold split\u00b6","text":""},{"location":"train_test_splitters/#2-leave-cluster-out-cross-validation","title":"2: Leave-cluster-out cross-validation\u00b6","text":""},{"location":"train_test_splitters/#2-leave-cluster-out-cross-validation","title":"2: Leave-cluster-out cross-validation\u00b6","text":"<p>kfold split based on cluster</p>"},{"location":"train_test_splitters/#tgsplitter","title":"Tgsplitter\u00b6","text":""},{"location":"train_test_splitters/#tgsplitter","title":"Tgsplitter\u00b6","text":"<p>kfold split</p>"},{"location":"train_test_splitters/#polymerclasssplitter","title":"PolymerClassSplitter\u00b6","text":"<p>kfold split</p>"},{"location":"use_featurizers/","title":"Using featurizers","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\n</pre> %reload_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import logging\nfrom typing import List, Optional\nimport pandas as pd\n\nfrom polymetrix.featurizers.polymer import Polymer\nfrom polymetrix.featurizers.molecule import Molecule\nfrom polymetrix.featurizers.chemical_featurizer import (\n    NumHBondDonors,\n    NumHBondAcceptors,\n    NumRotatableBonds,\n    NumRings,\n    NumNonAromaticRings,\n    NumAromaticRings,\n    NumAtoms,\n    TopologicalSurfaceArea,\n    FractionBicyclicRings,\n    NumAliphaticHeterocycles,\n    SlogPVSA1,\n    BalabanJIndex,\n    MolecularWeight,\n    Sp3CarbonCountFeaturizer,\n    Sp2CarbonCountFeaturizer,\n    MaxEStateIndex,\n    SmrVSA5,\n    FpDensityMorgan1,\n    HalogenCounts,\n    BondCounts,\n    BridgingRingsCount,\n    MaxRingSize,\n    HeteroatomCount,\n    HeteroatomDensity,\n)\nfrom polymetrix.featurizers.sidechain_backbone_featurizer import (\n    SideChainFeaturizer,\n    NumSideChainFeaturizer,\n    BackBoneFeaturizer,\n    NumBackBoneFeaturizer,\n    FullPolymerFeaturizer,\n    SidechainLengthToStarAttachmentDistanceRatioFeaturizer,\n    StarToSidechainMinDistanceFeaturizer,\n    SidechainDiversityFeaturizer,\n)\n\nfrom polymetrix.featurizers.molecule import FullMolecularFeaturizer\n\nfrom polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer\n\nfrom polymetrix.featurizers.comparator import PolymerMoleculeComparator\n</pre> import logging from typing import List, Optional import pandas as pd  from polymetrix.featurizers.polymer import Polymer from polymetrix.featurizers.molecule import Molecule from polymetrix.featurizers.chemical_featurizer import (     NumHBondDonors,     NumHBondAcceptors,     NumRotatableBonds,     NumRings,     NumNonAromaticRings,     NumAromaticRings,     NumAtoms,     TopologicalSurfaceArea,     FractionBicyclicRings,     NumAliphaticHeterocycles,     SlogPVSA1,     BalabanJIndex,     MolecularWeight,     Sp3CarbonCountFeaturizer,     Sp2CarbonCountFeaturizer,     MaxEStateIndex,     SmrVSA5,     FpDensityMorgan1,     HalogenCounts,     BondCounts,     BridgingRingsCount,     MaxRingSize,     HeteroatomCount,     HeteroatomDensity, ) from polymetrix.featurizers.sidechain_backbone_featurizer import (     SideChainFeaturizer,     NumSideChainFeaturizer,     BackBoneFeaturizer,     NumBackBoneFeaturizer,     FullPolymerFeaturizer,     SidechainLengthToStarAttachmentDistanceRatioFeaturizer,     StarToSidechainMinDistanceFeaturizer,     SidechainDiversityFeaturizer, )  from polymetrix.featurizers.molecule import FullMolecularFeaturizer  from polymetrix.featurizers.multiple_featurizer import MultipleFeaturizer  from polymetrix.featurizers.comparator import PolymerMoleculeComparator In\u00a0[3]: Copied! <pre>psmiles_list = [\n    \"c1ccccc1[*]CCO[*]\",\n    \"CC[*]CCCC[*]\",\n]\n\nfull_featurizers = [\n    FullPolymerFeaturizer(NumRings()),\n    FullPolymerFeaturizer(MolecularWeight()),\n    FullPolymerFeaturizer(TopologicalSurfaceArea()),\n]\nfull_multi_featurizer = MultipleFeaturizer(full_featurizers)\n\nfor psmiles in psmiles_list:\n    polymer = Polymer.from_psmiles(psmiles)\n    features = full_multi_featurizer.featurize(polymer)\n    labels = full_multi_featurizer.feature_labels()\n\n    for label, value in zip(labels, features):\n        print(f\"{label}: {value:.2f}\")\n</pre> psmiles_list = [     \"c1ccccc1[*]CCO[*]\",     \"CC[*]CCCC[*]\", ]  full_featurizers = [     FullPolymerFeaturizer(NumRings()),     FullPolymerFeaturizer(MolecularWeight()),     FullPolymerFeaturizer(TopologicalSurfaceArea()), ] full_multi_featurizer = MultipleFeaturizer(full_featurizers)  for psmiles in psmiles_list:     polymer = Polymer.from_psmiles(psmiles)     features = full_multi_featurizer.featurize(polymer)     labels = full_multi_featurizer.feature_labels()      for label, value in zip(labels, features):         print(f\"{label}: {value:.2f}\") <pre>num_rings_sum_fullpolymerfeaturizer: 1.00\nmolecular_weight_sum_fullpolymerfeaturizer: 121.07\ntopological_surface_area_sum_fullpolymerfeaturizer: 9.23\nnum_rings_sum_fullpolymerfeaturizer: 0.00\nmolecular_weight_sum_fullpolymerfeaturizer: 85.10\ntopological_surface_area_sum_fullpolymerfeaturizer: 0.00\n</pre> In\u00a0[4]: Copied! <pre>sidechain_featurizers = [\n    NumSideChainFeaturizer(),\n    SideChainFeaturizer(NumAtoms(agg=[\"sum\"])),\n    SideChainFeaturizer(NumHBondDonors(agg=[\"sum\"])),\n    SideChainFeaturizer(NumRotatableBonds(agg=[\"sum\"])),\n]\nsidechain_multi_featurizer = MultipleFeaturizer(sidechain_featurizers)\n\nfor psmiles in psmiles_list:\n    polymer = Polymer.from_psmiles(psmiles)\n    features = sidechain_multi_featurizer.featurize(polymer)\n    labels = sidechain_multi_featurizer.feature_labels()\n    \n    for label, value in zip(labels, features):\n        print(f\"{label}: {value:.2f}\")\n</pre> sidechain_featurizers = [     NumSideChainFeaturizer(),     SideChainFeaturizer(NumAtoms(agg=[\"sum\"])),     SideChainFeaturizer(NumHBondDonors(agg=[\"sum\"])),     SideChainFeaturizer(NumRotatableBonds(agg=[\"sum\"])), ] sidechain_multi_featurizer = MultipleFeaturizer(sidechain_featurizers)  for psmiles in psmiles_list:     polymer = Polymer.from_psmiles(psmiles)     features = sidechain_multi_featurizer.featurize(polymer)     labels = sidechain_multi_featurizer.feature_labels()          for label, value in zip(labels, features):         print(f\"{label}: {value:.2f}\") <pre>numsidechainfeaturizer: 1.00\nnum_atoms_sidechainfeaturizer_sum: 6.00\nnum_hbond_donors_sidechainfeaturizer_sum: 0.00\nnum_rotatable_bonds_sidechainfeaturizer_sum: 0.00\nnumsidechainfeaturizer: 1.00\nnum_atoms_sidechainfeaturizer_sum: 2.00\nnum_hbond_donors_sidechainfeaturizer_sum: 0.00\nnum_rotatable_bonds_sidechainfeaturizer_sum: 0.00\n</pre> In\u00a0[5]: Copied! <pre>backbone_featurizers = [\n    NumBackBoneFeaturizer(),\n    BackBoneFeaturizer(NumRings()),\n    BackBoneFeaturizer(NumAtoms()),\n    BackBoneFeaturizer(TopologicalSurfaceArea()),\n]\nbackbone_multi_featurizer = MultipleFeaturizer(backbone_featurizers)\n\nfor psmiles in psmiles_list:\n    polymer = Polymer.from_psmiles(psmiles)\n    features = backbone_multi_featurizer.featurize(polymer)\n    labels = backbone_multi_featurizer.feature_labels()\n    \n    for label, value in zip(labels, features):\n        print(f\"{label}: {value:.2f}\")\n</pre> backbone_featurizers = [     NumBackBoneFeaturizer(),     BackBoneFeaturizer(NumRings()),     BackBoneFeaturizer(NumAtoms()),     BackBoneFeaturizer(TopologicalSurfaceArea()), ] backbone_multi_featurizer = MultipleFeaturizer(backbone_featurizers)  for psmiles in psmiles_list:     polymer = Polymer.from_psmiles(psmiles)     features = backbone_multi_featurizer.featurize(polymer)     labels = backbone_multi_featurizer.feature_labels()          for label, value in zip(labels, features):         print(f\"{label}: {value:.2f}\") <pre>numbackbonefeaturizer: 1.00\nnum_rings_sum_backbonefeaturizer: 0.00\nnum_atoms_sum_backbonefeaturizer: 5.00\ntopological_surface_area_sum_backbonefeaturizer: 9.23\nnumbackbonefeaturizer: 1.00\nnum_rings_sum_backbonefeaturizer: 0.00\nnum_atoms_sum_backbonefeaturizer: 6.00\ntopological_surface_area_sum_backbonefeaturizer: 0.00\n</pre> In\u00a0[6]: Copied! <pre>psmiles_list = [\n    \"CCCC\",\n    \"NC(=O)c1ccc2c(c1)nc(C1CCC(O)CC1)n2CCCO\",\n    \"CNC(=S)Nc1cccc(-c2cnc3ccccc3n2)c1\",\n    \"C#Cc1ccc(-c2nc(-c3cc[nH]c(=O)c3)c(-c3ccc(F)cc3)[nH]2)cc1\",\n]\n\nfull_featurizers = [\n    FullMolecularFeaturizer(NumRings()),\n    FullMolecularFeaturizer(MolecularWeight()),\n    FullMolecularFeaturizer(TopologicalSurfaceArea()),\n]\nfull_multi_featurizer = MultipleFeaturizer(full_featurizers)\n\nfor psmiles in psmiles_list:\n    polymer = Molecule.from_smiles(psmiles)\n    features = full_multi_featurizer.featurize(polymer)\n    labels = full_multi_featurizer.feature_labels()\n\n    for label, value in zip(labels, features):\n        print(f\"{label}: {value:.2f}\")\n</pre> psmiles_list = [     \"CCCC\",     \"NC(=O)c1ccc2c(c1)nc(C1CCC(O)CC1)n2CCCO\",     \"CNC(=S)Nc1cccc(-c2cnc3ccccc3n2)c1\",     \"C#Cc1ccc(-c2nc(-c3cc[nH]c(=O)c3)c(-c3ccc(F)cc3)[nH]2)cc1\", ]  full_featurizers = [     FullMolecularFeaturizer(NumRings()),     FullMolecularFeaturizer(MolecularWeight()),     FullMolecularFeaturizer(TopologicalSurfaceArea()), ] full_multi_featurizer = MultipleFeaturizer(full_featurizers)  for psmiles in psmiles_list:     polymer = Molecule.from_smiles(psmiles)     features = full_multi_featurizer.featurize(polymer)     labels = full_multi_featurizer.feature_labels()      for label, value in zip(labels, features):         print(f\"{label}: {value:.2f}\") <pre>num_rings_sum_fullmolecularfeaturizer: 0.00\nmolecular_weight_sum_fullmolecularfeaturizer: 58.08\ntopological_surface_area_sum_fullmolecularfeaturizer: 0.00\nnum_rings_sum_fullmolecularfeaturizer: 3.00\nmolecular_weight_sum_fullmolecularfeaturizer: 317.17\ntopological_surface_area_sum_fullmolecularfeaturizer: 101.37\nnum_rings_sum_fullmolecularfeaturizer: 3.00\nmolecular_weight_sum_fullmolecularfeaturizer: 294.09\ntopological_surface_area_sum_fullmolecularfeaturizer: 49.84\nnum_rings_sum_fullmolecularfeaturizer: 4.00\nmolecular_weight_sum_fullmolecularfeaturizer: 355.11\ntopological_surface_area_sum_fullmolecularfeaturizer: 61.54\n</pre> In\u00a0[7]: Copied! <pre>polymer = Polymer.from_psmiles('*CCCCCCNC(=O)c1ccc(C(=O)N*)c(Sc2ccccc2)c1')\nmolecule = Molecule.from_smiles('CC(=O)OC1=CC=CC=C1C(=O)O')\n\npolymer_featurizers = [\n    FullPolymerFeaturizer(MolecularWeight()),\n    FullPolymerFeaturizer(NumHBondDonors()),\n    FullPolymerFeaturizer(NumHBondAcceptors()),\n    FullPolymerFeaturizer(NumRotatableBonds())\n]\n\nmolecule_featurizers = [\n    FullMolecularFeaturizer(MolecularWeight()),\n    FullMolecularFeaturizer(NumHBondDonors()),\n    FullMolecularFeaturizer(NumHBondAcceptors()),\n    FullMolecularFeaturizer(NumRotatableBonds())\n]\n\npolymer_multi = MultipleFeaturizer(polymer_featurizers)\nmolecule_multi = MultipleFeaturizer(molecule_featurizers)\n\n# comparator = PolymerMoleculeComparator(polymer_multi, molecule_multi)\n\ncomparator = PolymerMoleculeComparator(\n    polymer_multi, \n    molecule_multi, \n    comparisons=[\"absolute_difference\", \"signed_difference\", \"product\", \"squared_distance\", \"euclidean_distance\"],\n    agg=[\"mean\", \"max\", \"min\", \"sum\"]\n)\n\ndifference = comparator.compare(polymer, molecule)\n\nlabels = comparator.feature_labels()\n\n# Print feature-wise results\nfor label, diff in zip(labels, difference):\n    print(f\"  {label}: {diff}\")\n</pre> polymer = Polymer.from_psmiles('*CCCCCCNC(=O)c1ccc(C(=O)N*)c(Sc2ccccc2)c1') molecule = Molecule.from_smiles('CC(=O)OC1=CC=CC=C1C(=O)O')  polymer_featurizers = [     FullPolymerFeaturizer(MolecularWeight()),     FullPolymerFeaturizer(NumHBondDonors()),     FullPolymerFeaturizer(NumHBondAcceptors()),     FullPolymerFeaturizer(NumRotatableBonds()) ]  molecule_featurizers = [     FullMolecularFeaturizer(MolecularWeight()),     FullMolecularFeaturizer(NumHBondDonors()),     FullMolecularFeaturizer(NumHBondAcceptors()),     FullMolecularFeaturizer(NumRotatableBonds()) ]  polymer_multi = MultipleFeaturizer(polymer_featurizers) molecule_multi = MultipleFeaturizer(molecule_featurizers)  # comparator = PolymerMoleculeComparator(polymer_multi, molecule_multi)  comparator = PolymerMoleculeComparator(     polymer_multi,      molecule_multi,      comparisons=[\"absolute_difference\", \"signed_difference\", \"product\", \"squared_distance\", \"euclidean_distance\"],     agg=[\"mean\", \"max\", \"min\", \"sum\"] )  difference = comparator.compare(polymer, molecule)  labels = comparator.feature_labels()  # Print feature-wise results for label, diff in zip(labels, difference):     print(f\"  {label}: {diff}\") <pre>  molecular_weight_sum_fullpolymerfeaturizer_absolute_difference: 174.097940208\n  num_hbond_donors_sum_fullpolymerfeaturizer_absolute_difference: 1.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_absolute_difference: 0.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_absolute_difference: 8.0\n  molecular_weight_sum_fullpolymerfeaturizer_signed_difference: 174.097940208\n  num_hbond_donors_sum_fullpolymerfeaturizer_signed_difference: 1.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_signed_difference: 0.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_signed_difference: 8.0\n  molecular_weight_sum_fullpolymerfeaturizer_product: 63760.20132709417\n  num_hbond_donors_sum_fullpolymerfeaturizer_product: 2.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_product: 9.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_product: 20.0\n  molecular_weight_sum_fullpolymerfeaturizer_squared_distance: 30310.092784668348\n  num_hbond_donors_sum_fullpolymerfeaturizer_squared_distance: 1.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_squared_distance: 0.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_squared_distance: 64.0\n  molecular_weight_sum_fullpolymerfeaturizer_euclidean_distance: 174.097940208\n  num_hbond_donors_sum_fullpolymerfeaturizer_euclidean_distance: 1.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_euclidean_distance: 0.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_euclidean_distance: 8.0\n  molecular_weight_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_mean: 18918.5175864773\n  num_hbond_donors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_mean: 1.2\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_mean: 1.8\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_mean: 21.6\n  molecular_weight_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_max: 63760.20132709417\n  num_hbond_donors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_max: 2.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_max: 9.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_max: 64.0\n  molecular_weight_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_min: 174.097940208\n  num_hbond_donors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_min: 1.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_min: 0.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_min: 8.0\n  molecular_weight_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_sum: 94592.58793238651\n  num_hbond_donors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_sum: 6.0\n  num_hbond_acceptors_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_sum: 9.0\n  num_rotatable_bonds_sum_fullpolymerfeaturizer_absolute_difference_signed_difference_product_squared_distance_euclidean_distance_sum: 108.0\n</pre> In\u00a0[8]: Copied! <pre>polymer = Polymer.from_psmiles(\"[*]=C(C#N)NC(=O)c1ccc(C(=O)NC(=[*])C#N)cc1\")\n# Add terminal groups for the sidechain and backbone\npolymer.backbone_terminal_groups = {\"[*]\": \"*O\"} \npolymer.sidechain_terminal_groups = {\"[*]\": \"*CCO\"}\n</pre> polymer = Polymer.from_psmiles(\"[*]=C(C#N)NC(=O)c1ccc(C(=O)NC(=[*])C#N)cc1\") # Add terminal groups for the sidechain and backbone polymer.backbone_terminal_groups = {\"[*]\": \"*O\"}  polymer.sidechain_terminal_groups = {\"[*]\": \"*CCO\"} In\u00a0[9]: Copied! <pre>backbone_featurizers = [\n    NumBackBoneFeaturizer(),\n    BackBoneFeaturizer(NumRings()),\n    BackBoneFeaturizer(NumAtoms()),\n    BackBoneFeaturizer(TopologicalSurfaceArea()),\n]\n\nbackbone_multi_featurizer = MultipleFeaturizer(backbone_featurizers)\nfeatures = backbone_multi_featurizer.featurize(polymer)\nlabels = backbone_multi_featurizer.feature_labels()\n\n# Print labels and features\nfor label, value in zip(labels, features):\n    print(f\"{label}: {value:.2f}\")\n</pre> backbone_featurizers = [     NumBackBoneFeaturizer(),     BackBoneFeaturizer(NumRings()),     BackBoneFeaturizer(NumAtoms()),     BackBoneFeaturizer(TopologicalSurfaceArea()), ]  backbone_multi_featurizer = MultipleFeaturizer(backbone_featurizers) features = backbone_multi_featurizer.featurize(polymer) labels = backbone_multi_featurizer.feature_labels()  # Print labels and features for label, value in zip(labels, features):     print(f\"{label}: {value:.2f}\") <pre>numbackbonefeaturizer: 1.00\nnum_rings_sum_with_terminalgroups_backbonefeaturizer: 1.00\nnum_atoms_sum_with_terminalgroups_backbonefeaturizer: 16.00\ntopological_surface_area_sum_with_terminalgroups_backbonefeaturizer: 92.34\n</pre> In\u00a0[10]: Copied! <pre>sidechain_featurizers = [\n    NumSideChainFeaturizer(),\n    SideChainFeaturizer(NumAtoms()),\n    SideChainFeaturizer(NumHBondDonors()),\n    SideChainFeaturizer(TopologicalSurfaceArea()),\n]\n\nsidechain_multi_featurizer = MultipleFeaturizer(sidechain_featurizers)\nfeatures = sidechain_multi_featurizer.featurize(polymer)\nlabels = sidechain_multi_featurizer.feature_labels()\n\n# Print labels and features\nfor label, value in zip(labels, features):\n    print(f\"{label}: {value:.2f}\")\n</pre> sidechain_featurizers = [     NumSideChainFeaturizer(),     SideChainFeaturizer(NumAtoms()),     SideChainFeaturizer(NumHBondDonors()),     SideChainFeaturizer(TopologicalSurfaceArea()), ]  sidechain_multi_featurizer = MultipleFeaturizer(sidechain_featurizers) features = sidechain_multi_featurizer.featurize(polymer) labels = sidechain_multi_featurizer.feature_labels()  # Print labels and features for label, value in zip(labels, features):     print(f\"{label}: {value:.2f}\") <pre>numsidechainfeaturizer: 2.00\nnum_atoms_with_terminalgroups_sidechainfeaturizer_sum: 10.00\nnum_hbond_donors_with_terminalgroups_sidechainfeaturizer_sum: 2.00\ntopological_surface_area_with_terminalgroups_sidechainfeaturizer_sum: 88.04\n</pre> In\u00a0[11]: Copied! <pre># Full polymer featurizers\nfull_polymer_featurizers = [\n    FullPolymerFeaturizer(NumAtoms()),\n    FullPolymerFeaturizer(NumHBondDonors()),\n    FullPolymerFeaturizer(TopologicalSurfaceArea()),\n]\nfull_multi_featurizer = MultipleFeaturizer(full_polymer_featurizers)\nfeatures = full_multi_featurizer.featurize(polymer)\nlabels = full_multi_featurizer.feature_labels()\nprint(\"\\nFull molecular features:\")\nfor label, value in zip(labels, features):\n    print(f\"{label}: {value:.2f}\")\n</pre> # Full polymer featurizers full_polymer_featurizers = [     FullPolymerFeaturizer(NumAtoms()),     FullPolymerFeaturizer(NumHBondDonors()),     FullPolymerFeaturizer(TopologicalSurfaceArea()), ] full_multi_featurizer = MultipleFeaturizer(full_polymer_featurizers) features = full_multi_featurizer.featurize(polymer) labels = full_multi_featurizer.feature_labels() print(\"\\nFull molecular features:\") for label, value in zip(labels, features):     print(f\"{label}: {value:.2f}\") <pre>\nFull molecular features:\nnum_atoms_sum_with_terminalgroups_fullpolymerfeaturizer: 20.00\nnum_hbond_donors_sum_with_terminalgroups_fullpolymerfeaturizer: 2.00\ntopological_surface_area_sum_with_terminalgroups_fullpolymerfeaturizer: 105.78\n</pre>"},{"location":"use_featurizers/#full-polymer-featurization","title":"Full Polymer Featurization\u00b6","text":""},{"location":"use_featurizers/#side-chain-featurization","title":"Side Chain Featurization\u00b6","text":""},{"location":"use_featurizers/#backbone-featurization","title":"Backbone Featurization\u00b6","text":""},{"location":"use_featurizers/#full-molecular-featurization","title":"Full Molecular Featurization\u00b6","text":""},{"location":"use_featurizers/#using-comparators-to-compare-polymer-and-molecule-features","title":"Using Comparators to Compare Polymer and Molecule Features\u00b6","text":""},{"location":"use_featurizers/#adding-terminal-groups-to-polymers","title":"Adding Terminal Groups to Polymers\u00b6","text":""}]}